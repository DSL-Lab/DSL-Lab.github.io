<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://dsl-lab.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://dsl-lab.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-04T05:25:04+00:00</updated><id>https://dsl-lab.github.io/feed.xml</id><title type="html">Laboratory for Deep Structured Learning</title><subtitle>Renjie Liao&apos;s Lab for deep structured learning. </subtitle><entry><title type="html">A Unified Framework for Diffusion Distillation</title><link href="https://dsl-lab.github.io/blog/2025/diff-distill/" rel="alternate" type="text/html" title="A Unified Framework for Diffusion Distillation"/><published>2025-08-21T00:00:00+00:00</published><updated>2025-08-21T00:00:00+00:00</updated><id>https://dsl-lab.github.io/blog/2025/diff-distill</id><content type="html" xml:base="https://dsl-lab.github.io/blog/2025/diff-distill/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Diffusion and flow-based models<d-cite key="ho2020denoising, lipman_flow_2023, albergo2023stochastic, liu2022flow"></d-cite> have taken over the generative AI space, enabling unprecedented capabilities in videos, audios, and text generation. Nonetheless, there is a caveat⚠️ — they are painfully <strong>slow</strong> during inference. Generating a single high-quality sample requires running through hundreds of denoising steps, which translate to high costs and long wait times.</p> <p>At its core, diffusion models (equivalently, flow matching models) operate by iteratively refining noisy data into high-quality outputs through a series of denoising steps. Similar to divide-and-conquer algorithms <d-footnote>Common ones like Mergesort, locating the median and Fast Fourier Transform.</d-footnote>, diffusion models first <em>divide</em> the difficult denoising task into subtasks and <em>conquer</em> one of these at a time during training. To obtain a sample, we make a sequence of recursive predictions which means we need to <em>conquer</em> the entire task end-to-end.</p> <p>This challenge has spurred research into acceleration strategies across multiple granular levels, including hardware optimization, mixed precision training<d-cite key="micikevicius2017mixed"></d-cite>, <a href="https://github.com/bitsandbytes-foundation/bitsandbytes">quantization</a>, and parameter-efficient fine-tuning<d-cite key="hu2021lora"></d-cite>. In this blog, we focus on an orthogonal approach named <strong>Ordinary Differential Equation (ODE) distillation</strong>. This method introduces an auxiliary structure that bypasses explicit ODE solving, thereby reducing the Number of Function Evaluations (NFEs). As a result, we can generate high-quality samples with fewer denoising steps.</p> <p>Distillation, in general, is a technique that transfers knowledge from a complex, high-performance model (the <em>teacher</em>) to a more efficient, customized model (the <em>student</em>). Recent distillation methods have achieved remarkable reductions in sampling steps, from hundreds to a few and even <strong>one</strong> step, while preserving the sample quality. This advancement paves the way for real-time applications and deployment in resource-constrained environments.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/blog/2025/diff-distill/diff-distill.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls="" loop=""/> </figure> <div class="caption"> A video illustrating the basic flow matching concepts and three categories of ODE distillation objectives. </div> </div> </div> <h2 id="notation-at-a-glance">Notation at a Glance</h2> <p>The modern approaches of generative modelling consist of picking some samples from a base distribution \(\mathbf{x}_{1} \sim p_{\text{noise}}\), typically an isotropic Gaussian, and learning a map such that \(\mathbf{x}_{0} \sim p_{\text{data}}\). The connection between these two distributions can be expressed by establishing an initial value problem controlled by the <strong>velocity field</strong> \(v(\mathbf{x}_{t}, t)\),</p> \[\require{physics} \begin{equation} \dv{\psi_t(\mathbf{x}_t)}{t}=v(\psi_t(\mathbf{x}_t), t),\quad\psi_0(\mathbf{x}_0)=\mathbf{x}_0,\quad \mathbf{x}_0\sim p_{\text{data}} \label{eq:1} \end{equation}\] <p>where the <strong>flow</strong> \(\psi_t:\mathbb{R}^d\times[0,1]\to \mathbb{R}^d\) is a diffeomorphic map with \(\psi_t(\mathbf{x}_t)\) defined as the solution to the above ODE (\ref{eq:1}). If the flow satisfies the push-forward equation<d-footnote>This is also known as the change of variable equation: $[\phi_t]_\# p_0(x) = p_0(\phi_t^{-1}(x)) \det \left[ \frac{\partial \phi_t^{-1}}{\partial x}(x) \right].$</d-footnote> \(p_t=[\psi_t]_\#p_0\), we say a <strong>probability path</strong> \((p_t)_{t\in[0,1]}\) is generated from the velocity vector field. The goal of flow matching<d-cite key="lipman_flow_2023"></d-cite> is to find a velocity field \(v_\theta(\mathbf{x}_t, t)\) so that it transforms \(\mathbf{x}_1\sim p_{\text{noise}}\) to \(\mathbf{x}_0\sim p_{\text{data}}\) when integrated. In order to receive supervision at each time step, one must predefine a condition probability path \(p_t(\cdot \vert \mathbf{x}_0)\)<d-footnote>In practice, the most common one is the Gaussian conditional probability path. This arises from a Gaussian conditional vector field, whose analytical form can be derived from the continuity equation. $$\frac{\partial p_t}{\partial t} + \nabla \cdot (p_t v) = 0$$ See the table for details.</d-footnote> associated with its velocity field. For each datapoint \(\mathbf{x}_0\in \mathbb{R}^d\), let \(v(\mathbf{x}_t, t\vert\mathbf{x}_0)=\mathbb{E}_{p_t(v_t \vert \mathbf{x}_0)}[v_t]\) denote a conditional velocity vector field so that the corresponding ODE (\ref{eq:1}) yields the conditional flow.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/diff-distill/teaser_probpath_velocity_field-480.webp 480w,/blog/2025/diff-distill/teaser_probpath_velocity_field-800.webp 800w,/blog/2025/diff-distill/teaser_probpath_velocity_field-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/diff-distill/teaser_probpath_velocity_field.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> From left to right:<d-cite key="lipman2024flowmatchingguidecode"></d-cite>conditional and marginal probability paths, conditional and marginal velocity fields. The velocity field induces a flow that dictates its instantaneous movement across all points in space. </div> </div> </div> <p>Most of the conditional probability paths are designed as the <strong>differentiable</strong> interpolation between noise and data for simplicity, and we can express sampling from a marginal path \(\mathbf{x}_t = \alpha(t)\mathbf{x}_0 + \beta(t)\mathbf{x}_1\) where \(\alpha(t), \beta(t)\) are predefined schedules. <d-footnote>The stochastic interpolant paper defines this probability path that summarizes all diffusion models, with several assumptions. Here, we use a simpler interpolant for clean illustration.</d-footnote></p> <p>We provide some popular instances <d-footnote>We ignore the diffusion models with SDE formulation like DDPM<d-cite key="ho2020denoising"></d-cite> or ScoreSDE<d-cite key="song2020score"></d-cite> on purpose since we concentrate on ODE distillation in this blog.</d-footnote> of these schedules in the table below.</p> <table> <thead> <tr> <th>Method</th> <th>Probability Path \(p_t\)</th> <th>Vector Field \(u(\mathbf{x}_t, t\vert\mathbf{x}_0)\)</th> </tr> </thead> <tbody> <tr> <td>Gaussian</td> <td>\(\mathcal{N}(\alpha(t)\mathbf{x}_0,\beta^2(t)I_d)\)</td> <td>\(\left(\dot{\alpha}_t - \frac{\dot{\beta}_t}{\beta_t}\alpha_t\right) \mathbf{x}_0 + \frac{\dot{\beta}_t}{\beta_t}\mathbf{x}_1\)</td> </tr> <tr> <td>FM <d-cite key="lipman_flow_2023"></d-cite></td> <td>\(\mathcal{N}(t\mathbf{x}_1, (1-t+\sigma t)^2I_d)\)</td> <td>\(\frac{\mathbf{x}_1 - (1-\sigma)\mathbf{x}_t}{1-\sigma+\sigma t}\)</td> </tr> <tr> <td>iCFM <d-cite key="liu2022flow"></d-cite></td> <td>\(\mathcal{N}( t\mathbf{x}_1 + (1-t)\mathbf{x}_0, \sigma^2I_d)\)</td> <td>\(\mathbf{x}_1 - \mathbf{x}_0\)</td> </tr> <tr> <td>OT-CFM <d-cite key="tong2023improving"></d-cite></td> <td>Same prob. path above with \(q(z) = \pi(\mathbf{x}_0, \mathbf{x}_1)\)</td> <td>\(\mathbf{x}_1 - \mathbf{x}_0\)</td> </tr> <tr> <td>VP-SI <d-cite key="albergo2023stochastic"></d-cite></td> <td>\(\mathcal{N}( \cos(\pi t/2)\mathbf{x}_0 + \sin(\pi t/2)\mathbf{x}_1, \sigma^2I_d)\)</td> <td>\(\frac{\pi}{2}(\cos(\pi t/2)\mathbf{x}_1 - \sin(\pi t/2)\mathbf{x}_0)\)</td> </tr> </tbody> </table> <p>The simplest form of conditional probability path is \(\mathbf{x}_t = (1-t)\mathbf{x}_0 + t\mathbf{x}_1\) with the corresponding default conditional velocity field OT target \(v(\mathbf{x}_t, t \vert \mathbf{x}_0)=\mathbb{E}[\dot{\mathbf{x}}_t\vert \mathbf{x}_0]=\mathbf{x}_1- \mathbf{x}_0.\)</p> <p>Borrowed from this <a href="https://rectifiedflow.github.io/assets/slides/icml_07_distillation.pdf">slide</a> at ICML2025, the objectives of ODE distillation have been categorized into three cases, i.e., (a) <strong>forward loss</strong>, (b) <strong>backward loss</strong> and (c) <strong>self-consistency loss</strong>.</p> <p><span style="color: blue; font-weight: bold;">Training</span>: Since minimizing the conditional Flow Matching (FM) loss is equivalent to minimize the marginal FM loss<d-cite key="lipman_flow_2023"></d-cite>, the optimization problem becomes</p> \[\arg\min_\theta\mathbb{E}_{\mathbf{x}_0, \mathbf{x}_1, t} \left[ w(t) \left\| v_\theta(\mathbf{x}_t, t) - v(\mathbf{x}_t, t | \mathbf{x}_0) \right\|_2^2 \right]\] <p>where \(w(t)\) is a reweighting function<d-footnote>The weighting function modulates the contribution of the loss at each time step. This is necessary because the nature of the task differs fundamentally between high and low noise levels, requiring a balanced treatment of the loss across these regimes. Some common ones are included in this blog https://diffusionflow.github.io/.</d-footnote>.</p> <p><span style="color: orange; font-weight: bold;">Sampling</span>: Solve the ODE \(\require{physics} \dv{\mathbf{x}_t}{t}=v_\theta(\mathbf{x}_t, t)\) from the initial condition \(\mathbf{x}_1\sim p_{\text{noise}}.\) Typically, an Euler solver or another high-order ODE solver is employed, taking a few hundred discrete steps through iterative refinements.</p> <h2 id="ode-distillation-methods">ODE Distillation methods</h2> <p>Before introducing ODE distillation methods, it is imperative to define a general continuous-time flow map \(f_{t\to s}(\mathbf{x}_t, t, s)\)<d-cite key="boffi2025build"></d-cite> where it maps any noisy input \(\mathbf{x}_t, t\in[0,1]\) to any point \(\mathbf{x}_s, s\in[0,1]\) on the ODE (\ref{eq:1}) that describes the probability flow aformentioned. This is a generalization of flow-based distillation and consistency models within a single unified framework. The flow map is well-defined only if its <strong>boundary conditions</strong> satisfy \(f_{t\to t}(\mathbf{x}_t, t, t) = \mathbf{x}_t\) for all time steps. One popular way to meet the condition is to parameterize the model as \(f_{t\to s}(\mathbf{x}_t, t, s)= c_{\text{skip}}(t, s)\mathbf{x}_t + c_{\text{out}}(t,s)F_{t\to s}(\mathbf{x}_t, t, s)\) where \(c_{\text{skip}}(t, t) = 1\) and \(c_{\text{out}}(t, t) = 0\) for all \(t\).</p> <p>At its core, ODE distillation boils down to how to strategically construct the training objective of the flow map \(f_{t\to s}(\mathbf{x}_t, t, s)\) so that it can be efficiently evaluated during sampling. In addition, we need to orchestrate the schedule of \((t,s)\) pairs for better training dynamics.</p> <p>In the context of distillation, the forward direction \(s&lt;t\) is typically taken as the target. Yet, the other direction can also carry meaningful structure. Notice in DDIM<d-cite key="song2020denoising"></d-cite> sampling, the conditional probability path is traversed twice. In our flow map formulation, this can be replaced with the flow maps \(f_{\tau_i\to 0}(\mathbf{x}_{\tau_i}, \tau_i, 0), f_{0\to \tau_{i-1}}(\mathbf{x}_0, 0, \tau_{i-1})\) where \(0&lt;\tau_{i-1}&lt;\tau_i&lt;1\). Intuitively, the flow map \(f_{t\to s}(\mathbf{x}_t, t, s)\) represents a direct mapping of some <strong>displacement field</strong> where \(F_{t\to s}(\mathbf{x}_t, t, s)\) measures the increment which corresponds to a <strong>velocity field</strong>.</p> <h3 id="meanflow">MeanFlow</h3> <p>MeanFlow<d-cite key="geng2025mean"></d-cite> can be trained from scratch or distilled from a pretrained FM model. The conditional probability path is defined as the linear interpolation between noise and data \(\mathbf{x}_t = (1-t)\mathbf{x}_0 + t\mathbf{x}_1\) with the corresponding default conditional velocity field OT target \(v(\mathbf{x}_t, t \vert \mathbf{x}_0)=\mathbf{x}_1- \mathbf{x}_0.\) The main contribution consists of identifying and defining an <strong>average velocity field</strong> which coincides with our flow map as</p> \[F_{t\to s}(\mathbf{x}_t, t, s)=u(\mathbf{x}_t, t, s) \triangleq \frac{1}{t - s} \int_s^t v(\mathbf{x}_\tau, \tau) d\tau=\dfrac{f_{t\to s}(\mathbf{x}_t, t, s)-f_{t\to t}(\mathbf{x}_t, t, t)}{s-t}\] <p>where \(c_{\text{out}}(t,s)=s-t\). This is great since it attributes actual physical meaning to our flow map. In particular, \(f_{t\to s}(\mathbf{x}_t, t, s)\) represents the “displacement” from \(\mathbf{x}_t\) to \(\mathbf{x}_s\), while \(F_{t\to s}(\mathbf{x}_t, t, s)\) is the average velocity field pointing from \(\mathbf{x}_t\) to \(\mathbf{x}_s\).</p> <p>We rearrange equation above.</p> \[\begin{equation} (t-s)F_{t\to s}(\mathbf{x}_t, t, s)=\int_s^t v(\mathbf{x}_\tau, \tau) d\tau \label{eq:2} \end{equation}\] <p>Differentiating (\ref{eq:2}) both sides w.r.t. $t$ and considering the assumption that $s$ is independent of $t$, we obtain the MeanFlow identity<d-cite key="geng2025mean"></d-cite></p> \[\require{physics} v(\mathbf{x}_t, t)=F_{t\to s}(\mathbf{x}_t, t, s) +(t-s)\dv{F_{t\to s}(\mathbf{x}_t, t, s)}{t}\] <p>where we further compute the total derivative and derive the target \(F_{t\to s}^{\text{tgt}}(\mathbf{x}_t, t, s)\).</p> <p><span style="color: blue; font-weight: bold;">Training</span>: Adapting to our flow map notation, the training objective turns to</p> \[\mathbb{E}_{\mathbf{x}_0, \mathbf{x}_1, t, s} \left[ w(t) \left\| F^\theta_{t\to s}(\mathbf{x}_t, t, s) - F_{t\to s}^{\text{tgt}}(\mathbf{x}_t, t, s | \mathbf{x}_0) \right\|_2^2 \right]\] <p>where \(F_{t\to s}^{\text{tgt}}(\mathbf{x}_t, t, s\vert\mathbf{x}_0)=v - (t-s)(v\partial_{\mathbf{x}_t}F^{\theta^-}_{t\to s}(\mathbf{x}_t, t, s) + \partial_t F^{\theta^-}_{t\to s}(\mathbf{x}_t, t, s))\) and \(\theta^-\) means <code class="language-plaintext highlighter-rouge">stopgrad()</code>. Note <code class="language-plaintext highlighter-rouge">stopgrad</code> aims to avoid high order gradient computation. There are a couple of choices for \(v\), we can substitute it with \(F_{t\to t}(\mathbf{x}_t, t, t)\) or \(v(\mathbf{x}_t, t \vert \mathbf{x}_0)=\mathbf{x}_1- \mathbf{x}_0.\) Again, MeanFlow adopts the latter to reduce computation.</p> <details> <summary>Full derivation of the target</summary> Based on the MeanFlow identity, we can compute the target as follows: $$ \require{physics} \require{cancel} \begin{align*} F_{t\to s}^{\text{tgt}}(\mathbf{x}_t, t, s\vert\mathbf{x}_0) &amp;= \dv{\mathbf{x}_t}{t} - (t-s)\dv{F_{t\to s}(\mathbf{x}_t, t, s)}{t} \\ &amp; = \dv{\mathbf{x}_t}{t} - (t-s)\left(\nabla_{\mathbf{x}_t} F_{t\to s}(\mathbf{x}_t, t, s) \dv{\mathbf{x}_t}{t} + \partial_t F_{t\to s}(\mathbf{x}_t, t, s) + \cancel{\partial_s F_{t\to s}(\mathbf{x}_t, t, s) \dv{s}{t}}\right) \\ &amp; = v - (t-s)\left(v \nabla_{\mathbf{x}_t} F_{t\to s}(\mathbf{x}_t, t, s) + \partial_t F_{t\to s}(\mathbf{x}_t, t, s)\right). \\ \end{align*} $$ Note that in MeanFlow $$\dv{\mathbf{x}_t}{t} = v(\mathbf{x}_t, t\vert \mathbf{x}_0)$$ and $$\dv{s}{t}=0$$ since $s$ is independent of $t$. </details> <p>In practice, the total derivative of \(F_{t\to s}(\mathbf{x}_t, t, s)\) and the evaluation can be done in a single function call: <code class="language-plaintext highlighter-rouge">f, dfdt=jvp(f_theta, (xt, s, t), (v, 0, 1))</code>. Despite <code class="language-plaintext highlighter-rouge">jvp</code> operation only introduces one extra backward pass, it still incurs instability and slows down training. Moreover, the <code class="language-plaintext highlighter-rouge">jvp</code> operation is currently incompatible with the latest attention architecture. SplitMeanFlow<d-cite key="guo2025splitmeanflow"></d-cite> circumvents this issue by enforcing another consistency identity \((t-s)F_{t\to s} = (t-r)F_{t\to r}+(r-s)F_{r\to s}\) where \(s&lt;r&lt;t\). This implies a discretized version of the MeanFlow objective which falls into loss type (c).</p> <details> <summary>Loss type</summary> Type (b) backward loss </details> <p><span style="color: orange; font-weight: bold;">Sampling</span>: Either one-step or multi-step sampling can be performed. It is intuitive to obtain the following expression by the definition of average velocity field</p> \[\mathbf{x}_s = \mathbf{x}_t - (t-s)F^\theta_{t\to s}(\mathbf{x}_t, t, s).\] <p>In particular, we achieve one-step inference by setting $t=1, s=0$ and sampling from \(\mathbf{x}_1\sim p_{\text{noise}}\).</p> <h3 id="consistency-models">Consistency Models</h3> <p>Essentially, consistency models (CMs)<d-cite key="lu2024simplifying"></d-cite> are our flow map when \(s=0\), i.e., \(f_{t\to 0}(\mathbf{x}_t, t, 0).\)</p> <p><strong>Discretized CM</strong></p> <p>CMs are trained to have consistent outputs between adjacent timesteps along the ODE (\ref{eq:1}) trajectory. They can be trained from scratch by consistency training or distilled from given diffusion or flow models via consistency distillation like MeanFlow.</p> <ul> <li><span style="color: blue; font-weight: bold;">Training</span>: When expressed in our flow map notation, the objective becomes</li> </ul> \[\mathbb{E}_{\mathbf{x}_t, t} \left[ w(t) d\left(f_{t \to 0}^\theta(\mathbf{x}_t, t,0), f_{t \to 0}^{\theta^-}(\mathbf{x}_{t-\Delta t}, t - \Delta t,0)\right) \right],\] <p>where \(\theta^-\) denotes \(\text{stopgrad}(\theta)\), \(w(t)\) is a weighting function, \(\Delta t &gt; 0\) is the distance between adjacent time steps, and $d(\cdot, \cdot)$ is a distance metric.<d-footnote>Common choices include $\ell_2$ loss $d(\mathbf{x}, \mathbf{y}) = ||\mathbf{x} - \mathbf{y}||_2^2$, pseudo-Huber loss $d(\mathbf{x}, \mathbf{y}) = \sqrt{||\mathbf{x} - \mathbf{y}||_2^2 + c^2} - c$ and Learned Perceptual Image Patch Similarity (LPIPS) loss. </d-footnote></p> <ul> <li><span style="color: orange; font-weight: bold;">Sampling</span>: It is natural to conduct one-step sampling with CM</li> </ul> \[\hat{\mathbf{x}}_0 = f^{\theta}_{1\to 0}(\mathbf{x}_1, 1,0),\] <p>while multi-step sampling is also possible since we can compute the next noisy output \(\mathbf{x}_{t-\Delta t}\sim p_{t-\Delta t}(\cdot\vert \mathbf{x}_0)\) using the prescribed conditional probability path at our discretion. Discrete-time CMs depend heavily on the choice of \(\Delta t\) and often require carefully designed annealing schedules. To obtain the noisy sample \(\mathbf{x}_{t-\Delta t}\) at the previous step, one typically evolves backward \(\mathbf{x}_t\) by numerically solving the ODE (\ref{eq:1}), which can introduce additional discretization errors.</p> <p><strong>Continuous CM</strong></p> <p>When using \(d(\mathbf{x}, \mathbf{y}) = ||\mathbf{x} - \mathbf{y}||_2^2\) and taking the limit $\Delta t \to 0$, Song et al.<d-cite key="song2020score"></d-cite> show that the gradient of the discretized CM’s loss with respect to $\theta$ converges to a new objective with no \(\Delta t\) involved.</p> <ul> <li><span style="color: blue; font-weight: bold;">Training</span>: In our notation, the objective is</li> </ul> \[\require{physics} \mathbb{E}_{\mathbf{x}_t, t} \left[ w(t) (f^\theta_{t\to 0})^{\top}(\mathbf{x}_t, t,0) \dv{f^{\theta^-}_{t\to 0}(\mathbf{x}_t, t,0)}{t} \right]\] <p>where \(\require{physics} \dv{f^{\theta^-}_{t\to 0}(\mathbf{x}_t, t,0)}{t} = \nabla_{\mathbf{x}_t} f^{\theta^-}_{t\to 0}(\mathbf{x}_t, t,0) \dv{\mathbf{x}_t}{t} + \partial_t f^{\theta^-}_{t\to 0}(\mathbf{x}_t, t,0)\) is the tangent of \(f^{\theta^-}_{t\to 0}\) at \((\mathbf{x}_t, t)\) along the trajectory of the ODE (\ref{eq:1}). Consistency Trajectory Models (CTMs)<d-cite key="kim2023consistency"></d-cite> extend this objective so that the forward loss (type (a)) becomes globally optimized. In this context, their intuition is that \(f^\theta_{t \to s}(\mathbf{x}_t, t, s)\approx f^\theta_{r \to s}(\texttt{Solver}_{t\to r}(\mathbf{x}_t, t, r), r, s).\) The composition order on the right-hand side depends on the assumption of the solver of the teacher model.</p> <ul> <li><span style="color: orange; font-weight: bold;">Sampling</span></li> </ul> <p>Same as the Discretized Version. CTMs<d-cite key="kim2023consistency"></d-cite> introduce a new sampling method called \(\gamma\)-sampling which controls the noise level of diffusing the intermediate noisy sample according to the conditional probability path during multi-step sampling.</p> <details> <summary>Loss type</summary> Type (b) backward loss, while CTMs<d-cite key="kim2023consistency"></d-cite> optimize type (a) forward loss, both locally and globally. </details> <h3 id="flow-anchor-consistency-model">Flow Anchor Consistency Model</h3> <p>Similar to MeanFlow preliminaries, Flow Anchor Consistency Model (FACM)<d-cite key="peng2025flow"></d-cite> also adopts the linear conditional probability path \(\mathbf{x}_t = (1-t)\mathbf{x}_0 + t\mathbf{x}_1\) with the corresponding default conditional velocity field OT target \(v(\mathbf{x}_t, t \vert \mathbf{x}_0)=\mathbf{x}_1- \mathbf{x}_0.\) In our flow maps notation, FACM parameterizes the model as \(f^\theta_{t\to s}(\mathbf{x}_t, t, 0)= \mathbf{x}_t - tF^\theta_{t\to s}(\mathbf{x}_t, t, 0)\) where \(c_{\text{skip}}(t,s)=1\) and \(c_{\text{out}}(t,s)=-t\).</p> <p>FACM imposes a <strong>consistency property</strong> which requires the total derivative of the consistency function to be zero</p> \[\require{physics} \dv{t}f^\theta_{t \to 0}(\mathbf{x}, t, 0) = 0.\] <p>By substituting the parameterization of FACM, we have</p> \[\require{physics} F^\theta_{t\to 0}(\mathbf{x}_t, t, 0)=v(\mathbf{x}_t, t)-t\dv{F^\theta_{t\to 0}(\mathbf{x}_t, t, 0)}{t}.\] <p>Notice this is equivalent to <a href="#meanflow">MeanFlow</a> where \(s=0\). This indicates CM objective directly forces the network \(F^\theta_{t\to 0}(\mathbf{x}_t, t, 0)\) to learn the properties of an average velocity field heading towards the data distribution, thus enabling the 1-step generation shortcut.</p> <p><span style="color: blue; font-weight: bold;">Training</span>: FACM training algorithm equipped with our flow map notation. Notice that \(d_1, d_2\) are $\ell_2$ with cosine loss<d-footnote>$L_{\cos}(\mathbf{x}, \mathbf{y}) = 1 - \dfrac{\mathbf{x} \cdot \mathbf{y}}{\|\mathbf{x}\|_{2} \, \|\mathbf{y}\|_{2}}$</d-footnote> and norm $\ell_2$ loss<d-footnote>$L_{\text{norm}}(\mathbf{x}, \mathbf{y}) =\dfrac{\|\mathbf{x}-\mathbf{y}\|^2}{\sqrt{\|\mathbf{x}-\mathbf{y}\|^2+c}}$ where $c$ is a small constant. This is a special case of adaptive L2 loss proposed in MeanFlow<d-cite key="geng2025mean"></d-cite>.</d-footnote> respectively, plus reweighting. Interestingly, they separate the training of FM and CM on disentangled time intervals. When training with CM target, we let \(s=0, t\in[0,1]\). On the other hand, we set \(t'=2-t, t'\in[1,2]\) when training with FM anchors.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/diff-distill/facm_training-480.webp 480w,/blog/2025/diff-distill/facm_training-800.webp 800w,/blog/2025/diff-distill/facm_training-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/diff-distill/facm_training.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><span style="color: orange; font-weight: bold;">Sampling</span>: Same as CM.</p> <details> <summary>Loss type</summary> Type (b) backward loss </details> <h3 id="align-your-flow">Align Your Flow</h3> <p>Our notation incorporates a small modification of the flow map introduced by Align Your Flow<d-cite key="sabour2025align"></d-cite>, where we indicate the direction of the distillation. Hence, we say that Align Your Flow (AYF) the continuous-time flow map \(f^{\text{AYF}}(\mathbf{x}_t, t, s)=f_{t\to s}(\mathbf{x}_t, t, s).\) Specifically, AYF selects a tighter set of boundary conditions \(c_{\text{skip}}(t,s)=1\) and \(c_{\text{out}}(t,s)=s-t\).</p> <p><span style="color: blue; font-weight: bold;">Training</span>: The first variant of the objective, called AYF-<strong>Eulerian Map Distillation</strong>, is compatible with both distillation and training from scratch.</p> \[\nabla_\theta \mathbb{E}_{\mathbf{x}_t, t, s}\left[w(t, s)\text{sign}(t - s) \cdot (f^\theta_{t \to s})^\top(\mathbf{x}_t, t, s) \cdot \frac{\text{d}f^{\theta^-}_{t\to s}(\mathbf{x}_t, t, s)}{\text{d}t}\right]\] <p>It is intriguing that this objective reduces to the <a href="#consistency-models">continuous CM</a> objective when \(s=0\), while transforming to original FM objective when \(s\to t\)<d-footnote>The gradient of AYF-EMD matches the gradient of FM objective up to some constant when taking the limit $s\to t$.</d-footnote>. In addition, CTMs<d-cite key="kim2023consistency"></d-cite> uses a discrete consistency loss with a fixed discretized time schedule comparing to AYF-EMD objective. Regarding the second variant, named AYF-<strong>Lagrangian Map Distillation</strong>, it is only applicable to distillation from a pretrained flow model \(F^\delta_{t \to t}(\mathbf{x}_t,t,t)\).</p> \[\nabla_\theta \mathbb{E}_{\mathbf{x}_t, t, s}\left[w(t, s)\text{sign}(s - t) \cdot (f^\theta_{t \to s})^\top \cdot \left(\frac{\text{d}f^{\theta^-}_{t\to s}}{\text{d}s} - F^\delta_{s \to s}((f_{\theta^-}(\mathbf{x}_t, t, s), s,s)\right)\right].\] <p><span style="color: orange; font-weight: bold;">Sampling</span>: Same as CM. A combination of \(\gamma\)-sampling and classifier-free guidance.</p> <p>The formulation of these objectives is majorly built on the Flow Map Matching<d-cite key="boffi2025build"></d-cite>. Similar to the trick in training <a href="#meanflow">Meanflow</a> and <a href="#consistency-models">CMs</a>, they add a <code class="language-plaintext highlighter-rouge">stopgrad</code> operator to the loss to stabilize training and make the objective practical. In their appendix, they provide a detailed proof of why these objectives are equivalent to the objectives in Flow Map Matching<d-cite key="boffi2025build"></d-cite>.</p> <details> <summary>Loss type</summary> Type (b) backward loss for AYF-EMD, type (a) forward loss for AYF-LMD. </details> <h2 id="connections">Connections</h2> <p>Now it is time to connect the dots with some previous existing methods. Let’s frame their objectives in our flow map notation and identify their loss types if possible.</p> <h3 id="shortcut-models">Shortcut Models</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/diff-distill/shortcut_model-480.webp 480w,/blog/2025/diff-distill/shortcut_model-800.webp 800w,/blog/2025/diff-distill/shortcut_model-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/diff-distill/shortcut_model.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> The diagram of Shortcut Models<d-cite key="frans2024one"></d-cite> </div> </div> </div> <p>In essence, Shortcut Models<d-cite key="frans2024one"></d-cite> augment the standard flow matching objective with a self-consistency regularization term. This additional loss component ensures that the learned vector field satisfies a midpoint consistency property: the result of a single large integration step should match the composition of two smaller steps traversing the same portion of the ODE (\ref{eq:1}) trajectory.</p> <p><span style="color: blue; font-weight: bold;">Training</span>: In the training objective, we neglect the input arguments and focus on the core transition between time steps. Again, we elaborate it with our flow map notation.</p> \[\mathbb{E}_{\mathbf{x}_t, t, s}\left[\left\|F^\theta_{t\to t} - \dfrac{\text{d}\mathbf{x}_t}{\text{d}t}\right\|_2^2 + \left\|f^\theta_{t\to s} - f^{\theta^-}_{\frac{t+s}{2}\to s}\circ f^{\theta^-}_{t \to \frac{t+s}{2}}\right\|_2^2\right]\] <p>where we adopt the same flow map conditions based on <a href="#align-your-flow">AYF</a>.</p> <p><span style="color: orange; font-weight: bold;">Sampling</span>: Same with MeanFlow yet with specific shortcut lengths.</p> <details> <summary>Loss type</summary> Type (c) tri-consistency loss </details> <h3 id="reflow">ReFlow</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/diff-distill/rectifiedflow-480.webp 480w,/blog/2025/diff-distill/rectifiedflow-800.webp 800w,/blog/2025/diff-distill/rectifiedflow-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/diff-distill/rectifiedflow.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> The diagram of rectified flow and ReFlow process<d-cite key="liu2022flow"></d-cite> </div> </div> </div> <p>Unlike most ODE distillation methods that learn to jump from \(t\to s\) according to our defined flow map \(f_{t\to s}(\mathbf{x}_t, t, s)\), ReFlow<d-cite key="liu2022flow"></d-cite> takes a different approach by establishing new noise-data couplings so that the new model will generate straighter trajectories.<d-footnote>In the rectified flow paper<d-cite key="liu2022flow"></d-cite>, the straightness of any continuously differentiable process $$Z=\{Z_t\}$$ can be measured by $$S(Z)=\int_0^1\mathbb{E}\|(Z_1-Z_0)-\dot{Z}_t\|^2 dt$$ where $S(Z)=0$ implies the trajectories are perfectly straight.</d-footnote> In this case, this allows the ODE (\ref{eq:1}) to be solved with fewer steps and larger step sizes. To some extent, this resembles the preconditioning from OT-CFM<d-cite key="tong2023improving"></d-cite> where they intentionally sample noise and data pairs jointly from an optimal transport map \(\pi(\mathbf{x}_0, \mathbf{x}_1)\) instead of independent marginals.</p> <p><span style="color: blue; font-weight: bold;">Training</span>: Pair synthesized data from the pretrained model with the noise. Use this new coupling to train a student model with the standard FM objective.</p> <p><span style="color: orange; font-weight: bold;">Sampling</span>: Same as FMs.</p> <h3 id="inductive-moment-matching">Inductive Moment Matching</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/diff-distill/IMM-480.webp 480w,/blog/2025/diff-distill/IMM-800.webp 800w,/blog/2025/diff-distill/IMM-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/diff-distill/IMM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> The diagram of IMM<d-cite key="zhou2025inductive"></d-cite> </div> </div> </div> <p>This recent method<d-cite key="zhou2025inductive"></d-cite> trains our flow map from scratch via matching the distributions of \(f^{\theta}_{t\to s}(\mathbf{x}_t, t, s)\) and \(f^{\theta}_{r\to s}(\mathbf{x}_r, r, s)\) where \(s&lt;r&lt;t\). They adopt an Maximum Mean Discrepancy (MMD) loss to match the distributions.</p> <p><span style="color: blue; font-weight: bold;">Training</span>: In our flow map notation, the training objective becomes</p> \[\mathbb{E}_{\mathbf{x}_t, t, s} \left[ w(t,s) \text{MMD}^2\left(f_{t \to s}(\mathbf{x}_t, t,s), f_{r \to s}(\mathbf{x}_{r}, r,s)\right) \right]\] <p>where \(w(t,s)\) is a weighting function.</p> <p><span style="color: orange; font-weight: bold;">Sampling</span>: Same spirit as <a href="#align-your-flow">AYF</a>.</p> <h2 id="closing-thoughts">Closing Thoughts</h2> <p>The concept of a flow map offers a capable and unifying notation for summarizing the diverse landscape of diffusion distillation methods. Beyond these ODE distillation methods, an intriguing family of approaches pursues a more direct goal: training a one-step generator from the ground up by directly matching the data distribution from the teacher model.</p> <p>The core question is: how can we best leverage a pre-trained teacher model to train a student that approximates the data distribution \(p_{\text{data}}\) in a single shot? With access to the teacher’s flow, several compelling strategies emerge. It becomes possible to directly match the velocity fields, minimize the \(f\)-divergence between the student and teacher output distributions<d-cite key="yin2024improved, xu2025one"></d-cite>, or align their respective score functions<d-cite key="wang2025uni, zhou2024score"></d-cite>.</p> <p>This leads to distinct techniques in practice. For example, adversarial distillation<d-cite key="yin2024improved, sabour2025align"></d-cite> employs a min-max objective to align the two distributions, while other methods like <a href="#inductive-moment-matching">IMM</a> rely on statistical divergences like the Maximum Mean Discrepancy (MMD).</p> <p>In our own work on human motion prediction<d-cite key="fu2025moflowonestep"></d-cite>, we explored this direction by using Implicit Maximum Likelihood Estimation (IMLE). IMLE is a potent, if less common, technique that aligns distributions based purely on their samples, offering a direct and elegant way to distill the teacher’s knowledge without requiring an explicit density function or a discriminator.</p> <p>Diffusion distillation is a dynamic field brimming with potential. The journey from a hundred steps to a single step is not just a technical challenge but a gateway to real-time, efficient generative AI applications.</p>]]></content><author><name>Yuxiang Fu</name></author><category term="generative-models"/><category term="diffusion"/><category term="flow"/><summary type="html"><![CDATA[The explosive growth in one-step and few-step diffusion models has taken the field deep into the weeds of complex notations. In this blog, we cut through the confusion by proposing a coherent set of notations that reveal the connections among these methods.]]></summary></entry><entry><title type="html">On the Permutation Invariance of Graph Generative Models</title><link href="https://dsl-lab.github.io/blog/2025/gen-graph/" rel="alternate" type="text/html" title="On the Permutation Invariance of Graph Generative Models"/><published>2025-08-18T00:00:00+00:00</published><updated>2025-08-18T00:00:00+00:00</updated><id>https://dsl-lab.github.io/blog/2025/gen-graph</id><content type="html" xml:base="https://dsl-lab.github.io/blog/2025/gen-graph/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Graphs are ubiquitous mathematical objects that arise in various domains, such as social networks, protein structures, and chemical molecules. A graph can be formally represented as a set of nodes $V$, optionally associated with node features $X$, and a set of edges $E$. Its topology is commonly expressed using an adjacency matrix $A$.</p> <div class="row mt-2 justify-content-center" style="max-width: 600px; margin-left: auto; margin-right: auto;"> <div class="col-6 col-md-5 mt-1 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/icml_workshop_graph_3-480.webp 480w,/blog/2025/gen-graph/icml_workshop_graph_3-800.webp 800w,/blog/2025/gen-graph/icml_workshop_graph_3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/icml_workshop_graph_3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-6 col-md-5 mt-1 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/icml_workshop_graph_4-480.webp 480w,/blog/2025/gen-graph/icml_workshop_graph_4-800.webp 800w,/blog/2025/gen-graph/icml_workshop_graph_4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/icml_workshop_graph_4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Plain graphs composed of nodes and edges (visuals taken from <d-cite key="icml2024graphs"></d-cite>). </div> <div class="row mt-2"> <div class="col-sm mt-1 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/molecule_jin_20_icml-480.webp 480w,/blog/2025/gen-graph/molecule_jin_20_icml-800.webp 800w,/blog/2025/gen-graph/molecule_jin_20_icml-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/molecule_jin_20_icml.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-1 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/scene_graph_xu_17_cvpr-480.webp 480w,/blog/2025/gen-graph/scene_graph_xu_17_cvpr-800.webp 800w,/blog/2025/gen-graph/scene_graph_xu_17_cvpr-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/scene_graph_xu_17_cvpr.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Molecule graphs <d-cite key="jin2020hierarchical"></d-cite> and scene graphs <d-cite key="xu2017scene"></d-cite> with node and edge features. </div> <p>The goal of graph generative models is to generate novel graph samples that resemble those drawn from the true data distribution. Graphs can be stored in several ways in computational systems, including tree-based structures <d-cite key="shirzad2022td"></d-cite>, SMILES strings (molecule graphs) <d-cite key="weininger1988smiles"></d-cite>, and more commonly, adjacency matrices <d-cite key="hamilton2020graph"></d-cite>. In this post, we focus on the adjacency matrix representation, which is widely used due to its flexibility. Formally, graph generative models learn a distribution $p_\theta$ and generate adjacency matrices $\hat{A} \sim p_\theta$.</p> <h2 id="permutation-symmetry-for-graph-representation-learning">Permutation Symmetry for Graph Representation Learning</h2> <p>Permutation symmetry (i.e., permutation invariance and equivariance) is a fundamental design principle in graph representation learning tasks. Below, we provide a quick recap of the key ideas using resources from <d-cite key="hamilton2020graph"></d-cite>.</p> <p>A straightforward idea for constructing a deep neural network on graphs is to use the adjacency matrix directly as input. For instance, to obtain an embedding of the entire graph, one could flatten the adjacency matrix and pass it through a multi-layer perceptron (MLP):</p> \[\mathbf{z}_G = \text{MLP}({A}[1] \oplus {A}[2] \oplus \dots \oplus {A}[ \vert V \vert]),\] <p>where ${A}[i] \in \mathbb{R}^{\vert V \vert}$ corresponds to the $i$-th row of the adjacency matrix, and $\oplus$ denotes vector concatenation. The drawback of this method is that it relies on the arbitrary ordering of the nodes in the adjacency matrix. Consequently, such a model is not permutation invariant.</p> <p>A fundamental requirement for graph representation learning models is that they should exhibit permutation invariance (or equivariance). Formally, a function $f$ that processes an adjacency matrix ${A}$ should ideally satisfy one of the following conditions:</p> \[\begin{aligned} f({PAP}^\top) &amp;= f({A}) \quad \text{(Permutation Invariance)} \\ f({PAP}^\top) &amp;= {P} f({A}) P^\top \quad \text{(Permutation Equivariance)} \end{aligned}\] <p>where ${P} \in \mathbb{R}^{\vert V \vert \times \vert V \vert}$ represents a permutation matrix <d-cite key="wiki_Permutation_matrix"></d-cite>.</p> <ul> <li><strong>Permutation invariance</strong> implies that the function’s output does not change with different node orderings in the adjacency matrix.</li> <li><strong>Permutation equivariance</strong> means that permuting the adjacency matrix results in a correspondingly permuted output of $f$.</li> </ul> <div class="row mt-2"> <div class="col-sm mt-1 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/icml_workshop_graph_task_5-480.webp 480w,/blog/2025/gen-graph/icml_workshop_graph_task_5-800.webp 800w,/blog/2025/gen-graph/icml_workshop_graph_task_5-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/icml_workshop_graph_task_5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Common graph representation learning tasks include node-level, edge-level, and graph-level tasks (shown from left to right; image credit: <d-cite key="icml2024graphs"></d-cite>). </div> <p>Specifically, node- and edge-level tasks require permutation equivariance, while graph-level tasks require permutation invariance. A well-designed Graph Neural Network (GNN) should generalize across arbitrary permutations of node and edge indices. This ensures that outputs are symmetric with respect to node ordering in the input graph data. It has two key advantages: (i) during training, the model avoids the need to consider all possible node orderings (exhaustive data augmentation), thereby reducing learning complexity and enjoying theoretical benefits <d-cite key="lyle2020benefits,bietti2021sample"></d-cite>; and (ii) at inference, the model generalizes to unseen graphs without ordering bias, since any permutation is handled consistently.</p> <h2 id="rethinking-invariance-principle-for-generative-models">Rethinking Invariance Principle for Generative Models</h2> <p>For graph generative models, permutation symmetry boils down to the invariance of the learned probability distribution. Namely, $p_\theta(\hat{A}) = p_\theta(P \hat{A} P^\top)$ must hold for any valid permutation matrix $P$. Two adjacency matrices related by such a permutation are said to be <strong>isomorphic</strong> <d-cite key="wiki_Graph_isomorphism"></d-cite>. Thus, permutation-invariant graph generative models assign equal probability to any graph belonging to the same isomorphism class. One of the pioneering works that achieves this property is <d-cite key="niu2020permutation"></d-cite>, in the context of score-based (a.k.a. diffusion) generative models.</p> <div class="row mt-2"> <div class="col-sm mt-1 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/prob_perm_invar-480.webp 480w,/blog/2025/gen-graph/prob_perm_invar-800.webp 800w,/blog/2025/gen-graph/prob_perm_invar-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/prob_perm_invar.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Permutation invariance of probability distributions means the likelihood is the same regardless of the node ordering. For example, $p_\theta({A}^{\pi_1}) = p_\theta({A}^{\pi_2}) = p_\theta({A}^{\pi_3}) = p_\theta({A}^{\pi_4}) = \cdots $. </div> <h3 id="invariance-of-probability-distributions">Invariance of Probability Distributions</h3> <blockquote> <p><strong>Theorem 1 (from <d-cite key="niu2020permutation"></d-cite>).</strong> If $ \mathbf{s} : \mathbb{R}^{N \times N} \to \mathbb{R}^{N \times N} $ is a permutation equivariant function, then the scalar function $ f_s = \int_{\gamma[\mathbf{0}, {A}]} \langle \mathbf{s}({X}), \mathrm{d}{X} \rangle_F + C $ is permutation invariant, where $ \langle {A}, {B} \rangle_F = \mathrm{tr}({A}^\top {B}) $ is the Frobenius inner product, $ \gamma[\mathbf{0}, {A}] $ is any curve from $ \mathbf{0} = \{0\}_{N \times N} $ to $ {A} $, and $ C \in \mathbb{R} $ is a constant.</p> </blockquote> <p>We refer readers to <d-cite key="niu2020permutation"></d-cite> for proof details. The implication of this theorem is that the scalar function $f_s$ can characterize the probability density $p_\theta(\cdot)$ up to a constant. This happens when the vector-valued function $\mathbf{s}(\cdot)$ represents the gradient of the log-likelihood, commonly called the (Stein) score function in the context of generative models <d-cite key="song2019generative,song2020score"></d-cite>.</p> <p>Thus, if the learned gradient of the log-likelihood $\mathbf{s}_\theta(A) = \nabla_{A} \log p_\theta(A)$ is permutation equivariant, then the implicitly defined log-likelihood function $\log p_\theta(A)$ is permutation invariant, according to Theorem 1, as given by the line integral of $\mathbf{s}_\theta(A)$:</p> \[\log p_\theta({A}) = \int_{\gamma[0, {A}]} \langle \mathbf{s}_\theta({X}), \mathrm{d} {X} \rangle_F + \log p_\theta(\mathbf{0}).\] <p>Based on this theorem, as long as the score estimation neural network (equivalently, diffusion denoising network) is permutation equivariant, we can prove that the learned probability distribution is permutation invariant. Later works such as GDSS <d-cite key="jo2022score"></d-cite> and DiGress <d-cite key="vignac2022digress"></d-cite> also follow this idea.</p> <div class="row mt-2"> <div class="col-sm mt-1 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/graph_diffusion-480.webp 480w,/blog/2025/gen-graph/graph_diffusion-800.webp 800w,/blog/2025/gen-graph/graph_diffusion-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/graph_diffusion.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The diffusion processes for graph generation using adjacency matrices in the continuous state space. </div> <h3 id="implications-on-scalability">Implications on Scalability</h3> <p>While it is appealing to design a provably permutation invariant graph generative model, we find the empirical implications of this property are not as straightforward as one might expect.</p> <div class="row mt-2"> <div class="col-sm mt-1 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/distribution-480.webp 480w,/blog/2025/gen-graph/distribution-800.webp 800w,/blog/2025/gen-graph/distribution-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/distribution.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Data distribution and target distribution for a 3-node tree graph. For permutation matrix $P_i$ and adjacency matrix $A_i$, filled/blank cells mean one/zero. The probability mass function (PMF) highlights the difference in modes. Our example here also shows graph automorphism (e.g., $P_1$ and $P_2$). </div> <h4 id="theoretical-analysis">Theoretical Analysis</h4> <p>Here we provide a simple example to illustrate the potential challenges of learning permutation invariant graph generative models. As shown in the above figure, the <strong>empirical graph distribution</strong> $p_{\text{data}}$ (i.e., the observed training samples) may only assign a non-zero probability to a single observed adjacency matrix in its isomorphism class.</p> <p>The ultimate goal of a graph generative model is to match this empirical distribution, which may be biased by the observed permutation. However, the <strong>target distribution</strong> that generative models are trained to match may differ from the empirical one, depending on the model design w.r.t. permutation symmetry.</p> <p>For clarity, we define the <strong>effective target distribution</strong> as the closest distribution (e.g., measured in total variation distance) to the empirical data distribution achievable by the generative model, assuming sufficient data and model capacity.</p> <p>Formally, given a training set of adjacency matrices $\{A_i\}_{i=1}^m$ with $N$ nodes , we define the union of their isomorphism classes as $\mathcal{A}^* = \bigcup_{i=1}^m \mathcal{I}_{A_i}$. Each isomorphism class $\mathcal{I}_{A_i}$ represents all adjacency matrices that are topologically equivalent to $A_i$ but may have different matrix representations. The corresponding effective target distribution distribution is</p> \[p_{\text{data}}^*(A) = \frac{1}{Z} \sum_{A^* \in \mathcal{A}^*} \delta(A - A^*),\] <p>where $Z = \vert \mathcal{A}^* \vert = O(n!m)$ is the normalizing constant. Note that $Z = n!m$ may not always be achievable due to graph automorphisms <d-cite key="wiki_Graph_automorphism"></d-cite>.</p> <blockquote> <p><strong>Lemma 2 (from <d-cite key="yan2023swingnn"></d-cite>).</strong> Assume at least one training graph has $\Omega(n!)$ distinct adjacency matrices in its isomorphism class. Let $\mathcal{P}$ denote all discrete permutation-invariant distributions. The closest distributions in $\mathcal{P}$ to $p_{\text{data}}$, measured by total variation, have at least $\Omega(n!)$ modes. If, in addition, we restrict $\mathcal{P}$ to be the set of permutation-invariant distributions such that $p(A_i) = p(A_j) &gt; 0$ for all matrices in the training set $\{A_l\}_{l=1}^m$, then the closest distribution is $\arg\min_{q \in \mathcal{P}} TV(q, p_{\text{data}}) = p_{\text{data}}^*.$</p> </blockquote> <p>Under mild conditions, $p_{\text{data}}^*(A)$ with $O(n!m)$ modes, which is defined above, becomes the effective target distribution, which is the case for permutation invariant models using equivariant networks. In contrast, if we employ a non-equivariant network (i.e., the learned density is not invariant), the effective target distribution becomes $p_{\text{data}}(A)$, which only has $O(m)$ modes. While we discuss the number of modes from a general perspective, the analysis is also relevant to diffusion models <d-footnote> The modes of the Dirac delta target distributions determine the components of the Gaussian mixture models (GMMs) in diffusion models, with each component centered exactly on a target mode. For an invariant model, the GMMs take the form $p_\sigma^*(A) = \frac{1}{Z} \sum_{A^*_i \in \mathcal{A}^*} \mathcal{N}(A; A_i, \sigma^2\mathbf{I}),$ which has an $O(n!)$ factor more components than the non-invariant one. Thus, learning with a permutation-invariant principle is arguably harder than with a non-invariant one, due to the $O(n!)$ surge in both the modes of the target distribution and the number of GMM components at various noise scales. </d-footnote>.</p> <h4 id="empirical-investigation">Empirical Investigation</h4> <p>In practice, we typically observe only one adjacency matrix from each isomorphism class in the training data $\{A_i\}_{i=1}^m$. By applying permutation $n!$ times, one can construct $p_{\text{data}}^*$ (invariant distribution) from $p_{\text{data}}$ (non-invariant distribution).</p> <p>We define a trade-off distribution, called the <strong>$l$-permuted empirical distribution</strong>:</p> \[p_{\text{data}}^l(A) = \frac{1}{ml} \sum_{i=1}^{m} \sum_{j=1}^{l} \delta(A - P_j A_i P_j^{\top}),\] <p>where $P_1, \ldots, P_l$ are $l$ distinct permutation matrices. The construction of $p_{\text{data}}^l$ has the following properties: (1) $p_{\text{data}}^l$ has $O(lm)$ modes governed by $l$; (2) With proper permutations, $p_{\text{data}}^l = p_{\text{data}}$ when $l=1$; (3) $p_{\text{data}}^l \approx p_{\text{data}}^*$ when $l=n!$ (identical if no non-trivial automorphisms). We use $p_{\text{data}}^l$ as the diffusion model’s target by tuning $l$ to study the impact of mode count on empirical performance.</p> <p>The experimental setup is as follows. We use 10 random regular graphs with 16 nodes, with degrees in $[2, 11]$. The parameter $l$ ranges from 1 to 500, and all models are trained to convergence. For baselines, we consider <strong>invariant models</strong> for $p_{\text{data}}^*$: DiGress <d-cite key="vignac2022digress"></d-cite> and PPGN <d-cite key="maron2019provably"></d-cite> (a highly-expressive 3WL-discriminative GNN <d-footnote> The original PPGN model was proposed for graph representation learning. We reimplemented it based on the official codebase <d-cite key="maron2019provably"></d-cite> to adapt to the diffusion objective. </d-footnote>). For <strong>non-invariant models</strong> (corresponding to $p_{\text{data}}^l, \, l &lt; n!$), we evaluate PPGN with index-based positional embeddings and SwinGNN (ours) <d-cite key="yan2023swingnn"></d-cite>. We measure <strong>recall</strong>, defined as the proportion of generated graphs that are isomorphic to any training graph. Recall lies in the range of $[0,1]$, requires isomorphism testing for computation, and is permutation-invariant on its own. A higher recall indicates a stronger ability to capture the toy data distribution.</p> <div class="row mt-2"> <div class="col-sm mt-1 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/novelty_dataset2-480.webp 480w,/blog/2025/gen-graph/novelty_dataset2-800.webp 800w,/blog/2025/gen-graph/novelty_dataset2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/novelty_dataset2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Quantitative results on the $l$-permuted empirical distribution. Invariant models perform significantly worse than non-invariant models when the number of applied permutations ($l$) is small. </div> <p>As shown in the plot above, invariant models such as DiGress and PPGN consistently fail to achieve high recall. In contrast, non-invariant models perform exceptionally well when $l$ is small, where only a few permutations are imposed, but their sample quality degrades significantly as $l$ increases, reflecting the difficulty of learning from distributions with many modes. Importantly, in practice, one typically sets $l=1$ for non-invariant models, which often leads to empirically stronger performance than their invariant counterparts.</p> <h3 id="post-processing-to-reclaim-sample-invariance">Post-processing to Reclaim Sample Invariance</h3> <p>While non-invariant models often perform better empirically, they cannot guarantee permutation-invariant sampling. To bridge this gap, we propose a simple and provable trick: apply a random permutation to each generated sample, which yields invariant sampling at no extra cost.</p> <blockquote> <p><strong>Lemma 3 (from <d-cite key="yan2023swingnn"></d-cite>).</strong> Let $A$ be a random adjacency matrix distributed according to any graph distribution on $n$ vertices. Let $P_r \sim \mathrm{Unif}(\mathcal{S}_n)$ be uniform over the set of permutation matrices. Then, the induced distribution of the random matrix $A_r = P_r A P_r^{\top}$, denoted as $q_\theta(A_r)$, is permutation invariant, i.e., $q_\theta(A_r) = q_\theta(P A_r P^{\top}), \forall P \in \mathcal{S}_n$.</p> </blockquote> <p>This trick applies to all generative models. Importantly, the random permutation preserves the isomorphism class: $q_\theta$ is invariant but covers the same set of isomorphism classes as $p_\theta$. Thus, graphs from $q_\theta$ always have isomorphic counterparts under $p_\theta$.</p> <p>In summary, there are two key observations: (1) invariant models ensure invariant sampling but may harm empirical performance, and (2) invariant sampling does not require invariant models.</p> <h3 id="additional-experimental-results">Additional Experimental Results</h3> <p>Motivated by the aforementioned analysis, we design a new diffusion model that combines non-invariant objectives with invariant sampling to better capture graph distributions.</p> <details> <summary>click here for more details on model design</summary> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/model-480.webp 480w,/blog/2025/gen-graph/model-800.webp 800w,/blog/2025/gen-graph/model-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/model.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Overall architecture of the proposed model. </div> We propose an efficient high-order graph transformer, SwinGNN <d-cite key="yan2023swingnn"></d-cite>, for graph diffusion. Drawing inspiration from $k$-order and $k$-WL GNNs <d-cite key="morris2019weisfeiler"></d-cite>, SwinGNN approximates the expressive 2-WL message passing to enhance graph isomorphism testing and function approximation capacity. To address the computational complexity of $O(n^4)$ in 2-WL GNNs, SwinGNN employs a transformer with window-based self-attention <d-cite key="liu2021swin"></d-cite>, treating edge values as tokens and reducing complexity to $O(n^2M^2)$ by confining attention to local $M \times M$ windows. A shifted window technique further enables cross-window interactions. Additionally, SwinGNN incorporates multi-scale edge representation learning through channel mixing-based downsampling and upsampling layers, constructing hierarchical graph representations to capture long-range interactions efficiently. Experimental results demonstrate its superior performance in graph generation tasks. </details> <div class="row mt-2"> <div class="col-sm mt-1 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/qualitative_result-480.webp 480w,/blog/2025/gen-graph/qualitative_result-800.webp 800w,/blog/2025/gen-graph/qualitative_result-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/qualitative_result.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Qualitative comparison between invariant and non-invariant models. </div> <p>From the qualitative results, especially on the grid dataset, we can clearly see the difference between the non-invariant and invariant models, compared with then-SOTA models GRAN <d-cite key="liao2019efficient"></d-cite>, GDSS <d-cite key="jo2022score"></d-cite>, and ours.</p> <p>We also show the models’ superiority on the quantitative results on more synthetic and real-world datasets. The metrics are computed by maximum mean discrepancy (MMD) metrics characterizing graph structure properties, such as degree distributions. Please refer to the expandable box below and the original paper <d-cite key="yan2023swingnn"></d-cite> for more details.</p> <div class="row mt-2"> <div class="col-sm mt-1 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/quantitative_result_1-480.webp 480w,/blog/2025/gen-graph/quantitative_result_1-800.webp 800w,/blog/2025/gen-graph/quantitative_result_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/quantitative_result_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Quantitative comparison between invariant and non-invariant models. </div> <details> <summary>click here for more quantitative results</summary> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/quantitative_result_2-480.webp 480w,/blog/2025/gen-graph/quantitative_result_2-800.webp 800w,/blog/2025/gen-graph/quantitative_result_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/quantitative_result_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> More quantitative results on synthetic and real-world graph datasets. Table 2 demonstrates further results on larger graph datasets. Table 3 shows results on molecule datasets using domain-specific metrics. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/gen-graph/diffusesg_2-480.webp 480w,/blog/2025/gen-graph/diffusesg_2-800.webp 800w,/blog/2025/gen-graph/diffusesg_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/gen-graph/diffusesg_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> We apply non-invariant models on the scene graph generation task as well and show consistent scene-graph-to-image pair generation results. Please refer to <d-cite key="xu2024joint"></d-cite> for more details. </div> </details> <h2 id="discussion-with-recent-works">Discussion with Recent Works</h2> <p>It is interesting to see concurrent works adopting similar principles or arrive at similar findings regarding the permutation invariance property for generative models in the graph domain.</p> <p>For instance, AlphaFold 3 (2024) <d-cite key="abramson2024accurate"></d-cite> from DeepMind employs a non-equivariant diffusion model architecture to predict properties of complex proteins. We quote from their paper:</p> <blockquote style="font-size: 0.95em;"> The diffusion module operates directly on raw atom coordinates, and on a coarse abstract token representation, <b>without rotational frames or any equivariant processing</b>. </blockquote> <p>AlphaFold 3 indeed applies data augmentation to encourage equivariance but does not impose this condition through network design.</p> <p>Similarly, DiffAlign <d-cite key="laabid2024equivariant"></d-cite>, published in ICLR 2025, also discards the equivariance property for diffusion models on the retrosynthesis task and shows improved performance. From a theoretical perspective, they use copying graphs as a case study to illustrate the limitations of equivariance. Both works provide further empirical evidence that permutation invariance should not simply be taken for granted in generative models.</p> <p>More interestingly, research from the optimization perspective also addresses this problem and provides fresh insights, studying the relationship between intrinsic equivariance and data augmentation <d-cite key="nordenfors2023optimization, nordenfors2025data"></d-cite>.</p> <h2 id="summary">Summary</h2> <p>This post examines the role of permutation invariance in <strong>graph generative models</strong>. While symmetry is essential in <strong>graph representation learning</strong>, enforcing it in generative models can make learning harder by introducing exponentially many modes. Empirical results show that non-invariant models often outperform invariant ones, especially with limited permutations. A simple post-processing trick—random permutation—restores invariant sampling without requiring invariant model design. Building on this, we propose non-invariant graph generative models that achieve strong performance on synthetic and real-world datasets <d-cite key="yan2023swingnn, xu2024joint"></d-cite>. Recent works like AlphaFold 3 <d-cite key="abramson2024accurate"></d-cite> and DiffAlign <d-cite key="laabid2024equivariant"></d-cite> further support the view that permutation invariance should not be taken for granted for generative models in the graph domain. It appears more rigorous theoretical analysis is needed to understand the relationship between permutation invariance and the performance of generative models.</p>]]></content><author><name>Qi Yan</name></author><category term="graph"/><category term="permutation-invariance"/><category term="generative-models"/><summary type="html"><![CDATA[This blog post discusses the permutation invariance principle of graph generative models, which has often been taken for granted in graph-related tasks. While permutation symmetry is an elegant property of graph data, there is still more to learn about its empirical implications.]]></summary></entry><entry><title type="html">Conditional Generative Models for Motion Prediction</title><link href="https://dsl-lab.github.io/blog/2025/cogen-motion/" rel="alternate" type="text/html" title="Conditional Generative Models for Motion Prediction"/><published>2025-08-17T00:00:00+00:00</published><updated>2025-08-17T00:00:00+00:00</updated><id>https://dsl-lab.github.io/blog/2025/cogen-motion</id><content type="html" xml:base="https://dsl-lab.github.io/blog/2025/cogen-motion/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Needless to say, diffusion-based generative models (equivalently, flow matching models) are amazing inventions. They have shown great capacity to produce high-quality images, videos, audios and more, whether being unconditional on the benchmark datasets and conditioned on certain content in the wild. In this blog, we discuss a relatively less explored application of <strong>generative models for motion prediction</strong>, which is a fundamental problem in many applications such as autonomous driving and robotics.</p> <p>In a nutshell, motion prediction is the task of predicting the future trajectories of objects given their past trajectories, plus all sorts of available context information such as surrounding objects and high-fidelity maps. <br/> The said pipeline implemented by neural networks is simply:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Past Trajectory + Context Information ---&gt; Neural Network ---&gt; Future Trajectory
</code></pre></div></div> <p>To produce meaningful future trajectories, we condition the generative models on the past trajectory and the context information. Borrowed from our paper <d-cite key="fu2025moflow"></d-cite>, the pipeline looks like this:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/cogen-motion/noise_to_traj_moflow-480.webp 480w,/blog/2025/cogen-motion/noise_to_traj_moflow-800.webp 800w,/blog/2025/cogen-motion/noise_to_traj_moflow-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/cogen-motion/noise_to_traj_moflow.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The pipeline of motion prediction using conditional (denoising) generative models <d-cite key="fu2025moflow"></d-cite>. </div> <p>The early datasets on human motion prediction mostly do not come with heavy context information, such as the well-known ETH-UCY and the SDD datasets (see more for summarization at <d-cite key="ivanovic2023trajdata"></d-cite>), which the above figure accurately depicts. However, modern industry-standard datasets such as the Waymo Open Motion Dataset <d-cite key="ettinger2021large"></d-cite> and the Argoverse series datasets <d-cite key="wilson2023argoverse, chang2019argoverse"></d-cite> come with much richer context information, such as high-fidelity maps and other rich context information, which need more compute to process. No matter how complex the context information is, the generative model must be guided to <strong>produce spatially and temporally coherent trajectories consistent with the past</strong>.</p> <h2 id="challenges-of-multi-modal-prediction">Challenges of Multi-Modal Prediction</h2> <p>Motion <em>prediction</em>, as the name suggests, is inherently a forecasting task. For each input in a dataset, only one realization of the future motion is recorded, even though multiple plausible outcomes often exist. This mismatch between the inherently <strong>multi-modal</strong> nature of future motion and the <strong>single ground-truth</strong> annotation poses a core challenge for evaluation.</p> <p>In practice, standard metrics require models to output multiple trajectories, which are then compared against the observed ground truth. For example, <strong>ADE (Average Displacement Error)</strong> and <strong>FDE (Final Displacement Error)</strong> measure trajectory errors, and the minimum ADE/FDE across predictions is typically reported. This setup implicitly encourages models to produce diverse hypotheses, but only rewards the one closest to the recorded future. Datasets such as Waymo Open Motion <d-cite key="ettinger2021large"></d-cite> and Argoverse <d-cite key="wilson2023argoverse, chang2019argoverse"></d-cite> extend evaluation with metrics targeting uncertainty calibration. For instance, Waymo’s <strong>mAP</strong> rewards models that assign higher confidence to trajectories closer to the ground truth.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/cogen-motion/vehicle_1_trajflow-480.webp 480w,/blog/2025/cogen-motion/vehicle_1_trajflow-800.webp 800w,/blog/2025/cogen-motion/vehicle_1_trajflow-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/cogen-motion/vehicle_1_trajflow.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Multi-modal trajectory forecasting made by TrajFlow <d-cite key="yan2025trajflow"></d-cite> on the Waymo Open Motion Dataset <d-cite key="ettinger2021large"></d-cite>. Multiple predictions are visualized using different colors, while the single ground truth is shown in red. </div> <p>The strong dependency of current evaluation metrics on a single ground truth, assessed instance by instance, poses a particular challenge for generative models. Although the task inherently requires generating diverse trajectories, models are only rewarded when one of their outputs happens to align closely with the recorded ground truth.</p> <p>As a result, the powerful ability of generative models to produce diverse samples from noise <d-cite key="ho2020denoising, lipman2022flow"></d-cite> does not necessarily translate into better performance under current metrics. For example, MotionDiffuser <d-cite key="jiang2023motiondiffuser"></d-cite>, a diffusion-based model that generates one trajectory at a time, requires a complex post-processing pipeline—ranging from likelihood-based filtering to hand-crafted attractor/repeller cost functions and non-maximum suppression (NMS) for outlier removal—in order to achieve reasonably good results.</p> <h2 id="engineering-practices-and-lessons">Engineering Practices and Lessons</h2> <p>Now let’s dive into the technical side of the problem. In the forward process of flow matching, we adopt a simple linear interpolation between the clean trajectories \(Y^1 \sim q\), where \(q\) is the data distribution, and pure Gaussian noise \(Y^0 \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\):</p> \[Y^t = (1-t)Y^0 + tY^1 \qquad t \in [0, 1].\] <p>The reverse process, which allows us to generate new samples, is governed by the ordinary differential equations (ODEs):</p> \[\mathrm{d} Y^t = v_\theta(Y^t, t, C)\mathrm{d}t,\] <p>where \(v_\theta\) is the parametrized vector field approximating the straight flow \(U^t = Y^1 - Y^0\). Here, \(C\) denotes the aggregated contextual information of agents in a scene, including the past trajectory and any other available context information.</p> <h3 id="data-space-predictive-learning-objectives">Data-Space Predictive Learning Objectives</h3> <p>From an engineering standpoint, a somewhat <strong>bitter lesson</strong> we encountered is that <strong>existing predictive learning objectives remain remarkably strong</strong>. Despite the appeal of noise-prediction formulations (e.g., $\epsilon$-prediction introduced in DDPM <d-cite key="ho2020denoising"></d-cite> and later adopted in flow matching <d-cite key="lipman2022flow"></d-cite>), straightforward predictive objectives in the data space—such as direct \(\hat{x}_0\) reconstruction in DDPM notation<d-footnote> Note that we follow the flow matching notations in <d-cite key="lipman2022flow"></d-cite> to use $t=1$ as the data distribution and $t=0$ as the noise distribution, which is opposite to the original DDPM notations in <d-cite key="ho2020denoising"></d-cite>.</d-footnote>—consistently yields more stable convergence.</p> <p>Concretely, by rearranging the original linear flow objective, we define a neural network</p> \[D_\theta := Y^t + (1-t)v_\theta(Y^t, C, t),\] <p>which is trained to recover the future trajectory \(Y^1\) in the data space. The corresponding objective is:</p> \[\mathcal{L}_{\text{FM}} = \mathbb{E}_{Y^t, Y^1 \sim q, \, t \sim \mathcal{U}[0,1]} \left[ \frac{\| D_{\theta}(Y^t, C, t) - Y^1 \|_2^2}{(1 - t)^2} \right].\] <p>Our empirical observation is that data-space predictive learning objectives outperform denoising objectives. We argue that this is largely influenced by the current evaluation protocol, which heavily rewards model outputs that are close to the ground truth.</p> <p>During training, the original denoising target matches the vector field $Y^1 - Y^0$, defined as the difference between the data sample (future trajectory) and the noise sample (drawn from the noise distribution). Under the current proximity-based metrics, this objective is harder to optimize than the predictive objective because of the stochasticity introduced by $Y^0$, as the metrics do not adequately reward diverse forecasting. Moreover, during the sampling process, small errors in the vector field model $v_\theta$—measured with respect to the single ground-truth velocity field at intermediate time steps—can be amplified through subsequent iterative steps. Consequently, increasing inference-time compute may not necessarily improve results without incorporating regularization from the data-space loss <d-footnote> Interestingly, in our experiments, we found that flow-matching ODEs—thanks to their less noisy inference process—usually perform more stably than diffusion-model SDEs, which is surprising. In image generation, as shown in SiT <d-cite key="ma2024sit"></d-cite>, ODE-based samplers are generally weaker than SDE-based samplers. </d-footnote>.</p> <h3 id="joint-multi-modal-learning-losses">Joint Multi-Modal Learning Losses</h3> <p>Building on this, another key engineering practice was to introduce <strong>joint multi-modal learning losses</strong>. Our network \(D_\theta\) generates \(K\) scene-level correlated waypoint predictions \(\{S_i\}_{i=1}^K\) along with classification logits \(\{\zeta_i\}_{i=1}^K\)<d-footnote> Usually, different datasets have different conventions for what a proper $K$ should be. For example, $K=20$ is used for the ETH-UCY dataset, while $K=6$ is used for the Waymo Open Motion Dataset <d-cite key="ettinger2021large"></d-cite>. </d-footnote>. This allows us to capture diverse futures in a single inference loop while still grounding learning in a predictive loss. Such a principle of combined regression and classification losses to encourage trajectory multi-modality is ubiquitous in the motion prediction literature, as seen in MTR <d-cite key="shi2022motion"></d-cite>, UniAD <d-cite key="hu2023planning"></d-cite>, and QCNet <d-cite key="zhou2023query"></d-cite>, though these methods differ in other implementation details. For simplicity, we omit the time-dependent weighting and define the multi-modal flow matching loss:</p> \[\bar{\mathcal{L}}_{\text{FM}} = \mathbb{E}_{Y^t, Y^1 \sim q, \, t \sim \mathcal{U}[0,1]} \left[ \| S_{j^*} - Y^1 \|_2^2 + \text{CE}(\zeta_{1:K}, j^*) \right],\] <p>where \(j^* = \arg\min_{j} \| S_j - Y^1 \|_2^2\) indicates the closest waypoint to the ground-truth trajectory and \(\text{CE}(\cdot,\cdot)\) denotes cross-entropy. On tasks where confidence calibration is important, such as those measured by the mAP metric in the Waymo Open Motion Dataset, we refer readers to our paper <d-cite key="yan2025trajflow"></d-cite> for further details on uncertainty calibration.</p> <p>We acknowledge that some prior works, such as MotionLM <d-cite key="seff2023motionlm"></d-cite> and MotionDiffuser <d-cite key="jiang2023motiondiffuser"></d-cite>, generate one trajectory at a time and have demonstrated strong performance. However, since these methods are not open-sourced, we are unable to conduct direct comparisons or measure their runtime efficiency. We conjecture that requiring multiple inference loops (tens to hundreds) is considerably slower than our one-step generator—particularly on smaller-scale datasets, where the one-step approach achieves comparable performance without significant degradation.</p> <h2 id="exploring-inference-acceleration">Exploring Inference Acceleration</h2> <p>To accelerate inference in flow-matching models, which typically require tens or even hundreds of iterations for ODE simulation, we adopt an underrated idea from the image generation literature: conditional <strong>IMLE (implicit maximum likelihood estimation)</strong> <d-cite key="li2018implicit, li2019diverse"></d-cite>. IMLE provides a way to distill an iterative generative model into a <strong>one-step generator</strong>.</p> <p>The IMLE family consists of generative models designed to produce diverse samples in a single forward pass, conceptually similar to the generator in GANs <d-cite key="goodfellow2020generative"></d-cite>. In our setting, we construct a conditional IMLE model that takes the same context \(C\) as the teacher flow-matching model and learns to match the teacher’s motion prediction results directly in the data space.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/cogen-motion/imle_moflow-480.webp 480w,/blog/2025/cogen-motion/imle_moflow-800.webp 800w,/blog/2025/cogen-motion/imle_moflow-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/cogen-motion/imle_moflow.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Pipeline of the IMLE distillation process in our work <d-cite key="fu2025moflow"></d-cite>. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/cogen-motion/IMLE_algorithm-480.webp 480w,/blog/2025/cogen-motion/IMLE_algorithm-800.webp 800w,/blog/2025/cogen-motion/IMLE_algorithm-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2025/cogen-motion/IMLE_algorithm.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>The IMLE distillation process is summarized in <code class="language-plaintext highlighter-rouge">Algorithm 1</code>. Lines 4–6 describe the standard ODE-based sampling of the teacher model, which produces $K$ correlated multi-modal trajectory predictions \(\hat{Y}^1_{1:K}\) conditioned on the context $C$. A conditional IMLE generator $G_\phi$ then uses a noise vector $Z$ and context $C$ to generate $K$-component trajectories $\Gamma$, matching the shape of \(\hat{Y}^1_{1:K}\).</p> <p>Unlike direct distillation, the conditional IMLE objective generates <strong>more</strong> samples than those available in the teacher’s dataset for the same context $C$. Specifically, $m$ i.i.d. samples are drawn from $G_\phi$, and the one closest to the teacher prediction \(\hat{Y}^1_{1:K}\) is selected for loss computation. This nearest-neighbor matching ensures that the teacher model’s modes are faithfully captured.</p> <p>To preserve trajectory multi-modality, we employ the Chamfer distance <d-cite key="fan2017point"></d-cite> $d_{\text{Chamfer}}(\hat{Y}^1, \Gamma)$ as our loss function:</p> \[\mathcal{L}_{\text{IMLE}}(\hat{Y}^1_{1:K}, \Gamma) = \dfrac{1}{K} \left( \sum_{i=1}^K \min_j \|\hat{Y}^1_i - \Gamma^{(j)}\| + \sum_{j=1}^K \min_i \|\hat{Y}^1_i - \Gamma^{(j)}\| \right)\] <p>where $\Gamma^{(i)} \in \mathbb{R}^{A \times 2T_f}$ is the $i$-th component of the IMLE-generated correlated trajectory.</p> <p>Nonetheless, the acceleration of diffusion-based models—particularly through distillation—is evolving rapidly. Our work with IMLE is just one attempt in this direction, and we are actively exploring further improvements to extend its applicability to broader domains.</p> <h2 id="summary">Summary</h2> <p>We reviewed the challenges and engineering insights gained from developing conditional generative models for motion prediction, primarily drawing on our previous works <d-cite key="fu2025moflow, yan2025trajflow"></d-cite>. The task requires generating diverse trajectories, yet common evaluation metrics such as ADE and FDE primarily reward alignment with a single ground-truth trajectory.</p> <p>From these experiences, we identified two useful engineering practices:</p> <ul> <li>Data-space predictive learning objectives outperform denoising-based approaches, leading to more stable convergence.</li> <li>Joint multi-modal learning losses that integrate regression and classification more effectively capture trajectory diversity.</li> </ul> <p>In addition, we explored the IMLE distillation technique to accelerate inference by compressing iterative processes into a one-step generator, while preserving multi-modality through Chamfer distance losses.</p>]]></content><author><name>Qi Yan</name></author><category term="motion-prediction"/><category term="trajectory"/><category term="generative-models"/><summary type="html"><![CDATA[In this blog post, we discuss good engineering practices and the lessons learned—sometimes the hard way—from building conditional generative models (in particular, flow matching) for motion prediction problems.]]></summary></entry><entry><title type="html">Evaluating Motion Consistency by Fréchet Video Motion Distance (FVMD)</title><link href="https://dsl-lab.github.io/blog/2024/fvmd-2/" rel="alternate" type="text/html" title="Evaluating Motion Consistency by Fréchet Video Motion Distance (FVMD)"/><published>2024-06-30T00:00:00+00:00</published><updated>2024-06-30T00:00:00+00:00</updated><id>https://dsl-lab.github.io/blog/2024/fvmd-2</id><content type="html" xml:base="https://dsl-lab.github.io/blog/2024/fvmd-2/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Recently, diffusion models have demonstrated remarkable capabilities in high-quality image generation. This advancement has been extended to the video domain, giving rise to text-to-video diffusion models, such as <a href="https://pika.art/home">Pika</a>, <a href="https://research.runwayml.com/gen2">Runway Gen-2</a>, and <a href="https://openai.com/index/sora/">Sora</a> <d-cite key="videoworldsimulators2024"></d-cite>.</p> <p>Despite the rapid development of video generation models, research on evaluation metrics for video generation remains insufficient (see more discussion on our <a href="https://dsl-lab.github.io/blog/2024/fvmd-1/">blog</a>). For example, FID-VID <d-cite key="balaji2019conditional"></d-cite> and FVD <d-cite key="unterthiner2018towards"></d-cite> are commonly used video metrics. FID-VID focuses on visual quality by comparing synthesized <em>frames</em> to real ones, ignoring motion quality. FVD adds temporal coherence by using features from a <em>pre-trained action recognition model</em>, Inflated 3D Convnet (I3D) <d-cite key="carreira2017quo"></d-cite>. Recently, VBench <d-cite key="huang2023vbench"></d-cite> introduces a 16-dimensional evaluation suite for text-to-video generative models. However, VBench’s protocols for temporal consistency, like temporal flickering and motion smoothness, favor videos with smooth or static movement, <em>neglecting high-quality videos with intense motion</em>, such as dancing and sports videos.</p> <p>Simply put, there is a lack of metrics <strong>specifically designed to evaluate the complex motion patterns in generated videos</strong>. The Fréchet Video Motion Distance (FVMD) addresses this gap.</p> <p>The code is available at <a href="https://github.com/DSL-Lab/FVMD-frechet-video-motion-distance">GitHub</a>.</p> <h2 id="fréchet-video-motion-distance-fvmd">Fréchet Video Motion Distance (FVMD)</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/pipeline-480.webp 480w,/blog/2024/fvmd/pipeline-800.webp 800w,/blog/2024/fvmd/pipeline-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/pipeline.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The overall pipeline of the Fréchet Video Motion Distance (FVMD) that measures the discrepancy in motion features between generated videos and ground-truth videos. </div> <p>The core idea of FVMD is to measure temporal motion consistency based on <strong>the patterns of velocity and acceleration in video movements</strong>. First, motion trajectories of key points are extracted using the pre-trained model PIPs++ <d-cite key="zheng2023pointodyssey"></d-cite>, and their velocity and acceleration are computed across frames. Motion features are then derived from the statistics of these vectors. Finally, the similarity between the motion features of generated and ground truth videos is measured using the Fréchet distance <d-cite key="dowson1982frechet"></d-cite>.</p> <h3 id="video-key-points-tracking">Video Key Points Tracking</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/tracking_demo_1-480.webp 480w,/blog/2024/fvmd/tracking_demo_1-800.webp 800w,/blog/2024/fvmd/tracking_demo_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/tracking_demo_1.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/tracking_demo_2-480.webp 480w,/blog/2024/fvmd/tracking_demo_2-800.webp 800w,/blog/2024/fvmd/tracking_demo_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/tracking_demo_2.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Key point tracking results on the TikTok datasets <d-cite key="jafarian2022self"></d-cite> using PIPs++ <d-cite key="zheng2023pointodyssey"></d-cite>. </div> <p>To construct video motion features, key point trajectories are first tracked across the video sequence using PIPs++. For a set of $m$ generated videos, denoted as $\lbrace X^{(i)} \rbrace_{i=1}^m$, the tracking process begins by truncating longer videos into segments of $F$ frames with an overlap stride of $s$. For simplicity, segments from different videos are put together to form a single dataset $\lbrace x_{i} \rbrace_{i=1}^n$. Then, $N$ evenly-distributed target points in a grid shape are queried on the initial frames <d-footnote> For example, $F=16, s=1, N=400$ are used as default parameters to extract consecutive short segments.</d-footnote> and their trajectories are estimated across the video segments, resulting in a tensor $\hat{Y} \in \mathbb{R}^{F \times N \times 2}$.</p> <h3 id="key-points-velocity-and-acceleration-fields">Key Points Velocity and Acceleration Fields</h3> <p>FVMD proposes using the velocity and acceleration fields across frames to represent video motion patterns. The <strong>velocity field</strong> $\hat{V} \in \mathbb{R}^{F \times N \times 2}$ measures the first-order difference in key point positions between consecutive frames with zero-padding:</p> \[\hat{V} = \texttt{concat}(\boldsymbol{0}_{N\times 2}, \hat{Y}_{2:F} - \hat{Y}_{1:F-1}) \in \mathbb{R}^{F \times N \times 2},\] <p>The <strong>acceleration field</strong> $\hat{A} \in \mathbb{R}^{F \times N \times 2}$ is calculated by taking the first-order difference between the velocity fields in two consecutive frames, also with zero-padding:</p> \[\hat{A} = \texttt{concat}(\boldsymbol{0}_{N\times 2}, \hat{V}_{2:F} - \hat{V}_{1:F-1}) \in \mathbb{R}^{F \times N \times 2}.\] <h3 id="motion-feature">Motion Feature</h3> <p>To obtain compact motion features, the velocity and acceleration fields are further processed into <strong>spatial and temporal statistical histograms</strong>.</p> <p>First, the <em>magnitude and angle</em> for each tracking point in the velocity and acceleration vector fields are computed respectively. Let $\rho(U)$ and $\phi(U)$ denote the magnitude and angle of a vector field $U$, where $U \in \mathbb{R}^{F \times N \times 2}$ and $U$ can be either $\hat{V}$ or $\hat{A}$.</p> \[\begin{aligned} \rho(U)_{i, j} &amp;= \sqrt{U_{i,j,1}^2 + U_{i,j,2}^2}, &amp;\forall i \in [F], j \in [N], \\ \phi(U)_{i, j} &amp;= \left| \tanh^{-1}\left(\frac{U_{i, j,1}}{U_{i, j,2}}\right) \right|, &amp;\forall i \in [F], j \in [N]. \end{aligned}\] <p>Then, FVMD quantizes magnitudes and angles into discrete bins (8 for angles and 9 for magnitudes), which are then used to construct statistical histograms and extract motion features. It adopts <strong>dense 1D histograms</strong> <d-footnote>The 1D histogram approach is inspired by the HOG (Histogram of Oriented Gradients) approach <d-cite key="dalal2005histograms"></d-cite>, which counts occurrences of gradient orientation in localized portions of an image.</d-footnote> by aggregating magnitude values into 1D histograms corresponding to the quantized angles. Specifically, the $F$-frame video segments are divided into smaller volumes of size $f \times k \times k$, where $f$ is the number of frames and $k$ the number of tracking points. Within each small volume, every tracking point’s magnitude is summed into its corresponding angle bin, resulting in an 8-point histogram per volume. Eventually, the histograms from all volumes are combined to form the final motion feature <d-footnote>The shape of the dense 1D histogram is $ \lfloor \frac{F}{f} \rfloor \times \lfloor \frac{\sqrt{N}}{k} \rfloor \times \lfloor \frac{\sqrt{N}}{k} \rfloor \times 8$.</d-footnote>.</p> <p>Dense 1D histograms are used for <strong>both velocity and acceleration fields</strong>, and the resulting features are concatenated to form a combined motion feature for computing similarity. </p> <details> <summary>click here for 2D histogram construction</summary> FVMD also explores quantized 2D histograms but opts to use the dense 1D histograms for the default configuration due to their superior performance. In this approach, the corresponding vector fields of each volume are aggregated to form a 2D histogram, where $x$ and $y$ coordinates represent magnitudes and angles, respectively. The 2D histograms from all volumes are then concatenated and flattened into a vector to serve as the motion feature. The shape of the quantized 2D histogram is $ \lfloor \frac{F}{f} \rfloor \times \lfloor \frac{\sqrt{N}}{k} \rfloor \times \lfloor \frac{\sqrt{N}}{k} \rfloor \times 72$, where the number 72 is derived from 8 discrete bins for angle and 9 bins for magnitude. </details> <h3 id="visualizations">Visualizations</h3> <p>If two videos are of very different quality, their histograms should look very <em>different</em> to serve as a discriminative motion feature. Let’s take a look at what they look like for the videos in real life.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/gt-480.webp 480w,/blog/2024/fvmd/gt-800.webp 800w,/blog/2024/fvmd/gt-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/gt.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/disco-480.webp 480w,/blog/2024/fvmd/disco-800.webp 800w,/blog/2024/fvmd/disco-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/disco.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/anyone-480.webp 480w,/blog/2024/fvmd/anyone-800.webp 800w,/blog/2024/fvmd/anyone-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/anyone.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/gt_tracking-480.webp 480w,/blog/2024/fvmd/gt_tracking-800.webp 800w,/blog/2024/fvmd/gt_tracking-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/gt_tracking.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/disco_tracking-480.webp 480w,/blog/2024/fvmd/disco_tracking-800.webp 800w,/blog/2024/fvmd/disco_tracking-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/disco_tracking.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/anyone_tracking-480.webp 480w,/blog/2024/fvmd/anyone_tracking-800.webp 800w,/blog/2024/fvmd/anyone_tracking-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/anyone_tracking.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Raw videos and tracking results on the TikTok datasets <d-cite key="jafarian2022self"></d-cite>. Left: Ground-truth video. Middle and right: Generated videos for the same scene of worse (middle) and better (right) quality, respectively. </div> <p>Above, we show three pieces of video from the TikTok dataset <d-cite key="jafarian2022self"></d-cite> with very different visual qualities for the same scene. One can easily spot their differences in motion patterns. Next, we show the 1D histograms based on the velocity field of the videos.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/gt_v_1d-480.webp 480w,/blog/2024/fvmd/gt_v_1d-800.webp 800w,/blog/2024/fvmd/gt_v_1d-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/gt_v_1d.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/disco_v_1d-480.webp 480w,/blog/2024/fvmd/disco_v_1d-800.webp 800w,/blog/2024/fvmd/disco_v_1d-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/disco_v_1d.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/anyone_v_1d-480.webp 480w,/blog/2024/fvmd/anyone_v_1d-800.webp 800w,/blog/2024/fvmd/anyone_v_1d-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/anyone_v_1d.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Dense 1D histograms for the velocity fields of the videos. Left: Ground-truth video. Middle and right: Generated videos for the same scene of worse (middle) and better (right) quality, respectively. </div> <p>The low-quality video has more abrupt motion changes, resulting in a substantially greater number of large-angle velocity vectors. Therefore, the <strong>higher-quality video (right) has a motion pattern closer to the ground-truth video (left) than the lower-quality video (middle)</strong>. This is exactly what we want to observe in the motion features! These features can capture the motion patterns effectively and distinguish between videos of different qualities.</p> <details> <summary>click here for 2D histogram result</summary> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/gt_v_2d-480.webp 480w,/blog/2024/fvmd/gt_v_2d-800.webp 800w,/blog/2024/fvmd/gt_v_2d-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/gt_v_2d.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/disco_v_2d-480.webp 480w,/blog/2024/fvmd/disco_v_2d-800.webp 800w,/blog/2024/fvmd/disco_v_2d-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/disco_v_2d.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/anyone_v_2d-480.webp 480w,/blog/2024/fvmd/anyone_v_2d-800.webp 800w,/blog/2024/fvmd/anyone_v_2d-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/anyone_v_2d.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Dense 2D histograms for the velocity fields of the videos. Left: ground-truth video. Middle and right: Generated videos of worse and better quality, respectively. </div> We can observe similar patterns in the 2D histograms. The higher-quality video (right) has a motion pattern closer to the ground-truth video (left) than the lower-quality video (middle). The unnatural jittering and unsmooth motion in the lower-quality video lead to more frequent large-magnitude velocity vectors, as captured by the 2D histograms. </details> <h3 id="fréchet-video-motion-distance">Fréchet Video Motion Distance</h3> <p>After extracting motion features from video segments of generated and ground-truth video sets, FVMD measures their similarity using the <strong>Fréchet distance</strong> <d-cite key="dowson1982frechet"></d-cite>, which explains the name <em>Fréchet Video Motion Distance (FVMD)</em>. To make the computation tractable, multi-dimensional Gaussian distributions are used to represent the motion features, following previous works <d-cite key="heusel2017gans"></d-cite>. Let $\mu_{\text{gen}}$ and $\mu_{\text{data}}$ be the mean vectors, and $\Sigma_{\text{gen}}$ and $\Sigma_{\text{data}}$ be the covariance matrices of the generated and ground-truth videos, respectively. The FVMD is defined as:</p> \[d_F = ||\mu_{\text{data}}-\mu_{\text{gen}}{||}_2^2 + \mathrm{tr}\left(\Sigma_{\text{data}} + \Sigma_{\text{gen}} -2(\Sigma_{\text{data}}\Sigma_{\text{gen}})^{\frac{1}{2}}\right)\] <h2 id="experiments">Experiments</h2> <p>The ultimate aim of a video evaluation metric is to align with human perception. To validate the effectiveness of FVMD, a series of experiments is conducted in the paper, including <strong>sanity check</strong>, <strong>sensitivity analysis</strong>, and <strong>quantitative comparison</strong> with existing metrics. <strong>Large-scale human studies</strong> are also performed to compare the performance of FVMD with other metrics.</p> <h3 id="sanity-check">Sanity Check</h3> <p>To verify the efficacy of the extracted motion features in representing motion patterns, a sanity check is performed in the FVMD paper. Motion features based on velocity, acceleration, and their combination are used to compare videos from the same dataset and different datasets.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/sanity_check-480.webp 480w,/blog/2024/fvmd/sanity_check-800.webp 800w,/blog/2024/fvmd/sanity_check-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/sanity_check.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> As sample size increases, same-dataset discrepancies (BAIR <d-cite key="ebert2017self"></d-cite> vs BAIR) converge to zero, while cross-dataset discrepancies (TIKTOK <d-cite key="jafarian2022self"></d-cite> vs BAIR) remain large, verifying the soundness of the FVMD metric. </div> <p>When measuring the FVMD of <strong>two subsets from the same dataset</strong>, it <strong>converges to zero as the sample size increases</strong>, confirming that the motion distribution within the same dataset is consistent. Conversely, the FVMD <strong>remains higher for subsets from different datasets</strong>, showing that their motion patterns exhibit a larger gap compared to those within the same dataset.</p> <h3 id="sensitivity-analysis">Sensitivity Analysis</h3> <p>Moreover, a sensitivity analysis is conducted to evaluate if the proposed metric can effectively detect temporal inconsistencies in generated videos, <em>i.e.</em>, being <strong>numerically sensitive to temporal noises</strong>. To this end, artificially-made temporal noises are injected to the TikTok dancing dataset <d-cite key="jafarian2022self"></d-cite> and FVMD scores are computed to assess its sensitivity to data corruption.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/sensitivity_ana-480.webp 480w,/blog/2024/fvmd/sensitivity_ana-800.webp 800w,/blog/2024/fvmd/sensitivity_ana-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/sensitivity_ana.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The FVMD scores in the presence of various temporal noises are presented. </div> <p>Across the four types of temporal noises injected into the dataset <d-footnote> There are four types of temporary noises in the FVMD paper: 1) local swap: swapping a fraction of consecutive frames in the video sequence, 2) global swap: swapping a fraction of frames in the video sequence with randomly chosen frames, 3) interleaving: weaving the sequence of frames corresponding to multiple different videos to obtain new videos, 4) switching: jumping from one video to another video. </d-footnote>, <strong>FVMD based on combined velocity and acceleration features</strong> demonstrates the most reliable performance. It shows a strong negative correlation with noise level, indicating FVMD’s sensitivity to temporal noise and its effectiveness in detecting temporal inconsistencies in generated videos.</p> <h3 id="quantitative-results">Quantitative Results</h3> <p>Further, FVMD provides a quantitative comparison of various video evaluation metrics on TikTok dataset <d-cite key="jafarian2022self"></d-cite>. Fifty videos are generated using different checkpoints named (a) through (e) <d-footnote>The video samples are reproduced from the following models: (a) is from Magic Animate <d-cite key="xu2023magicanimate"></d-cite>; (b), (c), and (e) are from Animate Anyone <d-cite key="hu2023animate"></d-cite>, each with different training hyperparameters; and (d) is from DisCo <d-cite key="wang2023disco"></d-cite>.</d-footnote> and their performance is measured using the FVD <d-cite key="unterthiner2018towards"></d-cite>, FID-VID <d-cite key="heusel2017gans"></d-cite>, VBench <d-cite key="huang2023vbench"></d-cite>, and FVMD metrics. Note that the models (a) to (e) are sorted based on human ratings collected through a user study, from worse to better visual quality (model (e) has the best visual quality and model (a) has the worst). This allows for a comparison of <strong>how well the evaluation metrics align with human judgments</strong>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/blog/2024/fvmd/FVMD.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls=""/> </figure> </div> </div> <div class="caption"> Video samples created by various video generative models trained on the TikTok dataset <d-cite key="jafarian2022self"></d-cite> are shown to compare the fidelity of different evaluation metrics. </div> <table> <thead> <tr> <th><strong>Metrics</strong></th> <th><strong>Model (a)</strong></th> <th><strong>Model (b)</strong></th> <th><strong>Model (c)</strong></th> <th><strong>Model (d)</strong></th> <th><strong>Model (e)</strong></th> <th><strong>Human Corr.↑</strong></th> </tr> </thead> <tbody> <tr> <td>FID↓</td> <td>73.20 (3rd)</td> <td>79.35 (4th)</td> <td>63.15 (2nd)</td> <td>89.57 (5th)</td> <td>18.94 (1st)</td> <td>0.3</td> </tr> <tr> <td>FVD↓</td> <td>405.26 (4th)</td> <td>468.50 (5th)</td> <td>247.37 (2nd)</td> <td>358.17 (3rd)</td> <td>147.90 (1st)</td> <td>0.8</td> </tr> <tr> <td>VBench↑</td> <td>0.7430 (5th)</td> <td>0.7556 (4th)</td> <td>0.7841 (2nd)</td> <td>0.7711 (3rd)</td> <td>0.8244 (1st)</td> <td>0.9</td> </tr> <tr> <td>FVMD↓</td> <td>7765.91 (5th)</td> <td>3178.80 (4th)</td> <td>2376.00 (3rd)</td> <td>1677.84 (2nd)</td> <td>926.55 (1st)</td> <td><strong>1.0</strong></td> </tr> </tbody> </table> <p>FVMD ranks the models correctly in line with human ratings and has <strong>the highest correlation to human perceptions</strong>. Moreover, FVMD provides <strong>distinct scores for video samples of different quality</strong>, showing a clearer separation between models.</p> <h3 id="human-study">Human Study</h3> <p>In the paper, large-scale human studies are conducted to validate that the proposed FVMD metric aligns with human perceptions. Three different human pose-guided generative models are fine-tuned: DisCo <d-cite key="wang2023disco"></d-cite>, Animate Anyone <d-cite key="xu2023magicanimate"></d-cite>, and Magic Animate <d-cite key="xu2023magicanimate"></d-cite>. These models, with distinct architectures and hyper-parameter settings, yield over 300 checkpoints with varying sample qualities. Users are then asked to compare samples from each pair of models to form a ground-truth user score. All checkpoints are also automatically evaluated using the FVMD metric, and the results are compared with FID-VID <d-cite key="heusel2017gans"></d-cite>, FVD <d-cite key="unterthiner2018towards"></d-cite>, SSIM <d-cite key="wang2004image"></d-cite>, PSNR <d-cite key="wang2004image"></d-cite>, and VBench <d-cite key="huang2023vbench"></d-cite>. <strong>The correlation between the scores given by each metric and the ground-truth user scores is calculated to further assess the performance of each metric.</strong></p> <p>Following the model selection strategy in <d-cite key="unterthiner2018towards"></d-cite>, two settings for the human studies are designed. The first setup is <strong>One Metric Equal</strong>. In this approach, a group of models with nearly identical scores based on a selected metric is identified. Namely, the selected models’ generated samples are considered to have similar visual quality compared to the reference data, according to the selected metric. This setup investigates whether the other metrics and human raters can effectively differentiate between these models.</p> <p>The second setting, <strong>One Metric Diverse</strong>, evaluates the agreement among different metrics when a single metric provides a clear ranking of the performances of the considered video generative models. Specifically, model checkpoints whose samples can be clearly differentiated according to the given metric are selected to test the consistency between this metric, other metrics, and human raters.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/human_study_eql-480.webp 480w,/blog/2024/fvmd/human_study_eql-800.webp 800w,/blog/2024/fvmd/human_study_eql-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/human_study_eql.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Table 1: Pearson correlation for the One Metric Equal experiments. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/human_study_div-480.webp 480w,/blog/2024/fvmd/human_study_div-800.webp 800w,/blog/2024/fvmd/human_study_div-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/human_study_div.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Table 2: Pearson correlation for One Metric Diverse experiments. </div> <p>The Pearson correlations range in [-1, 1], with values closer to -1 or 1 indicating stronger negative or positive correlation, respectively. The agreement rate among raters is reported as a percentage from 0 to 1. A higher agreement rate indicates a stronger consensus among human raters and higher confidence in the ground-truth user scores. The correlation is higher-the-better for all metrics in both <strong>One Metric Equal</strong> and <strong>One Metric Diverse</strong> settings. Overall, FVMD demonstrates the strongest capability to distinguish videos when other metrics fall short.</p> <h2 id="summary">Summary</h2> <p>In this blog, we give a brief summary of the recently-proposed <strong>Fréchet Video Motion Distance (FVMD)</strong> metric and its advantages over existing metrics. FVMD is designed to evaluate the motion consistency of generated videos by comparing the discrepancies of velocity and acceleration patterns between generated and ground-truth videos. The metric is validated through a series of experiments, including a sanity check, sensitivity analysis, quantitative comparison, and large-scale human studies. The results show that FVMD outperforms existing metrics in many aspects, such as better alignment with human judgment and a stronger capability to distinguish videos of different quality.</p>]]></content><author><name>Jiahe Liu</name></author><category term="metrics"/><category term="video"/><category term="generative-models"/><summary type="html"><![CDATA[In this blog post, we introduce a promising new metric for video generative models, Fréchet Video Motion Distance (FVMD), which focuses on the motion consistency of generated videos.]]></summary></entry><entry><title type="html">A Review of Video Evaluation Metrics</title><link href="https://dsl-lab.github.io/blog/2024/fvmd-1/" rel="alternate" type="text/html" title="A Review of Video Evaluation Metrics"/><published>2024-06-20T00:00:00+00:00</published><updated>2024-06-20T00:00:00+00:00</updated><id>https://dsl-lab.github.io/blog/2024/fvmd-1</id><content type="html" xml:base="https://dsl-lab.github.io/blog/2024/fvmd-1/"><![CDATA[<h2 id="introduction">Introduction</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/video-metrics-480.webp 480w,/blog/2024/fvmd/video-metrics-800.webp 800w,/blog/2024/fvmd/video-metrics-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/video-metrics.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Video evaluation metrics fall into two categories: 1) set-to-set comparison metrics and 2) unary metrics <d-cite key="melnik2024video"></d-cite>. </div> <p>Video generative models have been booming recently with the advent of powerful deep learning architectures and large-scale video datasets. However, evaluating the quality of generated videos remains a challenging task. The lack of a robust and reliable metric makes it difficult to assess the performance of video generative models quantitatively.</p> <p>Arguably, the ultimate goal for video evaluation metric is to <strong>align with human judgment</strong>: the desideratum is for generative models to create videos that meet our aesthetic standards <d-footnote>To demonstrate the quality of a new model, human subjects usually rate its generated samples in comparison to an existing baseline. Subjects are usually presented with pairs of generated clips from two different video models. They are then asked to indicate which of the two examples they prefer in regard to a specific evaluation criterion. Depending on the study, the ratings can either purely reflect the subject's personal preference, or they can refer to specific aspects of the video such as temporal consistency and adherence to the prompt. See <d-cite key="huang2023vbench, liu2024fvmd"></d-cite> for details. </d-footnote>. Humans are very good at judging what <em>looks natural</em> and identifying small temporal inconsistencies. However, the downsides of human ratings, like in every other human-in-the-loop machine learning task, are poor scalability and high costs. For this reason, it is important to develop automated evaluation metrics for model development and related purposes <d-footnote>Human studies can not only be used to evaluate model performance but also to measure how well the automated metrics align with human preferences. Specifically, they can statistically evaluate whether human judgments agree with metric-given results when assessing similar videos <d-cite key="unterthiner2018towards, huang2023vbench, liu2024fvmd"></d-cite>.</d-footnote>.</p> <p>Video evaluation metrics can be categorized into two types: <strong>1) set-to-set comparison metrics</strong> and <strong>2) unary metrics</strong>. The first type measures the difference between the generated set of data and the reference dataset, typically using statistical measures such as the Fréchet distance <d-cite key="dowson1982frechet"></d-cite>. The second type, unary metrics, does not require a reference set, making them suitable for video generation in the wild or video editing, where a gold-standard reference is absent.</p> <p>Below, we elaborate on the most commonly used video evaluation metrics and provide a quantitative comparison of these metrics on the TikTok dataset.</p> <h2 id="set-to-set-comparison-metrics">Set-to-set Comparison Metrics</h2> <p>Set-to-set metrics evaluate the disparity between a generated dataset and a reference dataset, usually within the feature space.</p> <p><strong>Fréchet Inception Distance (FID)</strong> <d-cite key="heusel2017gans"></d-cite> was originally proposed to measure the similarity between the output distribution of an <em>image</em> generative model and its training data. Generated images are first passed through a pre-trained Inception Net <d-cite key="szegedy2016rethinking"></d-cite> to extract features, which are then used to calculate the Fréchet distance between the real and synthetic data distributions. It has been extended to the video domain by computing the FID between the features of <em>individual frames</em> in the generated and reference videos. However, as one could imagine, <strong>this metric does not consider the temporal coherence between frames</strong>.</p> <p><strong>Fréchet Video Distance (FVD)</strong> <d-cite key="unterthiner2018towards"></d-cite> has been proposed as an extension of FID for the video domain. Its backbone is replaced by a 3D ConvNet pre-trained on action recognition tasks in YouTube videos (I3D <d-cite key="carreira2017quo"></d-cite>). The authors acknowledge that the FVD measure is not only <strong>sensitive to spatial degradation</strong> (different kinds of noise) but also to <strong>temporal aberrations</strong> such as the swapping of video frames. <strong>Kernel Video Distance (KVD)</strong> <d-cite key="unterthiner2018towards"></d-cite> is an alternative to FVD proposed in the same work, using a polynomial kernel. It is computed in an analogous manner, except that a polynomial kernel is applied to the features of the Inception Net. However, FVD was found to align better with human judgments than KVD. Nevertheless, both are commonly reported as benchmark metrics for unconditional video generation.</p> <p><strong>Fréchet Video Motion Distance (FVMD)</strong> <d-cite key="liu2024fvmd"></d-cite> is a metric focused on temporal consistency, <strong>measuring the similarity between motion features of generated and reference videos</strong> using Fréchet Distance. It begins by tracking keypoints using the pre-trained PIPs++ model <d-cite key="zheng2023pointodyssey"></d-cite>, then calculates the velocity and acceleration fields for each frame. The metric aggregates these features into statistical histograms and measures their differences using the Fréchet Distance. FVMD assesses motion consistency by analyzing speed and acceleration patterns, assuming smooth motions should follow physical laws and avoid abrupt changes.</p> <p>In addition to these modern video-based metrics, the traditional <strong>Peak Signal-to-Noise Ratio (PSNR)</strong> and <strong>Structural Similarity Index Measure (SSIM)</strong> <d-cite key="wang2004image"></d-cite> are image-level metrics for video quality assessment. Specifically, SSIM characterizes the brightness, contrast, and structural attributes of the reference and generated videos, while PSNR quantifies the ratio of the peak signal to the Mean Squared Error (MSE). Originally proposed for imaging tasks such as super-resolution and in-painting, these metrics are nonetheless repurposed for video evaluation. Unlike the aforementioned methods, PSNR and SSIM do not need pre-trained models. <strong>Nor do they consider the temporal coherence between frames</strong>, which is crucial for video generation tasks.</p> <h2 id="unary-metrics">Unary Metrics</h2> <p>Unary metrics assess the quality of given video samples without the need for a reference set, making them ideal for applications such as video generation in the wild or video editing where a gold-standard reference is unavailable.</p> <p><strong>VBench</strong> <d-cite key="huang2023vbench"></d-cite> proposes a comprehensive set of fine-grained video evaluation metrics to assess <strong>temporal and frame-wise video quality, as well as video-text consistency</strong> in terms of semantics and style. They employ a number of pre-trained models, e.g., RAFT <d-cite key="teed2020raft"></d-cite> for dynamic degree, and MUSIQ <d-cite key="ke2021musiq"></d-cite> for imaging quality, along with heuristics-inspired algorithms, e.g., visual smoothness and temporal flickering, based on inter-frame interpolation and reconstruction error. The overall score is determined by a weighted sum of a number of fine-grained metrics, and the authors also conduct human studies to validate the effectiveness of these metrics.</p> <p>For <strong>text-to-video generation tasks</strong>, <strong>CLIP cosine similarity</strong> is often used to measure the consistency between text prompts and video frames. CLIP <d-cite key="radford2021learning"></d-cite> is a family of vision transformer auto-encoders that map image and text data into a shared embedding space <d-footnote>During training, the distance between embedded images and their associated text labels is minimized through self-supervised learning objective. Thereby, visual concepts are represented close to words that describe them in the embedding space.</d-footnote>. The similarity between text and image CLIP embeddings is measured through cosine distance, where a value of 1 indicates identical concepts, and -1 implies completely unrelated concepts. To determine how well a video sequence adheres to the text prompt, the average similarity between each video frame and the text prompt is calculated (<strong>prompt consistency</strong>) <d-cite key="esser2023structure"></d-cite>. Temporal coherence can be assessed by computing the mean CLIP similarity between adjacent video frames (<strong>frame consistency</strong>). In video editing tasks, the percentage of frames with a higher prompt consistency score than in the original is also reported (<strong>frame accuracy</strong>) <d-cite key="qi2023fatezero"></d-cite>.</p> <p>For generative models trained on <strong>video data with categorical labels</strong>, the <strong>Inception Score (IS)</strong> <d-cite key="salimans2016improved"></d-cite> is a widely used metric. Similar to FID, IS was originally proposed for image generation tasks: an Inception Net <d-cite key="szegedy2016rethinking"></d-cite> classifier pre-trained on the ImageNet dataset <d-cite key="deng2009imagenet"></d-cite> is first used to predict the class labels of each generated image. The IS score is then calculated using the Kullback-Leibler divergence between the conditional class probability distribution $p(y|x)$ and the marginal class distribution $p(y)$ of the generated samples, where $y$ is the discrete label and $x$ is the generated image. It has been generalized to the video domain <d-cite key="saito2020train"></d-cite>, specifically for the UCF101 dataset <d-cite key="soomro2012ucf101"></d-cite>, where a pre-trained action recognition classifier (C3D <d-cite key="tran2015learning"></d-cite>) is used for score computation. However, this metric in practice is <strong>highly specific to the UCF101 dataset</strong> and is hardly applicable to videos in the wild due to classification difficulty.</p> <h2 id="comparison-on-tiktok-dataset">Comparison on TikTok Dataset</h2> <p>Let’s see how these evaluation metrics work in real life! We adopt a generic setup without using text prompts or discrete labels in the video generation task. We use the TikTok dataset <d-cite key="jafarian2022self"></d-cite> to provide a quantitative comparison of various video evaluation metrics.</p> <p>Specifically, we generate 50 videos using different checkpoints named (a) through (e) <d-footnote>The video samples are reproduced from the following models: (a) is from Magic Animate <d-cite key="xu2023magicanimate"></d-cite>; (b), (c), and (e) are from Animate Anyone <d-cite key="hu2023animate"></d-cite>, each with different training hyperparameters; and (d) is from DisCo <d-cite key="wang2023disco"></d-cite>.</d-footnote> and measure their performance using the FVD <d-cite key="unterthiner2018towards"></d-cite>, FID <d-cite key="heusel2017gans"></d-cite>, VBench <d-cite key="huang2023vbench"></d-cite>, and FVMD <d-cite key="liu2024fvmd"></d-cite> metrics. We do not use CLIP or IS in this comparison, as they are not suitable for our setup. The models (a) to (e) are sorted based on human ratings collected through a user study, from worse to better visual quality <d-cite key="liu2024fvmd"></d-cite> (model (e) has the best visual quality and model (a) has the worst). We can then <strong>compare how well the evaluation metrics align with human judgments</strong>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/blog/2024/fvmd/FVMD.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls="" loop=""/> </figure> </div> </div> <div class="caption"> We evaluate video samples created by various video generative models trained on the TikTok dataset <d-cite key="jafarian2022self"></d-cite> to compare the fidelity of different evaluation metrics. </div> <p>We put together a couple of videos generated by different models which clearly differ in visual quality. Models (a), (b), and (c) result in videos with incomplete human shapes and unnatural motions. Model (d) produces a video with better visual quality, but the motion is still not smooth, resulting in a lot of flickering. In comparison, model (e) generates a video with better visual quality and motion consistency. <em>Disclaimer: These video samples are nowhere near perfect; however, they are sufficient to compare different evaluation metrics.</em></p> <p><strong>Quantitative Results.</strong></p> <table> <thead> <tr> <th><strong>Metrics</strong></th> <th><strong>Model (a)</strong></th> <th><strong>Model (b)</strong></th> <th><strong>Model (c)</strong></th> <th><strong>Model (d)</strong></th> <th><strong>Model (e)</strong></th> <th><strong>Human Corr.↑</strong></th> </tr> </thead> <tbody> <tr> <td>FID↓</td> <td>73.20 (3rd)</td> <td>79.35 (4th)</td> <td>63.15 (2nd)</td> <td>89.57 (5th)</td> <td>18.94 (1st)</td> <td>0.3</td> </tr> <tr> <td>FVD↓</td> <td>405.26 (4th)</td> <td>468.50 (5th)</td> <td>247.37 (2nd)</td> <td>358.17 (3rd)</td> <td>147.90 (1st)</td> <td>0.8</td> </tr> <tr> <td>VBench↑</td> <td>0.7430 (5th)</td> <td>0.7556 (4th)</td> <td>0.7841 (2nd)</td> <td>0.7711 (3rd)</td> <td>0.8244 (1st)</td> <td>0.9</td> </tr> <tr> <td>FVMD↓</td> <td>7765.91 (5th)</td> <td>3178.80 (4th)</td> <td>2376.00 (3rd)</td> <td>1677.84 (2nd)</td> <td>926.55 (1st)</td> <td><strong>1.0</strong></td> </tr> </tbody> </table> <p>In this table, we show the raw scores given by the metrics, where FVD, FID, and FVMD are lower-is-better metrics, while VBench is higher-is-better. The scores are computed by comparing a set of generated videos (as shown in the video above) to a set of reference videos. We also report the corresponding ranking among the five models based on quantitative results. The ranking correlation between the metrics evaluation and human ratings is also reported, where a higher value indicates better alignment with human judgments.</p> <p>We can see the ambiguity of some evaluation metrics. <strong>Model (a), which has the poorest quality, cannot be effectively distinguished from models (b-d) based on the FID or VBench metrics</strong>. <strong>Additionally, model (c) is mistakenly ranked higher than model (d) by all metrics except for the FVMD metric</strong>. In particular, VBench gives very close scores to models (a-d) with clearly different visual quality, which are not consistent with human judgments. <strong>FVMD, on the other hand, ranks the models correctly in line with human ratings</strong>. Moreover, FVMD gives distinct scores for video samples of different quality, showing a clearer separation between models. This suggests that FVMD is a promising metric for evaluating video generative models, especially when motion consistency is concerned.</p> <p><strong>Frames Comparison.</strong> <br/> We also present visualizations of video frames for one randomly selected scene to further compare the metrics fidelity.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/fig-eval-metric-comparison-v0-480.webp 480w,/blog/2024/fvmd/fig-eval-metric-comparison-v0-800.webp 800w,/blog/2024/fvmd/fig-eval-metric-comparison-v0-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/fig-eval-metric-comparison-v0.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <details> <summary>click here for more frames comparison</summary> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/fvmd/fig-eval-metric-comparison-v1-480.webp 480w,/blog/2024/fvmd/fig-eval-metric-comparison-v1-800.webp 800w,/blog/2024/fvmd/fig-eval-metric-comparison-v1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/fvmd/fig-eval-metric-comparison-v1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </details> <h2 id="summary">Summary</h2> <p>We review the video evaluation metrics used to assess video generative models. These metrics can be categorized into two types: set-to-set comparison metrics (FID, FVD, KVD, FVMD, PSNR, and SSIM) and unary metrics (VBench, CLIP score, and IS). We discuss the pros and cons of each type and provide a detailed comparison using the TikTok dataset. The results show that the <strong>FVMD metric aligns better with human judgments than other metrics, especially for assessing motion consistency</strong>. This suggests that FVMD is a promising metric for evaluating video generative models.</p> <p>Wonder why FVMD performs so much better than other metrics? Check out <a href="https://dsl-lab.github.io/blog/2024/fvmd-2/">the second part of our blog post</a> to find out more! We will delve into the details of the FVMD metric and explain why it is more effective in assessing video quality and motion consistency.</p>]]></content><author><name>Qi Yan</name></author><category term="metrics"/><category term="video"/><category term="generative-models"/><summary type="html"><![CDATA[Video generative models have been rapidly improving recently, but how do we evaluate them efficiently and effectively? In this blog post, we review the existing evaluation metrics and highlight their pros and cons.]]></summary></entry><entry><title type="html">Flow Matching (Part 2)</title><link href="https://dsl-lab.github.io/blog/2024/cnf/" rel="alternate" type="text/html" title="Flow Matching (Part 2)"/><published>2024-06-18T00:00:00+00:00</published><updated>2024-06-18T00:00:00+00:00</updated><id>https://dsl-lab.github.io/blog/2024/cnf</id><content type="html" xml:base="https://dsl-lab.github.io/blog/2024/cnf/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>This blog post is part 2 in a series covering flow matching. Check out <a href="">part 1</a> of the series for the background on discrete normalizing flows.</p> <p>In the normalizing flows setup, the transformation from the simple distribution to the data distribution is expressed as a finite composition of functions. We can intepret this as a discrete time process with \(K\) time steps. At each time step, there is a corresponding intermediary distribution. But how can we obtain a transformation from \(p\) to \(q\) in continuous time rather than discrete time? Imagine this as taking the composition of infinitely many functions. We can express this idea using Ordinary Differential Equations (ODE), the fundamental component of Continuous Normalizing Flows (CNF). <d-cite key="chen_neural_2019"> </d-cite> <d-cite key="m_tomczak_flow_nodate"> </d-cite> <d-cite key="huang_how_nodate"></d-cite></p> <p>There is an even deeper connection between ODEs and residual flows that will lead us to continuous time flows. We can write the residual layer more generally as,</p> \[\mathbf{x}_{t+1} = \mathbf{x}_t + h u(\mathbf{x}_t),\] <p>where \(h &gt; 0\) is some constant and \(u\) is the neural network. First, observe that this equation looks like the Euler discretization of an ODE. Following the analogy, \(\mathbf{x}_t\) represents the current point we are at. To get to the point \(\mathbf{x}_{t+1}\) we move in the direction of the derivative, \(u(\mathbf{x}_t)\) with step size \(h\). In fact, if we rearrange this equation, we start to see something that resembles the definition of the derivative,</p> \[\frac{\mathbf{x}_{t+1} - \mathbf{x}_t}{h} = u(\mathbf{x}_t).\] <p>If we take \(h \to 0\) and increase the number of layers \(t \to \infty\) we arrive at the following ODE:</p> \[\frac{d\mathbf{x}(t)}{dt} = u_t(\mathbf{x}(t)),\] <p>where \(u_t\) is a time varying vector field that we parameterize with a neural network with parameters \(\theta\). This is called a Neural Ordinary Differential Equation. When we first introduced residual flows, it may have seemed strange to denote the layers with a time parameter \(t\). Now we know that residual layers are just a discretization of the continuous time dynamics of an ODE. Also, since we have represented residual flows in continuous time, each layer does not have its own parameters. Instead, the parameters are shared across time. Now, we are modeling the time varying vector field that transforms a distribution \(p\) to \(q\). There are a few main benefits that we gain from using Neural ODEs.</p> <p>1) The Euler discretization method is very rudimentary. ODEs and numerical integration is a mature field and we have much better numerical integrators at our disposal. With CNFs, we can use faster and more accurate solvers to integrate the time varying vector field we model with a neural network. Residual flows required specifying the number of layers of the ResNet which we no longer need to do. ODE solvers can determine the discretization steps needed to obtain a certain error threshold.</p> <p>2) Discrete Normalizing flows required computing the determinant of the Jacobian matrix which is an \(\mathcal{O}(d^3)\) operation. As we will see, CNFs allow us to perform the same operation with some numerical approximation in just \(\mathcal{O}(d)\) time.</p> <h2 id="vector-fields-and-odes">Vector fields and ODEs</h2> <p>To gain some intuition for flows and ODEs, consider a two dimensional vector field \(v(x,y)\) that describes the movement of water flowing along a river. For simplicity, assume it’s time-independent. The velocity of the water at point \((x,y)\) is the vector \(v(x,y)\). The path of a pebble thrown into the water at time \(t=0\) is a curve we can parameterize as a function of time:</p> \[\mathbf{r}(t) = \langle x(t), y(t) \rangle, \qquad \mathbf{r}(0) = \langle x(0), y(0) \rangle.\] <p>We can solve for the position of the pebble at time \(t\) by making the following observation. At time \(t\), the velocity of the pebble, \(\frac{d\mathbf{r}(t)}{dt}\), is the same as the velocity of the water at the position of the pebble, \(\mathbf{r}(t)\). We can model this with the following ODE:</p> \[\frac{d\mathbf{r}(t)}{dt} = v(\mathbf{r}(t)) = v(x(t), y(t)), \qquad \mathbf{r}(0) = \langle x(0), y(0) \rangle.\] <p>This example demonstrate how we can describe the movement of a particle induced by a vector field given some initial position. Specifically, we can construct a function \(\mathbf{r}(t)\) that describes the path taken by a single particle starting at a specific point in space at \(t=0\). As we will see, a flow in the context of CNFs is a more general object that represents the motion of all particles through time.</p> <h4 id="vector-field-examples">Vector Field Examples</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/blog/2024/flows/ODE_ex_1.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls="" loop=""/> </figure> <div class="caption"> $$v(x,y) = [-x , \ y]$$ </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/blog/2024/flows/ODE_ex_2.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls="" loop=""/> </figure> <div class="caption"> $$v(x,y) = [y - x ,\ -x - y]$$ </div> </div> </div> <div class="caption"> For simplicity, the two examples above or not time dependent vector fields. In fact, we can obtain explicit solutions for the ODEs described by the vector fields. On the left, the solution curves are cocentric circles and on the right the solution curves are spirals. </div> <h2 id="flows">Flows</h2> <p>Let’s provide a more rigorous definition of a flow. Suppose we have a vector field \(u: \mathbb{R}^d \times [0, 1] \to \mathbb{R}^d\). Unlike the example above, this is a time-dependent vector field and we will denote the time parameter as a subscript, \(u_t(x)\). In this setup, \(d\) is the dimension of our data space.</p> <p>A flow, which is induced by the vector field \(u_t\), is a mapping \(\phi: \mathbb{R}^d \times [0,1] \to \mathbb{R}^d\) which satisfies the following ODE:</p> \[\frac{d\phi_t(\mathbf{x})}{dt} = u_t(\phi_t(\mathbf{x})),\] <p>with initial condition \(\phi_0(\mathbf{x}) = \mathbf{x}\).</p> <p>To gain a better intiution of what \(\phi\) represents we can compare it to \(\mathbf{r}(t)\). Given some initial point \(\mathbf{x_0}\), \(\mathbf{r}(t)\) is the position of that point at time \(t\) induced by the movement of water. Similarly, when we provide \(\mathbf{x_0}\) as input to \(\phi\), we will get the function \(\phi(t, \mathbf{x_0}): [0, 1] \to \mathbb{R}^d\) which is only a function of time. It parameterizes a curve in \(\mathbb{R}^d\) that represents the position of the point \(\mathbf{x_0}\) with time induced by the vector field \(u_t\). We can view \(\phi\) from another perspective. Given a specific point in time \(t_0 \in [0,1]\) as input to \(\phi\), we will obtain a function \(\phi(t_0, \mathbf{x}): \mathbb{R}^d \to \mathbb{R}^d\). This function maps all points at time \(t=0\) to the position they would be at time \(t=t_0\). Overall, the mapping \(\phi\) describes the movement of all points starting from time \(t=0\) to time \(t = 1\).For consistent notation, we will denote the time parameter as a subscript \(\phi_t\).</p> <p>Another important object in CNFs is the probability density path \({p_t: \mathbb{R}^d \times [0,1] \to \mathbb{R}_{&gt;0}}\). It is a time-dependent probability density function i.e. \(\int p_t(\mathbf{x})d\mathbf{x} = 1\). Similar to normalizing flows, we let \(p_0 = p\) be a simple distribution such as a canonical Gaussian. Then \(p_t\) is defined by a change of variables from \(p_0\) using mapping \(\phi_t\):</p> \[\begin{equation}\label{COV_CNF} p_t(\mathbf{x}) = p_0(\phi_t^{-1}(\mathbf{x}))\det \left| \frac{\partial \phi_t^{-1}}{\partial \mathbf{x}}(\mathbf{x}) \right|. \end{equation}\] <p>With some regularity conditions on \(u_t\), we can gaurauntee that \(\phi_t\) is invertible. Therefore, a vector field generates a single unique probability density path. This also implies that the paths generated by the flow ODE are non-crossing which can be shown by simple contradiction. Suppose the paths of two different points do overlap at some point in time \(t \in [0,1]\). This means that two different points are mapped to the same point at time \(t\). But this would mean that \(\phi_t\) is not an invertible mapping.</p> <p>In the setting of CNFs, we let \(p_1\) be the data distibution. The goal is to learn a vector field \(v_t\) which induces a flow \(\phi_t\). This flow is responsible for transforming the simple distribution \(p_0 = p\) at time \(t=0\) to the data distribution \(p_1 = q\) at time \(t=1\).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/blog/2024/flows/cnf_ex_1.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls="" loop=""/> </figure> </div> </div> <div class="caption"> An example of a CNF trained to transform a 1D Gaussian distribution to a multi-modal distribution. The lines represent the flow trajectories of samples through time. Example is from FFJORD. <d-cite key="grathwohl_ffjord_2018"></d-cite> </div> <h2 id="the-continuity-equation">The continuity equation</h2> <p>The training objective is the same as in normalizing flows. We maximize the log-likelihood of the data. Given a data point \(\mathbf{x_1} \in \mathbb{R}^d\), to compute \(\log p_1(\mathbf{x_1})\) we could use Equation \(\eqref{COV_CNF}\). However, as in normalizing flows, that would require computing the Jacobian which is an \(O(d^3)\) operation. A benefit of CNFs is that once we are in the continuous setting, there is an alternative method available so we don’t have to do this computation. The alternative method involves the continuity equation:</p> \[\begin{equation}\label{cont_eq} \frac{\partial}{\partial t}p_t(\mathbf{x}) + \nabla \cdot (p_t(\mathbf{x})u_t(\mathbf{x})) = 0. \end{equation}\] <p>The continuity equation is a Partial Differential Equation (PDE) where \(\nabla \cdot\) represents the divergence operator. The divergence is computed with respect to the spatial dimensions \(\frac{\partial}{\partial x_i}\). The continuity equation provides a necassary and sufficient condition to ensure that a vector field \(u_t\) generates the probability density path \(p_t\). A key detail to note is that a given probability density path can have infinitely many vector fields that generate it. Although, a specific vector field generates only one unique probability density path.</p> <p>The continuity equation can be derived using some basic vector calculus. It also has a nice physics interpretation. Let’s start by considering an arbitary volume \(V\) in \(\mathbb{R}^3\) for the purposes of visualization. The volume \(V\) is enclosed by the surface \(S\). By definition, \(p_t\) has to integrate to \(1\) over \(\mathbb{R}^3\). This is a key observation. It means that analagous to mass, the probability density \(p_t\) is a conserved quantity. It cannot appear or disappear out of thin air. Therefore, the change in probability density across the volume must equal the difference in probablity density that has entered the volume and the density that has exited the volume. To gain some physical intiution, imagine \(u_t\) as the vector field representing the flow of water through the volume \(V\). Let \(p_t\) be the mass of the water. The change in mass of the flowing water in the volume must be the difference in the mass of water entering and mass of water leaving. So, we can write the change in probability density as follows:</p> \[\frac{d}{dt}\iiint_V p_t dV.\] <p>The triple integral is the total mass or probability density inside the volume. To measure the change, we take the derivative. Notice the only way for density to enter or leave the volume is through the surface \(S\). Now, let \(n: \mathbb{R}^3 \to \mathbb{R}^3\) represent the outward normal vector to \(S\) at point \((x,y,z)\). Consider an infinitesimally small part of the surface \(S\). The flow of density entering or leaving is the dot product of the normal \(n\) in that small region and the flow vector field \(u_t\). Then the amount of probability density entering or leaving the small region is \((u_t \cdot n)p_t\). Therefore, the change of probability density can also be represented as</p> \[\frac{d}{dt}\iiint_V p_t dV = - \iint_S (u_t \cdot n) p_t dS.\] <p>We have a negative sign because any density leaving the volume means a negative rate of change of the probability density. Now we can apply Gauss’s divergence theorem:</p> \[- \iint_S (u_t \cdot n) p_t dS = - \iiint_V \nabla \cdot (p_tu_t) dV.\] <p>We have written the surface integral as a volume integral. Then,</p> \[\frac{d}{dt}\iiint_V p_t dV = - \iiint_V \nabla \cdot (p_tu_t) dV.\] <p>Moving everything to one side and simplfying we get,</p> \[\iiint_V \left[ \frac{d}{dt}p_t + \nabla \cdot (p_tu_t) \right] dV = 0.\] <p>Since this is true for any arbitrary volume \(V\) it must be that the quantity inside the integral is equal to \(0\). This results in the continuity equation.</p> <p>Using the continuity equation and the ODE describing the flow \(\phi_t\) we get the instantaneous change of variable equation:</p> \[\frac{d}{dt}\log p_t(\phi_t(\mathbf{x})) + \nabla \cdot u_t(\phi_t(\mathbf{x})) = 0.\] <p>The proof of this fact is rather short so we provide it here. Consider the total derivative of \(\log p_t(\phi_t(\mathbf{x}))\),</p> \[\begin{align} \frac{d\log p_t(\phi_t(\mathbf{x}))}{dt} &amp;= \frac{\partial \log p_t(\phi_t(\mathbf{x}))}{\partial t} \cdot \frac{\partial t}{\partial t} + \nabla_{\mathbf{x}} \log p_t(\phi_t(\mathbf{x})) \cdot \frac{d \phi_t(\mathbf{x})}{d t} \notag \\ &amp;= \frac{\partial \log p_t(\phi_t(\mathbf{x}))}{\partial t} + \nabla_{\mathbf{x}} \log p_t(\phi_t(\mathbf{x})) \cdot \frac{d \phi_t(\mathbf{x})}{d t} \notag \\ &amp;= \frac{\partial \log p_t(\phi_t(\mathbf{x}))}{\partial t} + \nabla_{\mathbf{x}} \log p_t(\phi_t(\mathbf{x})) \cdot u_t(\phi_t(x)) \label{cov_deriv} \end{align}\] <p>Notice the first term is the partial derivative with respect to \(t\). We can obtain this term by rearranging the continuity equation. One property of the divergence operator is that \(\nabla \cdot (p_t(\mathbf{x})u_t(\mathbf{x})) = p_t(\mathbf{x}) \nabla \cdot u_t(\mathbf{x}) + u_t(\mathbf{x}) \cdot \nabla_\mathbf{x} p_t(\mathbf{x})\). So the continuity equation becomes,</p> \[\begin{equation*} \frac{\partial}{\partial t}p_t(\phi_t(\mathbf{x})) + p_t(\phi_t(\mathbf{x})) \nabla \cdot u_t(\phi_t(\mathbf{x})) + u_t(\phi_t(\mathbf{x})) \cdot \nabla_\mathbf{x} p_t(\phi_t(\mathbf{x})) = 0. \end{equation*}\] <p>Now divide by \(p_t(\phi_t(\mathbf{x}))\),</p> \[\begin{equation*} \frac{1}{p_t(\phi_t(\mathbf{x}))}\frac{\partial}{\partial t}p_t(\phi_t(\mathbf{x})) + \nabla \cdot u_t(\phi_t(\mathbf{x})) + u_t(\phi_t(\mathbf{x})) \cdot \nabla_\mathbf{x} \frac{p_t(\phi_t(\mathbf{x}))}{p_t(\phi_t(\mathbf{x}))} = 0. \end{equation*}\] <p>Recognize the derivative of \(\log\) and move some terms to the other side to get,</p> \[\begin{equation*} \frac{\partial}{\partial t}\log p_t(\phi_t(\mathbf{x})) = -\nabla \cdot u_t(\phi_t(\mathbf{x})) - u_t(\phi_t(\mathbf{x})) \cdot \nabla_\mathbf{x} \log p_t(\phi_t(\mathbf{x})). \end{equation*}\] <p>Now substitute this formula into \(\eqref{cov_deriv}\) to obtain the desired result. Remember that in the discrete normalizing flow setup, the change of variable formula required computing the determinant of the Jacobian which was a \(\mathcal{O}(d^3)\) operation. Using the instantaneous change of variables formula we can compute the log-likelihood by integrating the ODE,</p> \[\log p_1(\phi_1(\mathbf{x})) = \log p_0(\phi_0(\mathbf{x})) - \int_0^1 \nabla \cdot u_t(\phi_t(\mathbf{x})) dt.\] <p>Observe that divergence with respect to the spatial dimension is the same as trace of the Jacobian of \(u_t\). Computing the trace is an \(\mathcal{O}(d^2)\) operation. Using Hutchinson’s trace estimator formula we can reduce the cost down to \(\mathcal{O}(d)\).</p> <h2 id="training-cnfs">Training CNFs</h2> <p>Now we have an ODE that describes the change of the log-probability along the flow trajectory. So how can we use this ODE to compute \(\log p_1(\mathbf{x_1})\), and train a CNF with maximum likelihood? So far, we have discussed ODEs in the forward direction i.e. increasing time which is needed to transform the noise distribution into a data distribution. We can also compute and solve ODEs in the reverse direction allowing us to transfrom \(q\) to \(p\). In order to compute the log-likelihood of the data, we need to use the reverse direction ODE. First, we sample a point \(\mathbf{x_1}\) from \(q\). Then we solve the reverse ODE,</p> \[\frac{d\phi_{1-s}(\mathbf{x})}{ds} = -u_{1-s}(\phi_{1-s}(\mathbf{x})),\] <p>with initial condition \(\phi_1(\mathbf{x}) = \mathbf{x_1}\) with \(s \in [0,1]\). The solution to this is a point \(\mathbf{x_0}\) from the noise distribution. Now we can solve the reverse ODE corresponding to instantenous change of variables formula,</p> \[\frac{d}{ds}\log p_{1-s}(\phi_{1-s}(\mathbf{x})) = \nabla \cdot u_{1-s}(\phi_{1-s}(\mathbf{x})).\] <p>with initial condition \(\log p_0(\phi_0(\mathbf{x})) = \log p(\mathbf{x_0})\). The fact that \(p_0 = p\) is a simple distribution is a key property because that allows us to evaluate the log-likelihood \(\log p_0(\mathbf{x_0})\). Instead of having to evaluate the \(u_{1-s}\) again to solve this ODE, we can solve the log-likelihood and flow trajectory in a coupled manner:</p> \[\frac{d}{ds} \begin{bmatrix} \phi_{1-s}(\mathbf{x}) \\ f(1-s) \end{bmatrix} = \begin{bmatrix} -u_{1-s}(\phi_{1-s}(\mathbf{x})) \\ \nabla \cdot u_{1-s}(\phi_{1-s}(\mathbf{x})) \end{bmatrix}\] <p>with \(f(t) = \log p_t(\phi_t(\mathbf{x})) - \log p_1(\phi_1(\mathbf{x}))\). At \(t=1\) we want the difference between the two likelihoods to match so our initial condition is \(f(1) = 0\). The combined initial conditions are,</p> \[\begin{bmatrix} \phi_{1}(\mathbf{x}) \\ f(1) \end{bmatrix} = \begin{bmatrix} \mathbf{x_1} \\ 0 \end{bmatrix}.\] <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/blog/2024/flows/cnf_ex_2.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls="" loop=""/> </figure> </div> </div> <div class="caption"> Evolution of the probability density path and vector field trained to transform a 2D Gaussian to a 2D spiral distribution. Example is from FFJORD. <d-cite key="grathwohl_ffjord_2018"></d-cite> </div> <p>To summarize, we can train CNFs with maximum likelihood using reverse ODEs. Unlike training discrete normalizing flows which require computing the determinant with cost \(\mathcal{O}(d^3)\), CNFs only need \(\mathcal{O}(d)\) for computing the divergence. However, there is still a downside to training CNFs. The caveat is we have to simulate the flow trajectory to obtain the log-probability. Simulation is very slow even with the \(\mathcal{O}(d)\) operation cost. As a result, continuous normalizing flows scale very poorly which is why they were not as popular as other deep generative methods. In the next blog post, we will discuss flow matching which aims to solve this issue.</p>]]></content><author><name>Robin Yadav</name></author><category term="generative-models"/><category term="ODE"/><category term="flows"/><summary type="html"><![CDATA[This is part two in a series of blog posts about flow matching. In this post, we dig deep into continuous normalizing flows as they form the basis for flow matching methods. We discuss the benefits but also the drawbacks of continuous normalizing flows.]]></summary></entry><entry><title type="html">Flow-based Models and Flow Matching</title><link href="https://dsl-lab.github.io/blog/2024/flows/" rel="alternate" type="text/html" title="Flow-based Models and Flow Matching"/><published>2024-06-18T00:00:00+00:00</published><updated>2024-06-18T00:00:00+00:00</updated><id>https://dsl-lab.github.io/blog/2024/flows</id><content type="html" xml:base="https://dsl-lab.github.io/blog/2024/flows/"><![CDATA[<p>This is part one in a series of blog posts that will provide an introduction to flow-based models and flow matching.</p> <p>Flow-based models are an example of a probabilistic generative model. The goal of probabilistic modeling is to model the distribution of a random variable \(X\). This is typically done in a supervised fashion using examples \(\{x^{(i)}\}_{i=1}^N\) collected from the data distribution. We learn to approximate the probability density function of the data distribution with a model \(p(x;\theta)\) where \(\theta\) represents the parameters of a neural network. Why might this be useful? The most well-known use case is sampling. Once we have an approximation of the data distribution, we can sample from it to create new unseen data. In the past decade, we have witnessed Variational Auto-Encoders (VAE), Generative Adversarial Networks (GAN) and diffusion models at the forefront of research in generative modelling. These models have been applied successfully across various domains especially for image generation.</p> <p>Although flow-based models have recieved relatively less attention compared to other generative models in those years, there has been a recent surge in popularity due to the advent of flow matching. Flow matching encompasses diffusion models as a special case and offers a more simple and flexible training framework. We will build up to flow matching by covering some of the other relevant techniques developed for flow-based modeling in the past decade. Part one will start with normalizing flows and cover residual flow methods. Part two will touch on Neural ODEs and dicuss continuous normalizing flows. Finally, in part three, we dicuss flow matching and its generalizations such as Riemannian flow matching.</p> <p>Other than being a competitive alternative to diffusion models, what are some other motivations to study flow-based methods and flow matching? Well, flow-based methods are capable of likelihood evaluation because they model the probability density function directly. Also, as we will see, the flow matching framework relies on Ordinary Differential Equations (ODE) so they are effecient at sample generation.</p> <h2 id="normalizing-flows">Normalizing Flows</h2> <p>In future blog posts, we will see that flow matching is a way to train continuous normalizing flows. So we start by covering the basics of normalizing flows. The framework for normalizing flows is based on a rather simple fact from probability theory. Suppose \(\mathbf{x_0} \in \mathbb{R}^d\) is distributed according to \(p\) i.e. \(\mathbf{x_0} \sim p\). Let \(f: \mathbb{R}^d \to \mathbb{R}^d\) be an invertible and differentiable function. Now, let’s do a change of variables, \(\mathbf{x_1} = f(\mathbf{x_0})\). Then we are able to determine \(q\), the distribution of the transformed variable, \(\mathbf{x_1}\), in terms of \(p\). Namely,</p> \[\begin{align} q(\mathbf{x_1}) &amp;= p(\mathbf{x_0})\left|\det \frac{\partial f^{-1}}{\partial \mathbf{x_1}}(\mathbf{x_1})\right| \notag \\ &amp;= p\left(f^{-1}(\mathbf{x_1})\right)\left|\det \frac{\partial f^{-1}}{\partial \mathbf{x_1}}(\mathbf{x_1})\right|. \end{align}\] <p>The notation \(\frac{\partial f^{-1}}{\partial \mathbf{x_1}}\) denotes the Jacobian of \(f^{-1}\). Also, because the transformation is invertible, we can write \(p\) in terms of \(q\) too:</p> \[\begin{align*} p(\mathbf{x_0}) &amp;= q(\mathbf{x_1})\left|\det \frac{\partial f}{\partial \mathbf{x_0}}(\mathbf{x_0}) \right| \\ &amp;= q(f(\mathbf{x_0}))\left|\det \frac{\partial f}{\partial \mathbf{x_0}}(\mathbf{x_0}) \right|. \end{align*}\] <p><b> Example 1 </b>. Scaling and shifting a Gaussian. Suppose \(\mathbf{x_0} \in \mathbb{R}\) and \(\mathbf{x_0} \sim \mathcal{N}(0,1)\). Let \(\mathbf{x_1} = f(\mathbf{x_0}) = \sigma \mathbf{x_0} + \mathbf{\mu}\). Then \(\mathbf{x_0} = f^{-1}(\mathbf{x_1}) = \frac{\mathbf{x_1} - \mathbf{\mu}}{\sigma}\) so \(\frac{df^{-1}}{d\mathbf{x_1}} = \frac{1}{\sigma}\). In this case, the Jacobian is a positive scalar function so the determinant is itself. Recall the pdf of a canonical Gaussian:</p> \[p(\mathbf{x_0}) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}\mathbf{x_0}^2}.\] <p>Applying the formula we obtain a Gaussian with mean \(\mu\) and variance \(\sigma^2\),</p> \[\begin{align*} q(\mathbf{x_1}) &amp;= p\left(f^{-1}(\mathbf{x_1})\right)\left|\det \frac{\partial f^{-1}}{\partial \mathbf{x_1}}(\mathbf{x_1})\right| \\ &amp;= \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x - \mathbf{\mu}}{\sigma})^2}\frac{1}{\sigma} \\ &amp;= \frac{1}{\sqrt{2\pi\sigma}}e^\frac{-(x-\mathbf{\mu})^2}{2\sigma^2}. \end{align*}\] <p>Intuitively, multiplying \(\mathbf{x_0}\) by \(\sigma\) stretches the domain which changes the variance of the Gaussian. Adding \(\mu\) applies a shift to this stretched Gaussian.</p> <p><b> Example 2 </b>. Non-linear transformation of a canonical Gaussian. Suppose \(\begin{bmatrix} x \\ y\end{bmatrix} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\). The pdf of a canonical Gaussian in 2D is:</p> \[p(x,y) = \frac{1}{\sqrt{2\pi}}e^\frac{-(x^2 + y^2)}{2}.\] <p>Let’s apply a cubic transformation to each coordinate, \(u = x^3\) and \(v = y^3\). The inverse is \(x = u^\frac{1}{3}\) and \(y = v^\frac{1}{3}\). The Jacobian of this transformation is the following:</p> \[\begin{bmatrix} \frac{\partial x}{\partial u} &amp; \frac{\partial v}{\partial v} \\ \frac{\partial y}{\partial u} &amp; \frac{\partial v}{\partial v} \\ \end{bmatrix} = \begin{bmatrix} \frac{1}{3}u^{-\frac{2}{3}} &amp; 0 \\ 0 &amp; \frac{1}{3}v^{-\frac{2}{3}}\\ \end{bmatrix}.\] <p>The absolute value of the determinant of this matrix is \(\frac{1}{9}\lvert uv\rvert ^{-\frac{2}{3}}\). Therefore,</p> \[\begin{align*} q(u, v) &amp;= \frac{1}{9}\lvert uv\rvert ^{-\frac{2}{3}} p(x,y) \\ &amp;= \frac{1}{9}\lvert uv\rvert ^{-\frac{2}{3}}p(u^\frac{1}{3}, v^\frac{1}{3}) \\ &amp;= \frac{\lvert uv\rvert ^{-\frac{2}{3}}}{9\sqrt{2\pi}}e^\frac{-(u^\frac{2}{3} + v^\frac{2}{3})}{2} \\ \end{align*}\] <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/ex2_1-480.webp 480w,/blog/2024/flows/ex2_1-800.webp 800w,/blog/2024/flows/ex2_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/ex2_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/ex2_2-480.webp 480w,/blog/2024/flows/ex2_2-800.webp 800w,/blog/2024/flows/ex2_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/ex2_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 1: On the left is the graph of a canonical Gaussian. By applying a cubic transformation (which is invertible), we obtained a slightly more complex distribution that is displayed on the right. </div> <p>In the next sections, we will see that flow matching is capable of transforming between arbitrary distributions \(p\) and \(q\). But in the context of normalizing flows for generative modeling, \(p\) is simple distribution which we can sample from easily, typically a canonical Gaussian and \(q\) is our data distribution which we only have samples from i.e. the dataset \(x^{(i)}\). Our goal with this setup is to learn the transformation from \(p\) to the complex data distribution \(q\). We can do this by learning the invertible transformation \(f\). The function \(f\) will involve the use a neural network with parameters \(\theta\), so from now on we will denote the transformation as \(f_\theta\). Once we have learned \(f_\theta\) we will have access to \(\hat{q}\) which hopefully will be a good approximation of \(q\).</p> <p>Given that we learned \(f_\theta\), how do we do density estimation and generate samples from \(q\)? This is quite simple for flow models. If you have a data sample \(\mathbf{x}^{(i)}\), you can compute \(f^{-1}(\mathbf{x}^{(i)})\) and the deterimant of the Jacobian. Then plug those into eq. (1) to obtain \(\hat{q}(\mathbf{x}^{(i)})\). If you want to sample from \(q\), first obtain a sample \(\mathbf{x_0} \sim p\) which we know how to do because \(p\) is a simple distribution. Then, we can compute \({\mathbf{x_1} = f^{-1}_\theta(\mathbf{x_0})}\) and so \(\mathbf{x_1}\) will be a sample from \(\hat{q}\). Essentially, normalizing flows provide a way to learn how to transform samples from a simple distribution to a complex data distribution. This might seem a bit neboulous right now. How do we learn the transformation \(f_\theta\) using only samples from the complex data distribution? First, we have to discuss how to determine the design of \(f_\theta\) and ensure that it is invertible.</p> <p>Ensuring invertibility is challenging so normalizing flow methods start with imposing a specific structure on \(f_\theta\). We want to learn the transformation from \(p\) to \(q\) as a sequence of simpler transformations. Define functions \(f_1 \cdots f_k\) to be invertible and differentiable. Note these functions are still parameterized by \(\theta\) but we omit making this explicit for sake of notation. Invertible and differentiable functions are closed under composition. We can use this fact to define \(f_\theta\) in the following manner:</p> \[f_\theta = f_k \circ f_{k-1} \cdots f_2 \circ f_1.\] <p>The intiution behind this formulation is somewhat analagous to the justification of stacking many layers in a deep learning model instead of using one wide layer. Learning the transformation from \(p\) to \(q\) in one step might be too difficult. Instead, we can learn a sequence of functions where each function is responsible for transforming its input distribution into a slightly more complex distribution. Eventually, over the entire sequence we are able to model the complexity of the data distribution. Furthermore, now we only need to ensure that each simpler transformation is invertible which should be easier than designing a complex invertible transformation in one step.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/norm_flow-480.webp 480w,/blog/2024/flows/norm_flow-800.webp 800w,/blog/2024/flows/norm_flow-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/norm_flow.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Each transforms an input distrubtion into a slightly more complex distribution. The overall transformation maps the simple distribution to the complex data distribution </div> <p>Let’s reformulate the process of normalizing flows. Since we are performing multiple steps, \(\mathbf{x_1}\) is no longer a sample from \(q\) but a sample from a distribution slightly more complex than \(p_0 = p\). After applying \(K\) transformations we will have that \(\mathbf{x_K} \sim \hat{q}\):</p> \[\begin{align*} &amp;\phantom{\Rightarrow} \ \ \mathbf{x_0} \sim p_0, \quad \mathbf{x_1} = f_1(\mathbf{x_0}) \\ &amp;\Rightarrow \mathbf{x_1} \sim p_1, \quad \mathbf{x_2} = f_2(\mathbf{x_1}) \\ \phantom{\Rightarrow x_1} &amp;\cdots \\ &amp;\Rightarrow \mathbf{x}_{K-1} \sim p_{K-1}, \quad \mathbf{x}_K = f_K(\mathbf{x}_{K-1}) \\ &amp;\Rightarrow \mathbf{x}_K \sim p_K = \hat{q} \approx q. \end{align*}\] <p>The sequence of transformations from \(p\) to the distribution \(q\) is called a flow. The term normalizing in normalizing flow refers to the fact that after a transformation is applied, the resulting pdf is valid i.e. it integrates to one over its support and is greater than zero.</p> <p>So how do we actually train normalizing flows? The objective function is simply the maximum log-likelihood of the data:</p> \[\begin{align*} \theta^* &amp;= \max_{\theta} \sum_{i=1}^{N} \log(\hat{q}(\mathbf{x}^{(i)})) \\ &amp;= \max_{\theta} \sum_{i=1}^{N} \log\left(p\left(f^{-1}_\theta(\mathbf{x}^{(i)})\right)\left|\det \frac{\partial f^{-1}_\theta}{\partial \mathbf{x}_K}(\mathbf{x}^{(i)})\right|\right) \\ &amp;= \max_{\theta} \sum_{i=1}^{N} \log p\left(f^{-1}_\theta(\mathbf{x}^{(i)})\right) + \log\left|\det \frac{\partial f^{-1}_\theta}{\partial \mathbf{x}_K}(\mathbf{x}^{(i)})\right| \end{align*}.\] <p>Remember that \(f_\theta\) is actually the composition of a sequence of functions. We can simplify the determinant of the Jacobian of \(f\) by decomposing it as a product of the individual determinants. Specifically,</p> \[\left| \det \frac{f^{-1}_\theta}{\partial \mathbf{x}_K} \right| = \left| \det \prod_{k=1}^K \frac{f^{-1}_k}{\partial \mathbf{x}_k} \right| = \prod_{k=1}^K \left| \det \frac{f^{-1}_k}{\partial \mathbf{x}_k} \right|.\] <p>Substituting this back into the objective function we obtain:</p> \[\max_{\theta} \sum_{i=1}^{N} \left[ \log p\left(f^{-1}_\theta(\mathbf{x}^{(i)})\right) + \sum_{k=1}^{K} \log\left|\det \frac{f^{-1}_k}{\partial \mathbf{x}_k} (\mathbf{x}^{(i)}) \right|\right]\] <p>We can intepret the sum of log determinants in the objective as each “layer” of the flow receiving additional gradient information about the objective.</p> <p>While we discussed that \(f_\theta\) is a sequence of transformations, we didn’t cover how to define those transformations. Research in normalizing flow methods typically consists of constructing transformations that are easily invertible and have simple and computable log determinants. The most well-known normalizing flow methods are NICE, RealNVP and Glow. Many of these methods impose specific archictectural constraints on each neural network layer to ensure that it is invertible and that the Jacobian has some simple structure. For example, in the NICE paper, each transformation is a coupling layer that has a lower triangular Jacobian. The determinant of a triangular matrix is just the product of entries on the diagonal. The coupling layer transformation is quite simple. First we partition the input to layer \(K\) into two blocks \(\mathbf{x}_{K - 1} = [\mathbf{x}_{K - 1}^A, \mathbf{x}_{K - 1}^B]\). Then we compute the following:</p> \[\begin{align*} \mathbf{x}_{K}^A &amp;= \mathbf{x}_{K - 1}^A \\ \mathbf{x}_{K}^B &amp;= \mathbf{x}_{K - 1}^B + m_{\theta_K}(\mathbf{x}_{K - 1}^A), \end{align*}\] <p>where \(m_\theta\) is some arbitrarly complex neural network at layer \(K\). Then \(\mathbf{x}_{K} = [\mathbf{x}_{K}^A, \mathbf{x}_{K}^B]\). In words, this transformation keeps the first block of the partition the same. The second block is updated/coupled with the first part based on some complicated function parameterized by a neural network. The inverse of this transformation can be obtain simply:</p> \[\begin{align*} \mathbf{x}_{K - 1}^A &amp;= \mathbf{x}_{K}^A \\ \mathbf{x}_{K - 1}^B &amp;= \mathbf{x}_{K}^B - m_{\theta_K}(\mathbf{x}_{K - 1}^A). \end{align*}\] <p>The Jacobian of this transformation can be written as a lower triangular block matrix. We can see this by taking the derivative with respect to each part in the partitions. The following figure shows a visual depication of the transformation:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/nice_transf.JPG-480.webp 480w,/blog/2024/flows/nice_transf.JPG-800.webp 800w,/blog/2024/flows/nice_transf.JPG-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/nice_transf.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Each transforms an input distrubtion into a slightly more complex distribution. The overall transformation maps the simple distribution to the complex data distribution </div> <p>The next method we will cover is residual flows which will help us understand and motivate continuous normalizing flows.</p> <h3 id="residual-flows">Residual Flows</h3> <p>Many of the methods described above impose specific architectural constraints on the neural network to ensure that the transformation \(f_\theta\) is invertible. Furthermore, additional restrictions have to be placed in order to ensure the transformation has a sparse or structured Jacobian to make the log determinant easier to compute. Creating invertible neural network architectures with structured Jacobians is a difficult task that often leads to exotic designs, and in general, is a limiting approach to normalizing flows.</p> <p>Residual flows make use of invertible-ResNets (i-ResNet) and compute an unbiased estimate of the log determinant. Unlike previous approaches there are no constraints on the Jacobian. These properties allow us to use more expressive architectures. In particular, there is a rather simple property that can be imposed on ResNets to make them invertible.</p> <p>Recall that ResNets are a pretty simple architecture that consist of many residual blocks of the form:</p> \[\mathbf{x}_{t+1} = \mathbf{x_t} + g_{\theta_{t}}(\mathbf{x_t}).\] <p>Simply transform the input \(\mathbf{x_t}\) via the neural network \(g_{\theta_{t}}\) at layer \(t\) and add it to itself. If we can find a way to make each layer invertible then the entire ResNet will be invertible. To understand how we can accomplish this, we first have to learn about the Banach fixed point theorem.</p> <p>Suppose you have a contractive transformation \(T: \mathbb{R}^d \to \mathbb{R}^d\). Technically, \(T\) can map between any two general metric spaces but we will consider \(\mathbb{R}^d\) for simplicity. We say that the transformation \(T\) is contractive if there exists a constant \(K &lt; 1\) such that for all \(\mathbf{x}, \mathbf{y} \in \mathbb{R}^d\),</p> \[\left\lVert T(\mathbf{x}) - T(\mathbf{y}) \right\rVert \leq K\left\lVert \mathbf{x} - \mathbf{y} \right\rVert.\] <p>The Banach fixed point theorem states that there is a unique point \(\mathbf{x}\) such that \(T(\mathbf{x}) = \mathbf{x}\) i.e. \(\mathbf{x}\) is a fixed point that does not move under the transformation. In fact, we can compute \(\mathbf{x}\) using the following iterative procedure which provably converges. Select \(\mathbf{x}^{(0)} \in \mathbb{R}^d\) at random and then,</p> \[\mathbf{x}^{(n+1)} = T(\mathbf{x}^{(n)}).\] <p>Intuitively, since \(T\) is contractive, the distances between images of the iterate \(\mathbf{x}^{(n)}\) and the fixed point \(\mathbf{x}\) under \(T\) will shrink. Since the distance is shrinking it must mean that the iterates are converging to the fixed point.</p> <p>An equivalent way of stating that map \(T\) is contractive is declaring that \(T\) is \(L\)-Lipschitz continuous with constant \(L &lt; 1\). To make a residual layer invertible, we are going to enforce that the neural network \(g_{\theta_t}\) is contractive i.e. it has \(L_t &lt; 1\). Although this won’t provide us with an analytical form for the inverse, we can determine the inverse through an iterative routine. The proof of this is rather short. Suppose \(\mathbf{x}_{t+1} \in \mathbb{R}^d\) is arbitrary. We need to show that there exists a point \(\mathbf{x}_t\) such that \(\mathbf{x}_{t+1} = \mathbf{x}_t + g_{\theta_t}(\mathbf{x}_t)\). Let’s perform the following iterative routine with initial point \(\mathbf{y}^{(0)} = \mathbf{x}_{t+1}\):</p> \[\mathbf{y}^{(n+1)} = \mathbf{x}_{t+1} - g_{\theta_t}(\mathbf{y}^{(n)}).\] <p>We are going to define transformation \(T_{\mathbf{x}_{t+1}}(\mathbf{w}) = \mathbf{x}_{t+1} - g_{\theta_t}(\mathbf{w})\). Notice that \(\mathbf{x}_{t+1}\) is a constant with respect to the transformation in \(\mathbf{w}\). Multiplying \(g_{\theta_t}\) by \(-1\) and adding a constant perserves the Lipschitz continuity and does not change the Lipschitz constant. Therefore, \(T_{\mathbf{x}_{t+1}}\) is also a contractive map. Therefore, there exists a point we will denote by \(\mathbf{x}_t\) that is a fixed point of the transformation and the above iterative routine is equivalent to the following:</p> \[\mathbf{y}^{(n+1)} = T_{\mathbf{x}_{t+1}}(\mathbf{y}^{(n)}).\] <p>Therefore, the iterative subroutine will converge to fixed point \(\mathbf{x}_t\). Since \(\mathbf{x}_{t+1}\) was arbitrary and \(\mathbf{x_t}\) satisifies,</p> \[\mathbf{x}_t = \mathbf{x}_{t+1} - g_{\theta_t}(\mathbf{x}_t),\] <p>the residual layer is invertible.</p> <p>Now, how can we actually design a neural network \(g_{\theta_t}\) that will have a Lipschitz constant less than one? Fortunately, this does not require any complex architecture requirements. We can do this by using contractive activition functions such as \(\tanh\), ReLU and ELU and standard linear layers such as a feed-forward layer or convolutional layer. However, we must normalize the weight matrix of each layer, \(\mathbf{W}_i\) such that the spectral norm \(\left\lVert \mathbf{W}_i\right\rVert _2 \leq 1\). To do this, we compute an approximation of spectral norm of the unnormalized matrix and simply divide the unnormalized matrix by this approximation.</p> <p>Once we have the invertible network, the next tricky part of residual flows is evaluating the log-determinant: \(\log\left\vert\det \frac{\partial f^{-1}_\theta}{\partial \mathbf{x}}\right\vert\) of the transformation. Interestingly, the log-determinant of each layer of the ResNet can be written as an infinite series of trace matrix powers:</p> \[\sum_{k=1}^{\infty} \frac{(-1)^{k+1}}{k} \text{tr}\left[\left(\frac{\partial g_{\theta_t}}{\partial \mathbf{x}}\right)^k\right].\] <p>We can compute an approximation of this infinite series by truncating it to the first \(N\) terms where \(N\) is a hyperparameter. The trace of the matrix in each term can be estimated using the Hutchinson trace estimator. The Hutchinson trace estimator computes an unbiased estimate of the trace using matrix vector products. Specifically, to compute the trace of matrix \(\mathbf{A}\), we need a random vector \(\mathbf{v}_i\) such that \(\mathbb{E}[\mathbf{v}^{}_i\mathbf{v}^\top _i] = \mathbf{I}\). Then,</p> \[\text{tr}[\mathbf{A}] = \frac{1}{V} \sum_{i=1}^{V} \mathbf{v}_i^\top \mathbf{A} \mathbf{v}_i.\] <p>In practice, we only use one sample to estimate the trace. Although the trace estimation is unbiased, since we always truncate the original infinite series at \(N\) terms, the overall estimate will be biased.</p> <p>To make the estimator unbiased, we need to introduce some randomness into the truncation and take an expectation. Fortunately, we can use the “Russian roulette” estimator. The formula for the estimator is quite involved so we present a high-level intuition. The basic idea is that we always evaluate the first term and to determine whether we should evaluate the remaining terms we flip a coin that has probability \(p\) of coming up heads. If the remaining terms are evaluated then they are reweighted by \(\frac{1}{p}\) which results in an unbiased estimate. Futhermore, the estimate has probability \(1 - p\) of being evaluated in finite time (the case where we only evaluate the first term). Interesingly, we can obtain an estimator that is evaluated in finite time with probability one. We simply have to apply this process infinitely many times to the terms that have yet to be computed. Eventually, we are gauranteed to flip a tail and stop computing. Also, just like before we use the Hutchinson trace estimator to estimate the trace of the matrix in each term. Thus, we can compute this infinite series as:</p> \[\mathbb{E}_{n, \mathbf{v}}\left[\sum_{k=1}^{n} \frac{(-1)^{k+1}}{\mathbb{P}(N \geq k)} \mathbf{v}^\top\left[\left(\frac{\partial g_{\theta_t}}{\partial \mathbf{x}}\right)^k\right]\mathbf{v}\right],\] <p>where \(n \sim p(N)\) for some distribution \(p\) and \(\mathbf{v} \sim \mathcal{N}(0,1)\).</p> <p>To summarize, we have introduced normalizing flows, a class of generative models that learn an invertible transformation between a noise distribution \(p\) and a data distribution \(q\). We briefly covered some normalizing flow methods such as NICE that impose specific architectural constraints to ensure an invertible neural network and computable Jacobian. We discussed residual flows in detail which avoid exotic architecture design by using invertible ResNets. Relatively simple design choices can ensure that ResNets are invertible. Then we discussed how to compute an unbiased estimator of the Jacobian in the case of residual flows. Overall, normalizing flows are a powerful framework for generative modeling. Their main drawbacks include the limitation regarding architecture design and the high computational cost of the determinant of the Jacobian. In the next blog post, we will attempt to address these issues with continuous normalizing flows.</p> <h2 id="continuous-normalizing-flows">Continuous Normalizing Flows</h2> <p>In the normalizing flows setup, the transformation from the simple distribution to the data distribution is expressed as a finite composition of functions. We can intepret this as a discrete time process with \(K\) time steps. At each time step, there is a corresponding intermediary distribution. But how can we obtain a transformation from \(p\) to \(q\) in continuous time rather than discrete time? Imagine this as taking the composition of infinitely many functions. We can express this idea using Ordinary Differential Equations (ODE), the fundamental component of Continuous Normalizing Flows (CNF).</p> <p>There is an even deeper connection between ODEs and residual flows that will lead us to continuous time flows. We can write the residual layer more generally as,</p> \[\mathbf{x}_{t+1} = \mathbf{x}_t + h u(\mathbf{x}_t),\] <p>where \(h &gt; 0\) is some constant and \(u\) is the neural network. First, observe that this equation looks like the Euler discretization of an ODE. Following the analogy, \(\mathbf{x}_t\) represents the current point we are at. To get to the point \(\mathbf{x}_{t+1}\) we move in the direction of the derivative, \(u(\mathbf{x}_t)\) with step size \(h\). In fact, if we rearrange this equation, we start to see something that resembles the definition of the derivative,</p> \[\frac{\mathbf{x}_{t+1} - \mathbf{x}_t}{h} = u(\mathbf{x}_t).\] <p>If we take \(h \to 0\) and increase the number of layers \(t \to \infty\) we arrive at the following ODE:</p> \[\frac{d\mathbf{x}(t)}{dt} = u_t(\mathbf{x}(t)),\] <p>where \(u_t\) is a time varying vector field that we parameterize with a neural network with parameters \(\theta\). This is called a Neural Ordinary Differential Equation. When we first introduced residual flows, it may have seemed strange to denote the layers with a time parameter \(t\). Now we know that residual layers are just a discretization of the continuous time dynamics of an ODE. Also, since we have represented residual flows in continuous time, each layer does not have its own parameters. Instead, the parameters are shared across time. Now, we are modeling the time varying vector field that transforms a distribution \(p\) to \(q\). There are a few main benefits that we gain from using Neural ODEs.</p> <p>1) The Euler discretization method is very rudimentary. ODEs and numerical integration is a mature field and we have much better numerical integrators at our disposal. With CNFs, we can use faster and more accurate solvers to integrate the time varying vector field we model with a neural network. Residual flows required specifying the number of layers of the ResNet which we no longer need to do. ODE solvers can determine the discretization steps needed to obtain a certain error threshold.</p> <p>2) Discrete Normalizing flows required computing the determinant of the Jacobian matrix which is an \(\mathcal{O}(d^3)\) operation. As we will see, CNFs allow us to perform the same operation with some numerical approximation in just \(\mathcal{O}(d)\) time.</p> <p>To gain some intuition for flows and ODEs, consider a two dimensional vector field \(v(x,y)\) that describes the movement of water flowing along a river. For simplicity, assume it’s time-independent. The velocity of the water at point \((x,y)\) is the vector \(v(x,y)\). The path of a pebble thrown into the water at time \(t=0\) is a curve we can parameterize as a function of time:</p> \[\mathbf{r}(t) = \langle x(t), y(t) \rangle, \qquad \mathbf{r}(0) = \langle x(0), y(0) \rangle.\] <p>We can solve for the position of the pebble at time \(t\) by making the following observation. At time \(t\), the velocity of the pebble, \(\frac{d\mathbf{r}(t)}{dt}\), is the same as the velocity of the water at the position of the pebble, \(\mathbf{r}(t)\). We can model this with the following ODE:</p> \[\frac{d\mathbf{r}(t)}{dt} = v(\mathbf{r}(t)) = v(x(t), y(t)), \qquad \mathbf{r}(0) = \langle x(0), y(0) \rangle.\] <p>This example demonstrate how we can describe the movement of a particle induced by a vector field given some initial position. Specifically, we can construct a function \(\mathbf{r}(t)\) that describes the path taken by a single particle starting at a specific point in space at \(t=0\). As we will see, a flow in the context of CNFs is a more general object that represents the motion of all particles through time.</p> <h4 id="vector-field-examples">Vector Field Examples</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/blog/2024/flows/ODE_ex_1.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls="" loop=""/> </figure> <div class="caption"> $$v(x,y) = [-x , \ y]$$ </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/blog/2024/flows/ODE_ex_2.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls="" loop=""/> </figure> <div class="caption"> $$v(x,y) = [y - x ,\ -x - y]$$ </div> </div> </div> <div class="caption"> For simplicity, the two examples above or not time dependent vector fields. In fact, we can obtain explicit solutions for the ODEs described by the vector fields. On the left, the solution curves are cocentric circles and on the right the solution curves are spirals. </div> <p>Let’s provide a more rigorous definition of a flow. Suppose we have a vector field \(u: \mathbb{R}^d \times [0, 1] \to \mathbb{R}^d\). Unlike the example above, this is a time-dependent vector field and we will denote the time parameter as a subscript, \(u_t(x)\). In this setup, \(d\) is the dimension of our data space.</p> <p>A flow, which is induced by the vector field \(u_t\), is a mapping \(\phi: \mathbb{R}^d \times [0,1] \to \mathbb{R}^d\) which satisfies the following ODE:</p> \[\frac{d\phi_t(\mathbf{x})}{dt} = u_t(\phi_t(\mathbf{x})),\] <p>with initial condition \(\phi_0(\mathbf{x}) = \mathbf{x}\).</p> <p>To gain a better intiution of what \(\phi\) represents we can compare it to \(\mathbf{r}(t)\). Given some initial point \(\mathbf{x_0}\), \(\mathbf{r}(t)\) is the position of that point at time \(t\) induced by the movement of water. Similarly, when we provide \(\mathbf{x_0}\) as input to \(\phi\), we will get the function \(\phi(t, \mathbf{x_0}): [0, 1] \to \mathbb{R}^d\) which is only a function of time. It parameterizes a curve in \(\mathbb{R}^d\) that represents the position of the point \(\mathbf{x_0}\) with time induced by the vector field \(u_t\). We can view \(\phi\) from another perspective. Given a specific point in time \(t_0 \in [0,1]\) as input to \(\phi\), we will obtain a function \(\phi(t_0, \mathbf{x}): \mathbb{R}^d \to \mathbb{R}^d\). This function maps all points at time \(t=0\) to the position they would be at time \(t=t_0\). Overall, the mapping \(\phi\) describes the movement of all points starting from time \(t=0\) to time \(t = 1\).For consistent notation, we will denote the time parameter as a subscript \(\phi_t\).</p> <p>Another important object in CNFs is the probability density path \({p_t: \mathbb{R}^d \times [0,1] \to \mathbb{R}_{&gt;0}}\). It is a time-dependent probability density function i.e. \(\int p_t(\mathbf{x})d\mathbf{x} = 1\). Similar to normalizing flows, we let \(p_0 = p\) be a simple distribution such as a canonical Gaussian. Then \(p_t\) is defined by a change of variables from \(p_0\) using mapping \(\phi_t\):</p> \[\begin{equation}\label{COV_CNF} p_t(\mathbf{x}) = p_0(\phi_t^{-1}(\mathbf{x}))\det \left| \frac{\partial \phi_t^{-1}}{\partial \mathbf{x}}(\mathbf{x}) \right|. \end{equation}\] <p>With some regularity conditions on \(u_t\), we can gaurauntee that \(\phi_t\) is invertible. Therefore, a vector field generates a single unique probability density path. This also implies that the paths generated by the flow ODE are non-crossing which can be shown by simple contradiction. Suppose the paths of two different points do overlap at some point in time \(t \in [0,1]\). This means that two different points are mapped to the same point at time \(t\). But this would mean that \(\phi_t\) is not an invertible mapping.</p> <p>In the setting of CNFs, we let \(p_1\) be the data distibution. The goal is to learn a vector field \(v_t\) which induces a flow \(\phi_t\). This flow is responsible for transforming the simple distribution \(p_0 = p\) at time \(t=0\) to the data distribution \(p_1 = q\) at time \(t=1\).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/blog/2024/flows/cnf_ex_1.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls="" loop=""/> </figure> </div> </div> <div class="caption"> An example of a CNF trained to transform a 1D Gaussian distribution to a multi-modal distribution. The lines represent the flow trajectories of samples through time. </div> <p>The training objective is the same as in normalizing flows. We maximize the log-likelihood of the data. Given a data point \(\mathbf{x_1} \in \mathbb{R}^d\), to compute \(\log p_1(\mathbf{x_1})\) we could use Equation \(\eqref{COV_CNF}\). However, as in normalizing flows, that would require computing the Jacobian which is an \(O(d^3)\) operation. A benefit of CNFs is that once we are in the continuous setting, there is an alternative method available so we don’t have to do this computation. The alternative method involves the continuity equation:</p> \[\begin{equation}\label{cont_eq} \frac{\partial}{\partial t}p_t(\mathbf{x}) + \nabla \cdot (p_t(\mathbf{x})u_t(\mathbf{x})) = 0. \end{equation}\] <p>The continuity equation is a Partial Differential Equation (PDE) where \(\nabla \cdot\) represents the divergence operator. The divergence is computed with respect to the spatial dimensions \(\frac{\partial}{\partial x_i}\). The continuity equation provides a necassary and sufficient condition to ensure that a vector field \(u_t\) generates the probability density path \(p_t\). A key detail to note is that a given probability density path can have infinitely many vector fields that generate it. Although, a specific vector field generates only one unique probability density path.</p> <p>The continuity equation can be derived using some basic vector calculus. It also has a nice physics interpretation. Let’s start by considering an arbitary volume \(V\) in \(\mathbb{R}^3\) for the purposes of visualization. The volume \(V\) is enclosed by the surface \(S\). By definition, \(p_t\) has to integrate to \(1\) over \(\mathbb{R}^3\). This is a key observation. It means that analagous to mass, the probability density \(p_t\) is a conserved quantity. It cannot appear or disappear out of thin air. Therefore, the change in probability density across the volume must equal the difference in probablity density that has entered the volume and the density that has exited the volume. To gain some physical intiution, imagine \(u_t\) as the vector field representing the flow of water through the volume \(V\). Let \(p_t\) be the mass of the water. The change in mass of the flowing water in the volume must be the difference in the mass of water entering and mass of water leaving. So, we can write the change in probability density as follows:</p> \[\frac{d}{dt}\iiint_V p_t dV.\] <p>The triple integral is the total mass or probability density inside the volume. To measure the change, we take the derivative. Notice the only way for density to enter or leave the volume is through the surface \(S\). Now, let \(n: \mathbb{R}^3 \to \mathbb{R}^3\) represent the outward normal vector to \(S\) at point \((x,y,z)\). Consider an infinitesimally small part of the surface \(S\). The flow of density entering or leaving is the dot product of the normal \(n\) in that small region and the flow vector field \(u_t\). Then the amount of probability density entering or leaving the small region is \((u_t \cdot n)p_t\). Therefore, the change of probability density can also be represented as</p> \[\frac{d}{dt}\iiint_V p_t dV = - \iint_S (u_t \cdot n) p_t dS.\] <p>We have a negative sign because any density leaving the volume means a negative rate of change of the probability density. Now we can apply Gauss’s divergence theorem:</p> \[- \iint_S (u_t \cdot n) p_t dS = - \iiint_V \nabla \cdot (p_tu_t) dV.\] <p>We have written the surface integral as a volume integral. Then,</p> \[\frac{d}{dt}\iiint_V p_t dV = - \iiint_V \nabla \cdot (p_tu_t) dV.\] <p>Moving everything to one side and simplfying we get,</p> \[\iiint_V \left[ \frac{d}{dt}p_t + \nabla \cdot (p_tu_t) \right] dV = 0.\] <p>Since this is true for any arbitrary volume \(V\) it must be that the quantity inside the integral is equal to \(0\). This results in the continuity equation.</p> <p>Using the continuity equation and the ODE describing the flow \(\phi_t\) we get the instantaneous change of variable equation:</p> \[\frac{d}{dt}\log p_t(\phi_t(\mathbf{x})) + \nabla \cdot u_t(\phi_t(\mathbf{x})) = 0.\] <p>The proof of this fact is rather short so we provide it here. Consider the total derivative of \(\log p_t(\phi_t(\mathbf{x}))\),</p> \[\begin{align} \frac{d\log p_t(\phi_t(\mathbf{x}))}{dt} &amp;= \frac{\partial \log p_t(\phi_t(\mathbf{x}))}{\partial t} \cdot \frac{\partial t}{\partial t} + \nabla_{\mathbf{x}} \log p_t(\phi_t(\mathbf{x})) \cdot \frac{d \phi_t(\mathbf{x})}{d t} \notag \\ &amp;= \frac{\partial \log p_t(\phi_t(\mathbf{x}))}{\partial t} + \nabla_{\mathbf{x}} \log p_t(\phi_t(\mathbf{x})) \cdot \frac{d \phi_t(\mathbf{x})}{d t} \notag \\ &amp;= \frac{\partial \log p_t(\phi_t(\mathbf{x}))}{\partial t} + \nabla_{\mathbf{x}} \log p_t(\phi_t(\mathbf{x})) \cdot u_t(\phi_t(x)) \label{cov_deriv} \end{align}\] <p>Notice the first term is the partial derivative with respect to \(t\). We can obtain this term by rearranging the continuity equation. One property of the divergence operator is that \(\nabla \cdot (p_t(\mathbf{x})u_t(\mathbf{x})) = p_t(\mathbf{x}) \nabla \cdot u_t(\mathbf{x}) + u_t(\mathbf{x}) \cdot \nabla_\mathbf{x} p_t(\mathbf{x})\). So the continuity equation becomes,</p> \[\begin{equation*} \frac{\partial}{\partial t}p_t(\phi_t(\mathbf{x})) + p_t(\phi_t(\mathbf{x})) \nabla \cdot u_t(\phi_t(\mathbf{x})) + u_t(\phi_t(\mathbf{x})) \cdot \nabla_\mathbf{x} p_t(\phi_t(\mathbf{x})) = 0. \end{equation*}\] <p>Now divide by \(p_t(\phi_t(\mathbf{x}))\),</p> \[\begin{equation*} \frac{1}{p_t(\phi_t(\mathbf{x}))}\frac{\partial}{\partial t}p_t(\phi_t(\mathbf{x})) + \nabla \cdot u_t(\phi_t(\mathbf{x})) + u_t(\phi_t(\mathbf{x})) \cdot \nabla_\mathbf{x} \frac{p_t(\phi_t(\mathbf{x}))}{p_t(\phi_t(\mathbf{x}))} = 0. \end{equation*}\] <p>Recognize the derivative of \(\log\) and move some terms to the other side to get,</p> \[\begin{equation*} \frac{\partial}{\partial t}\log p_t(\phi_t(\mathbf{x})) = -\nabla \cdot u_t(\phi_t(\mathbf{x})) - u_t(\phi_t(\mathbf{x})) \cdot \nabla_\mathbf{x} \log p_t(\phi_t(\mathbf{x})). \end{equation*}\] <p>Now substitute this formula into \(\eqref{cov_deriv}\) to obtain the desired result. Remember that in the discrete normalizing flow setup, the change of variable formula required computing the determinant of the Jacobian which was a \(\mathcal{O}(d^3)\) operation. Using the instantaneous change of variables formula we can compute the log-likelihood by integrating the ODE,</p> \[\log p_1(\phi_1(\mathbf{x})) = \log p_0(\phi_0(\mathbf{x})) - \int_0^1 \nabla \cdot u_t(\phi_t(\mathbf{x})) dt.\] <p>Observe that divergence with respect to the spatial dimension is the same as trace of the Jacobian of \(u_t\). Computing the trace is an \(\mathcal{O}(d^2)\) operation. Using Hutchinson’s trace estimator formula we can reduce the cost down to \(\mathcal{O}(d)\).</p> <p>Now we have an ODE that describes the change of the log-probability along the flow trajectory. So how can we use this ODE to compute \(\log p_1(\mathbf{x_1})\), and train a CNF with maximum likelihood? So far, we have discussed ODEs in the forward direction i.e. increasing time which is needed to transform the noise distribution into a data distribution. We can also compute and solve ODEs in the reverse direction allowing us to transfrom \(q\) to \(p\). In order to compute the log-likelihood of the data, we need to use the reverse direction ODE. First, we sample a point \(\mathbf{x_1}\) from \(q\). Then we solve the reverse ODE,</p> \[\frac{d\phi_{1-s}(\mathbf{x})}{ds} = -u_{1-s}(\phi_{1-s}(\mathbf{x})),\] <p>with initial condition \(\phi_1(\mathbf{x}) = \mathbf{x_1}\) with \(s \in [0,1]\). The solution to this is a point \(\mathbf{x_0}\) from the noise distribution. Now we can solve the reverse ODE corresponding to instantenous change of variables formula,</p> \[\frac{d}{ds}\log p_{1-s}(\phi_{1-s}(\mathbf{x})) = \nabla \cdot u_{1-s}(\phi_{1-s}(\mathbf{x})).\] <p>with initial condition \(\log p_0(\phi_0(\mathbf{x})) = \log p(\mathbf{x_0})\). The fact that \(p_0 = p\) is a simple distribution is a key property because that allows us to evaluate the log-likelihood \(\log p_0(\mathbf{x_0})\). Instead of having to evaluate the \(u_{1-s}\) again to solve this ODE, we can solve the log-likelihood and flow trajectory in a coupled manner:</p> \[\frac{d}{ds} \begin{bmatrix} \phi_{1-s}(\mathbf{x}) \\ f(1-s) \end{bmatrix} = \begin{bmatrix} -u_{1-s}(\phi_{1-s}(\mathbf{x})) \\ \nabla \cdot u_{1-s}(\phi_{1-s}(\mathbf{x})) \end{bmatrix}\] <p>with \(f(t) = \log p_t(\phi_t(\mathbf{x})) - \log p_1(\phi_1(\mathbf{x}))\). At \(t=1\) we want the difference between the two likelihoods to match so our initial condition is \(f(1) = 0\). The combined initial conditions are,</p> \[\begin{bmatrix} \phi_{1}(\mathbf{x}) \\ f(1) \end{bmatrix} = \begin{bmatrix} \mathbf{x_1} \\ 0 \end{bmatrix}.\] <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/blog/2024/flows/cnf_ex_2.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls="" loop=""/> </figure> </div> </div> <div class="caption"> Evolution of the probability density path and vector field trained to transform a 2D Gaussian to a 2D spiral distribution. </div> <p>To summarize, we can train CNFs with maximum likelihood using reverse ODEs. Unlike training discrete normalizing flows which require computing the determinant with cost \(\mathcal{O}(d^3)\), CNFs only need \(\mathcal{O}(d)\) for computing the divergence. However, there is still a downside to training CNFs. The caveat is we have to simulate the flow trajectory to obtain the log-probability. Simulation is very slow even with the \(\mathcal{O}(d)\) operation cost. As a result, continuous normalizing flows scale very poorly which is why they were not as popular as other deep generative methods. In the next blog post, we will discuss flow matching which aims to solve this issue.</p> <h2 id="flow-matching">Flow Matching</h2> <p>Flow Matching (FM) builds on the same framework as CNFs but uses a different loss function. The main motivation to use this loss function is to address the scalability issue with the maximum likelihood computation. Furthermore, we will see that flow matching will allow for arbitrary source distributions \(p\) and we will not be restricted to simple noise distributions such as the standard Gaussian.</p> <p>To motivate the FM loss, consider the continuity equation. It provides a direct correspondence between the probability density path \(p_t\) and the vector field \(u_t\). Namely, if we knew the vector field already, then we know it generates a unique probability density path. Therefore, instead of directly optimizing the probability density path and having to compute \(\log p_1(\mathbf{x_1})\), we can optimize the vector field instead. Assuming that we know the probability density path and its generating vector field, the flow matching loss is defined as follows:</p> \[\mathcal{L}_{FM}(\theta) = \mathbb{E}_{t,p_t(\mathbf{x})}\left\lVert v_t(\mathbf{x}) - u_t(\mathbf{x})\right\rVert^2,\] <p>where \(v_t(x)\) is a learnable vector field parameterized by \(\theta\). We let \(p_t\) be the probability density path where \(p_0 = p\) is a simple source distribution and \(p_1\) is the data distribution \(q\). We regress the learnable vector field \(v_t\) onto the true vector field, \(u_t\). The FM loss is somewhat comparable to score-based generative modelling where we learn the score function (which can be seen as a time-independent vector field) in a regressive manner. Intuitively, we take an expectation over time \(t \in [0,1]\) because we are interested in learning a time dependent vector field. We take an expectation over the probability density path given time \(t\) since we want to regress the vector field onto points that are likely under the probability path it generates. This would be more effecient at learning an accurate vector field than randomly sampling points in \(\mathbb{R}^d\) under some arbitrary distribution.</p> <p>Although the FM loss seems to solve the problem with CNFs, the major caveat of course, is in practice, we cannot compute this loss because we don’t know \(p_t\) or \(u_t\). If we did then obviously there would be no point in learning the vector field \(v_t\). To overcome this obstacle, we are going to create another loss that will be computable. This is the conditional flow matching loss:</p> \[\begin{equation}\label{CFM_loss} \mathcal{L}_{CFM}(\theta) = \mathbb{E}_{t,q(\mathbf{x_1}), p_t(\mathbf{x}\vert\mathbf{x_1})}\left\lVert v_t(\mathbf{x}) - u_t(\mathbf{x}\vert\mathbf{x_1})\right\rVert^2. \end{equation}\] <p>We can prove that \(\nabla_\theta \mathcal{L}_{FM}\) and \(\nabla_\theta \mathcal{L}_{CFM}\) are equal upto a constant. So they are equivalent in a sense since they have the same optima. This makes the conditional flow matching loss a reasonable replacement. Now, we will describe conditional flow matching (CFM) and the objects in the conditional flow matching loss.</p> <p>The basic idea is that we can construct the marginal probability path by “averaging” conditional probability paths. These conditional paths are conditioned on data samples. Suppose we have a particular sample \(\mathbf{x_1}\) from the data distribution. We design the conditional probability path, \(p_t(\mathbf{x} \vert \mathbf{x_1})\) to satisfy the following boundary conditions: \(p_0(\mathbf{x}\vert\mathbf{x_1}) = p\) and \(p_1(\mathbf{x} \vert \mathbf{x_1}) = q\). Then we can marginalize over the data distribution to obtain the marginal probability density path,</p> \[p_t(\mathbf{x}) = \int p_t(\mathbf{x}|\mathbf{x_1})q(\mathbf{x_1})d\mathbf{x_1}.\] <p>From this, we can see that constructing the conditional probability path so \(p_0(\mathbf{x} \vert\mathbf{x_1}) = p_0(\mathbf{x})\) and \(p_1(\mathbf{x} \vert\mathbf{x_1}) = \delta_{\mathbf{x_1}}\) results in \(p_0(\mathbf{x}) = p(\mathbf{x})\) and \(p_1(\mathbf{x}) = q(\mathbf{x})\).</p> <p>For a given conditional probability path, there exists a conditional vector field which generates the path. The conditional vector field is denoted as \(u_t(x\vert\mathbf{x_1})\). Interestingly, we can compute the marginal vector field by also marginalizing over the data distribution in the following manner,</p> \[\begin{align*} u_t(\mathbf{x}) = \int u_t(\mathbf{x} \vert \mathbf{x_1})\frac{p_t(\mathbf{x} \vert \mathbf{x_1})q(\mathbf{x_1})}{p_t(\mathbf{x})}d\mathbf{x_1}. \end{align*}\] <p>The key realization is that the marginal vector field constructed above actually generates the marginal probability path. We can prove this by showing that \(u_t\) and \(p_t\) satisfy the continuity equation but the calculations are left out for brevity. Since \(p_0 = p\) and \(p_1 = q\), we have a method of transporting the source distribution to the data distribution just by using simple conditional probability paths. Furthermore, we can also define the conditional flow, \(\phi_t(\mathbf{x}\vert \mathbf{x_1})\) which satisfies the following ODE based on the conditional vector field:</p> \[\begin{equation}\label{CFM_ODE} \frac{d}{dt}\phi_t(\mathbf{x} \vert \mathbf{x_1}) = u_t\left(\phi_t(\mathbf{x} \vert \mathbf{x_1}) \vert \mathbf{x_1}\right), \end{equation}\] <p>with initial condition \(\phi_0(\mathbf{x} \vert \mathbf{x_1}) = \mathbf{x}\). The conditional flow generates the probability density path through the change of variables equation. Also, as before, we can integrate over the conditional vector field to obtain the conditional flow.</p> <p>So, if we have a way of defining the marginal vector field and probability density path which transforms \(p\) to \(q\), why do we have to use the conditional flow matching loss? This is because computing the integral over conditional vector fields is still intractable. Thus, we need a loss function that does not require computing \(u_t\).</p> <p>Returning back to the conditional flow matching loss, the main idea is that we take an expectation over the data distribution and the conditional probability path. As a result, we can replace the marginal vector field in the flow matching loss with the conditional vector field. In practice, we sample a point from the dataset and then sample from the conditional probability path instead of the marginal probability path. Of course, computing the loss also involves sampling a time \(t \in [0,1]\).</p> <p>Furthermore, we can make the following observation to reparameterize the conditional flow matching loss. The reparameterization avoids having to sample \(\mathbf{x} \sim p_t(\mathbf{x} \vert \mathbf{x_1})\). Instead, we can sample \(\mathbf{x_0} \sim p\) from the simple distribution. Then \(\mathbf{x_t} = \phi_t(\mathbf{x_0} \vert \mathbf{x_1})\) is a sample from \(p_t(\mathbf{x} \vert \mathbf{x_1})\) since the conditional flow is a transformation from \(p\) to \(p_t(\mathbf{x} \vert \mathbf{x_1})\). Therefore, \(\mathbf{x_t}\) is the solution to the ODE in Equation \(\eqref{CFM_ODE}\) with \(\mathbf{x_0}\) substituted into the flow:</p> \[\frac{d\phi_t(\mathbf{x_0}|\mathbf{x_1})}{dt} = \mu_t(\phi_t(\mathbf{x_0}|\mathbf{x_1}) \vert \mathbf{x_1}),\] <p>with initial condition \(\phi_0(\mathbf{x_0}\vert\mathbf{x_1}) = \mathbf{x_0}\). Therefore, we can rewrite the conditional flow matching objective as:</p> \[\begin{align} \mathcal{L}_{CFM}(\theta) &amp;= \mathbb{E}_{t, q(\mathbf{x_1}), p(\mathbf{x_0})}\left\lVert v_t(\phi_t(\mathbf{x_0}|\mathbf{x_1})) - \mu_t(\phi_t(\mathbf{x_0}|\mathbf{x_1}) | \mathbf{x_1})\right\rVert^2 \notag \\ &amp;= \mathbb{E}_{t, q(\mathbf{x_1}), p(\mathbf{x_0})}\left\lVert v_t(\phi_t(\mathbf{x_0}|\mathbf{x_1})) - \frac{d\phi_t(\mathbf{x_0}|\mathbf{x_1})}{dt}\right\rVert^2. \label{reparam_CFM_loss} \end{align}\] <p>To summarize, we have a way of training CNFs by using conditional probability paths and flows. The conditional flow matching loss has the same optima and doesn’t require access to the marginal probability path or vector field. We can compute the conditional flow matching loss effeciently as long as \(p_t(\mathbf{x}\vert\mathbf{x_1})\) is defined and can be sampled from effeciently. Furthermore, we are able to easily compute \(u_t(\mathbf{x}\vert\mathbf{x_1})\) because it is defined on a per-sample basis.</p> <p>Flow matching does not require simulating the flow or solving an ODE during training unlike training CNFs with the maximum likelihood objective. This makes training CNFs with flow matching more stable and effecient. In order to generate new samples, first sample \(\mathbf{x_0} \sim p\) from the noise distribution and then use a solver to find the solution, \(\phi_1(\mathbf{x_0})\) to the flow matching ODE with the learned vector field:</p> \[\frac{d\phi_t(\mathbf{x_0})}{dt} = v_t(\phi_t(\mathbf{x_0})),\] <p>with initial condition \(\phi_0(\mathbf{x_0}) = \mathbf{x_0}\).</p> <p>We have covered the basics of the conditional flow matching framework but have not specified the conditional probability path or conditional flow. These aspects are design choices and it is up to us to choose how we define \(p_t(\mathbf{x} \vert \mathbf{x_1})\) and \(\phi_t(\mathbf{x} \vert \mathbf{x_1})\). Broadly speaking, there are two ways we can make these choices:</p> <ol> <li> <p>Probability path perspective. Notice that the conditional flow matching objective in Equation \(\eqref{CFM_loss}\) just requires defining the conditional probability path \(p(\mathbf{x} \vert \mathbf{x_1})\) that satisfies the boundary conditions. Once a conditional probability path is defined, we can obtain the conditional vector field by solving the continuity equation \(\eqref{cont_eq}\). However, solving for \(u_t(\mathbf{x} \vert \mathbf{x_1})\) is usually very difficult. Also, in this case, the flow is defined implicity since once we have a vector field we can solve the conditional flow matching ODE in Equation \(\eqref{CFM_ODE}\) to get the flow.</p> </li> <li> <p>Interpolant perspective. The reparameterized flow matching loss in Equation \(\eqref{reparam_CFM_loss}\) requires defining the prior distribution \(p\) and the conditional flow \(\phi_t(\mathbf{x} \vert \mathbf{x_1})\). In this case, the conditional probability path is defined implicity and we can obtain it by applying \(\phi_t(\mathbf{x} \vert \mathbf{x_1})\) to the prior \(p\) using the change of variables formula. Also, we could solve for \(p_t(\mathbf{x} \vert \mathbf{x_1})\) using the continuity equation but that would be harder. But notice that we don’t need \(p_t(\mathbf{x} \vert \mathbf{x_1})\) to train the reparameterized objective and we also don’t need it for sampling because we use the learned vector field \(v_t\). As a result, the interpolant perspective is usually the easier approach.</p> </li> </ol> <p>To define these objects, we will follow the approach taken by the original flow matching paper by (cite). The definitions for these objects are motivated primarily by simplicity and tractability. Due to the simplicity of their approach, we will see that it can be viewed both from the probability path and interpolant perspective. Flow matching was introduced as a vector field \(u_t\) inducing a flow \(\phi_t\) that results in a probability density path \(p_t\). Although this is the natural way to understand the framework, we are going to define these objects in the opposite order but everything still works out.</p> <p>We start off by defining the conditional probability path. As a reminder, the simple source distribution \(p\) will be a canonical Gaussian. Therefore, to satisfy the first boundary condition, we must have \(p_0(\mathbf{x}\vert\mathbf{x_1}) = \mathcal{N}(\mathbf{0}, \mathbf{I})\). The second boundary condition is \(p_1(\mathbf{x} \vert\mathbf{x_1}) = \delta_{\mathbf{x_1}}\). For numerical reasons, we approximate the Dirac-delta distribution with a small variance Gaussian \(\mathcal{N}(\mathbf{x_1}, \sigma^2_{min}\mathbf{I})\). Given the boundary conditions, a natural and simple choice for the conditional probability path is a Gaussian distribution for each time \(t\),</p> \[p_t(\mathbf{x}\vert\mathbf{x_1}) = \mathcal{N}(u_t(\mathbf{x_1}), \sigma^2_t(\mathbf{x_1})\mathbf{I}),\] <p>where \(u_t: \mathbb{R}^d \times [0,1] \to \mathbb{R}^d\) and \(\sigma: \mathbb{R}^d \times [0,1] \to \mathbb{R}_{&gt;0}\) are the time-dependent mean and standard deviation. In order to satisfy the boundary conditions, we must have that \(u_0(\mathbf{x_1}) = 0\), \(\sigma_0(\mathbf{x_1}) = 1\), \(u_1(\mathbf{x_1}) = \mathbf{x_1}\) and \(\sigma_1(\mathbf{x_1}) = \sigma_{min}\).</p> <p>The simplest conditional flow that will generate \(p_t(\mathbf{x} \vert \mathbf{x_1})\) given that \(p\) is a canonical Gaussian is the following:</p> \[\phi_t(\mathbf{x} \vert\mathbf{x_1}) = \sigma_t(\mathbf{x_1})\mathbf{x} + u_t(\mathbf{x_1}),\] <p>where \(\mathbf{x} \sim p\). Indeed by example 1, this is true.</p> <p>The conditional vector field that generates this flow is given by the following:</p> \[u_t(\mathbf{x}\vert\mathbf{x_1}) = \frac{\sigma_t'(\mathbf{x_1})}{\sigma_t(\mathbf{x_1})}(\mathbf{x} - \mu_t(\mathbf{x_1})) + \mu'_t(\mathbf{x_1}).\] <p>In this setup, \(\mu_t\) is an arbitrary function that we can choose. Essentially, this allows us to select any arbitrary path from \(0\) to \(\mathbf{x_1}\). A natural choice for this is a straight line which is called the optimal transport solution.</p> <h4 id="optimal-transport">Optimal Transport</h4> <p>The optimal transport solution is the path that requires the least amount of work done to transform the canonical Gaussian to the mean \(u_t\) and std. \(\sigma_t\) Gaussian. Specifically, the mean and standard deviation change linearly with time:</p> \[u_t(\mathbf{x}) = t\mathbf{x_1}, \quad \text{and} \quad \sigma_t(\mathbf{x}) = 1 - (1 - \sigma_{min})t.\] <p>This straight line path is generated by the vector field:</p> \[u_t(\mathbf{x} \vert \mathbf{x_1}) = \frac{\mathbf{x_1} - (1 - \sigma_{min})\mathbf{x}}{1 - (1 - \sigma_{min})t}.\] <p>By substituting \(u_t\) and \(\sigma_t\), we get that the conditional flow in optimal transport case is:</p> \[\phi_t(\mathbf{x}|\mathbf{x_1}) = [1- (1 - \sigma_{min})t]\mathbf{x} + t\mathbf{x_1}.\] <p>Therefore, the reparameterized conditional flow matching loss is the following,</p> \[\mathbb{E}_{t, q(\mathbf{x_1}), p(\mathbf{x_0})}\left\lVert v_t(\phi_t(\mathbf{x_0}|\mathbf{x_1})) - (\mathbf{x_1} - (1 - \sigma_{min})\mathbf{x_0})\right\rVert^2.\] <p>The conditional flow is the optimal transport displacement map between two Gaussians. Although, the conditional flow is optimal it doesn’t imply that the marginal vector field is the optimal transport map between \(p\) and \(q\).</p> <p>To summarize, in this section, we covered the conditional flow matching framework using Gaussian probability paths with a canonical Gaussian source distribution. In this particular case, the probability path is simple enough that we can define the conditional flow and vector field using the probability path perspective or the interpolant perspective. Furthermore, the conditional flow matching framework is not restricted to Gaussian probability paths. We can have a different source distribution and use a different conditional path given that it satisifies the boundary conditions. However, designing probability paths for arbitrary source distributions may be difficult.</p> <h3 id="icfm-and-ot-cfm">iCFM and OT-CFM</h3> <p>In the previous section, we covered the conditional flow matching framework that was introduced by Lipman et al. (2023). There are two main limitations of the approach that they proposed. In this section, we introduce independent Conditional Flow Matching (iCFM) and Optimal Transport Conditional Flow Matching (OT-CFM) that will address these two limitations. In order to do this, we are going to reformulate CFM in a slightly more general form and then we will see that iCFM and OT-CFM are particular instantiations of this general CFM.</p> <p>The first limitation we want to address is finding a way to work with a source distribution that has an intractible probability density function. This can be done by conditioning on the source distribution in addition to the target/data distribution. To generalize, we condition on some variable \(\mathbf{z}\) that is distributed according to some distribution \(\tilde{q}\). In the conditional flow matching loss, we use to the conditional probability path, \(p_t(\mathbf{x} \vert \mathbf{z})\) and condition vector field \(u_t(\mathbf{x} \vert \mathbf{z})\):</p> \[\mathcal{L}(\theta) = \mathbb{E}_{t, \tilde{q}(\mathbf{z}), p_t(\mathbf{x} \vert \mathbf{z})} \lVert v_t(\mathbf{x}) - u_t(\mathbf{x} \vert \mathbf{z}) \rVert.\] <p>The work by Lipman et al. (2023) conditions on the target distribution so \(\tilde{q} = q\) and \(\mathbf{z} = \mathbf{x_1}\). In the iCFM framework, we let \(\mathbf{z} = (\mathbf{x_0}, \mathbf{x_1})\) where \(\tilde{q}(\mathbf{z}) = p(\mathbf{x_0})q(\mathbf{x_1})\). So \(\mathbf{z}\) represents a point from the source distribution and data distribution which are sampled independently from each other. The conditional flow transports a Gaussian with a small variance centered at \(\mathbf{x_0}\) to a Gaussian with small variance centered at \(\mathbf{x_1}\). The conditional probability path and conditional vector field are:</p> \[p_t(\mathbf{x} \vert \mathbf{x_0}, \mathbf{x_1}) = \mathcal{N}((1-t)\mathbf{x_0} + t\mathbf{x_1}, \sigma_{min}), \qquad u_t(\mathbf{x} \vert \mathbf{x_0}, \mathbf{x_1}) = \mathbf{x_1} - \mathbf{x_0}.\] <p>Also, the conditional flow generated by this vector field is the following:</p> \[\begin{align*} \phi_t(\mathbf{x} \vert \mathbf{x_0}, \mathbf{x_1}) &amp;= \mathbf{x} - \mathbf{x_0} + (1-t)\mathbf{x_0} + t\mathbf{x_1} \\ &amp;= t(\mathbf{x_1} - \mathbf{x_0}) + \mathbf{x}. \end{align*}\] <p>In order to obtain the marginal probability path \(p_t\), we must marginalize with respect to \(\mathbf{z}\) which is \(\mathbf{x_1}, \mathbf{x_0}\) in this case:</p> \[p_t(\mathbf{x}) = \int_{\mathbf{x_1}} \int_{\mathbf{x_0}} p_t(\mathbf{x} \vert \mathbf{x_0}, \mathbf{x_1}) p(\mathbf{x_0}) q(\mathbf{x_1}) d\mathbf{x_0}d\mathbf{x_1}.\] <p>At \(t=0\), we have that \(p_0(\mathbf{x} \vert \mathbf{x_0}, \mathbf{x_1}) = \mathcal{N}(\mathbf{x_0}, \sigma_{min})\) which does not dependent on \(\mathbf{x_1}\). Therefore,</p> \[p_0 = \int_{\mathbf{x_0}} p_0(\mathbf{x} \vert \mathbf{x_0}) p(\mathbf{x_0}) d\mathbf{x_0}.\] <p>As \(\sigma_{min} \to 0\), the conditional path at \(t=0\) becomes a dirac-delta distribution centered at \(\mathbf{x_1}\). In that case the marginal path at \(t=0\) corresponds exactly to the source distribution \(p\). Of course, we use a Gaussian with small variance to approximate the dirac delta distribution so the marginal probability path at \(t=0\) is \(p_0 = p \star \mathcal{N}(\mathbf{0}, \sigma_{min}^2\mathbf{I})\) where \(\star\) is the convolutional operator. Using similar reasoning, the marginal probability path at \(t=1\) is \(p_1 = q \star \mathcal{N}(\mathbf{0}, \sigma_{min}^2\mathbf{I})\). Therefore, the conditional probability path and vector field transport \(p_0\) to \(p_1\) which are approximately \(p\) and \(q\). If we use dirac-delta distributions instead, we would transport \(p\) to \(q\) exactly.</p> <p>This also highlights a difference between CFM and iCFM. In CFM, the conditional probability path at \(t=0\) must be the same as the source distribution \(p\). However, in iCFM the conditional path at \(t=0\) does not correspond to the source distribution. Furthermore, since iCFM conditions the probability path on the source distribution, we do not need a source distribution that has a tractible probability density. We just need to be able to sample from the source distribution. This is the added flexibility that flow matching provides. Diffusion models can only learn how to transform a noise distribution (e.g. Gaussian) to a data distribution. With flow matching, we can go from any source to target distribution. This allows us to use more informative source distributions rather than just a complete noisy distribution such as a Gaussian. For example, if we want to generate molecules, we might already have another dataset of similar molecules which we can use as a source distribution.</p> <p>One of the issues of CFM that iCFM fails to address is the fact that the marginal vector field is not the optimal transport solution from \(p\) to \(q\). Recall that there are potentially infinitely many vector fields that transform distribution \(p\) to \(q\). Just because the conditional vector fields of CFM and iCFM are optimal, it doesn’t imply that the marginal vector field is. But what does it mean for a vector field to be the optimal transport solution?</p> <p>The solution to the static optimal transport problem minimizes the distance between two probability measures based on some cost function \(c(\mathbf{x},\mathbf{y})\). The 2-Wasserstein distance corresponds to using the L2 norm, \(c(\mathbf{x},\mathbf{y}) = \lVert \mathbf{x} - \mathbf{y} \rVert _2^2\). Then the \(2\)-Wasserstein distance between distributions \(p\) and \(q\), \(W_2^2(p,q)\) is defined as the solution to the following optimization problem,</p> \[W_2^2(p,q) = \min_{\pi \in \Gamma(p,q)} \mathbb{E}_{\pi(\mathbf{x_0}, \mathbf{x_1})} \left[\lVert \mathbf{x_0} - \mathbf{x_1} \rVert _2^2\right],\] <p>where \(\Gamma(p,q)\) denotes the set of probability measures on \(\mathbb{R}^d \times \mathbb{R}^d\) with left marginal \(p\) and right marginal \(q\). We denote the minimizer as \(\pi^\star\) and it is also called the optimal coupling. Intuitively, the optimization problem captures the cost of transforming distribution \(p\) to distribution \(q\). One of the interesting aspects of the \(2\)-Wasserstein distance is that we can reformulate the optimization problem in terms of vectors fields \(u_t\) that generate probability density paths \(p_t\),</p> \[W_2^2(p,q) = \min_{u_t, p_t} \int_0^1 \int_{\mathbb{R}^d} p_t(\mathbf{x}) \lVert u_t(\mathbf{x}) \rVert _2^2 d\mathbf{x}dt,\] <p>where \(p_0 = p\) and \(p_1 = q\) (i.e. \(p_t\) satisifies the boundary conditions). This is called the dynamic formulation of the optimal transport problem and is equivalent to the static formulation. But why would we be interested in obtaining a vector field \(u_t\) that is a solution to the optimal transport problem? In the static formulation, we want to minimize the distance between the start and end points. In the dynamic formulation, we can see a term that takes into account the norm of the vector field. Intuitively, we are encouraging the lengths of the path taken by the flow to be as short as possible. Thus, the paths generated by the optimal vector field will be straight lines. This is helpful because straight line paths are easy to simulate during inference and they reduce the variance of the gradient objective during training which helps optimization.</p> <p>In fact, we can empirically observe non-straight flow paths generated by the marginal vector field learned through the CFM and iCFM framework. In the figure below, we have two mixtures of Gaussians represented with the source distribution in purple and target distribution in red. The image one the right shows simulated flow paths of the learned marginal vector field. The most logical paths generated by the marginal vector field should transport points from the top purple mixture to the top red mixture and the bottom purple mixture to the bottom red mixture. However, during training the source and target data points are sampled independently, so there are conditional flow paths \(\phi_t(\mathbf{x} \vert \mathbf{x_0}, \mathbf{x_1})\) that mix top and bottom mixtures. As a result, the learned marginal vector field produces curved marginal flow paths. This means that a lot of points are being pushed towards the curved part and the marginal vector field is changing rapidly during the curved part. This behaviour makes integrating across the vector field more numerically unstable so simulating the flow during inference becomes slow because we would have to use smaller step sizes in the ODE solver.</p> <p>Furthermore, we can see that the conditional flow paths cross each other. Of course this happens because we sample pairs that contain one point from a top mixture and the other point from a bottom mixture. The problem with this is that during training, we are regressing the learnable marginal vector field onto the conditional vector fields whose corresponding paths cross each other. However, the marginal vector field cannot generate paths that cross each other. This inconsistency results in the loss function having a large variance of gradient estimates during training which slows down optimization. Also, note that the conditional flow paths arising from the same conditional vector field do not intersect by uniqueness of the ODE. The problem arises because conditional flow paths from different vector fields can interstect i.e. paths from \(u_t(\mathbf{x} \vert \mathbf{x_0}, \mathbf{x_1})\) and \(u_t(\mathbf{x} \vert \tilde{\mathbf{x_0}}, \tilde{\mathbf{x_1})}\) can intersect.</p> <div class="row mt-2"> <div class="col-sm mt-2 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/m1-480.webp 480w,/blog/2024/flows/m1-800.webp 800w,/blog/2024/flows/m1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/m1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-2 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/m2-480.webp 480w,/blog/2024/flows/m2-800.webp 800w,/blog/2024/flows/m2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/m2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> These are the paths simulated during inference after we have obtained the learned vector. On the left, we have the conditional flow paths $$\phi_t(\mathbf{x} \vert \mathbf{x_0}, \mathbf{x_1})$$ between pairs of points. On the right, we simulate the paths of the learned marginal vector field (cite figure). </div> <p>To quickly summarize, the main issues with CFM and iCFM is that the marginal vector field is not gauranteed to have straight paths leading to slow inference and the conditional flows can cross each other leading to slow training speed. The reason for this is that iCFM samples points \(\mathbf{z} = (\mathbf{x_0}, \mathbf{x_1})\) independently i.e. \(\tilde{q}(\mathbf{z}) = p(\mathbf{x_0})q(\mathbf{x_1})\). OT-CFM resolves these problems by using the o</p> <p>In order to resolve this problem, we will choose a different distribution \(\tilde{q}\) for \(\mathbf{z}\) which will result in the OT-CFM method. Instead of sampling \(\mathbf{x_0}\) and \(\mathbf{x_1}\) independently as in \(\tilde{q}(\mathbf{z}) = p(\mathbf{x_0})q(\mathbf{x_1})\) we define \(\tilde{q}\) to be the \(2\)-Wasserstein optimal transport map \(\pi\),</p> \[\tilde{q}(\mathbf{z}) \pi(\mathbf{x_0}, \mathbf{x_1}).\] <h2 id="riemannian-flow-matching-rfm">Riemannian Flow Matching (RFM)</h2> <p>In the previous section, we discussed how to do flow matching in \(\mathbb{R}^d\). Another interesting question is how do we do flow matching on non-Euclidean geometries? This is relevant if you already know that your data lies on a manifold.</p> <p><em>Figure 2:</em> Consider a simple case where your data lies on a simple manifold in \(\mathbb{R}^2\) - the circle. Of course, on the left-hand side, you can use flow matching on Euclidean spaces to try to model this data. But it may be beneficial to specify as much prior knowledge you have about the data to obtain the best model. So performing flow matching on the manifold domain, the circle represented on the right, may lead to better performance.</p> <p>There are many real-world applications where we would want to model data that resides on a manifold. Examples include protein modelling, molecule modelling, robotics, medical imaging and geological sciences.</p> <p>In this section, we introduce Riemannian flow matching - a generalization of flow matching. Specifically, we consider complete, connected and smooth Riemannian manifolds, \(\mathcal{M}\) endowed with metric \(g\). Formally, we have a set of data samples \(\{x_i\}_{i=1}^N\) with \(x_i \in \mathcal{M}\) that arise from a probability distribution, \(q\) on \(\mathcal{M}\). We aim to learn a flow that transforms a simple noise distribution \(p\) on \(\mathcal{M}\) to the data distribution.</p> <p>The tangent space at \(x \in \mathcal{M}\) is denoted as \(T_x\mathcal{M}\). Also, \(g\) induces many key quantities. It defines an inner product over \(T_x\mathcal{M}\) denoted as \(\langle u,v \rangle _g\). We have the expontential map \(\exp_x: T_x\mathcal{M} \to \mathcal{M}\) and extensions of the gradient, divergence and Laplacian. For all \(x \in \mathcal{M}\), \(\text{div}_g{x}\) denotes the divergence with respect to the spatial (\(x\)) argument. The integration of the function \(f: \mathcal{M} \to \mathbb{R}\) is denotes as \(\int f(x) d\text{vol}_x\).</p> <p>Fortunately, there is not too many changes required to make flow matching work on manifolds. The objects used in RFM are the same as in FM. The space of probability densities over \(\mathcal{M}\) is defined as \(\mathcal{P}\). We have a probability path \(p_t: \mathcal{M} \times [0,1] \to \mathcal{P}\) such that \(\int p_t(x)d\text{vol}_x = 1\). The time dependent vector field is represented as \(u_t: \mathcal{M} \times [0,1] \to \mathcal{M}\). The flow \(\phi_t: \mathcal{M} \times [0,1] \to \mathcal{M}\) satisifies the following ODE defined on \(\mathcal{M}\):</p> \[\frac{d\phi_t(\mathbf{x})}{dt} = u_t(\phi_t(\mathbf{x})),\] <p>with initial condition \(\phi_0(\mathbf{x}) = \mathbf{x}\). The vector field \(u_t\) and probability path \(p_t\) also satisify the continuity equation on manifolds:</p> \[\frac{dp_t(\mathbf{x})}{dt} + \text{div}_g u_t(\phi_t(\mathbf{x})) = 0.\] <p>The vector field \(u_t\) generates the probability path \(p_t\) such that \(p_0 = p\) is the simple distribution and \(p_1 = q\) is the data distribution. The Riemannian flow matching objective is almost the same except we use \(g\) as the metric for the norm:</p> \[\mathcal{L}_{RFM}(\theta) = \mathbb{E}_{t, p_t(\mathbf{x})} \left\lVert v_t(\mathbf{x}) - u_t(\mathbf{x})\right\rVert^2_g.\] <p>Again, \(v_t\) is a learnable time-dependent vector field parameterized by \(\theta\). However, as before we don’t know the probability path \(p_t\) nor the vector field that generates this probability path. Since we cannot compute this loss, we use the Riemannian conditional flow matching loss instead.</p> <p>We condition on data samples to construct the conditional probability path and conditional vector field. Given \(\mathbf{x_1} \sim q\) we define the conditional path as \(p_t(\mathbf{x}\vert\mathbf{x_1})\) to satisfy the boundary conditions. As a note, we are keeping it general and not specifying the form of the conditional distribution. It does not have to be a Gaussian as in the Euclidean flow matching. Also, we can write the marginal probability path as</p> \[p_t(\mathbf{x}) = \int_{\mathcal{M}} p_t(\mathbf{x}\vert\mathbf{x_1})q(\mathbf{x_1})d\text{vol}_{\mathbf{x_1}}.\] <p>We define the conditional vector field \(u_t(\mathbf{x}\vert\mathbf{x_1})\) that generates this probability path. The marginal vector field can be obtained in a similar fashion as before:</p> \[u_t(x) = \int_{\mathcal{M}} u_t(x|\mathbf{x_1}) \frac{p_t(x|\mathbf{x_1})q(\mathbf{x_1})}{p_t(x)} d\text{vol}_{\mathbf{x_1}}.\] <p>Once again computing this integral is intractable which motivates us to define the Riemannian conditional flow matching loss:</p> \[\mathcal{L}_{RCFM}(\theta) = \mathbb{E}_{t, q(\mathbf{x_1}), p_t(\mathbf{x}\vert\mathbf{x_1})} ||v_t(\mathbf{x}) - u_t(\mathbf{x}\vert\mathbf{x_1})||^2_g.\] <p>We can reparameterize the loss as follows:</p> \[\mathcal{L}_{RCFM}(\theta) = \mathbb{E}_{t, q(\mathbf{x_1}), r(\mathbf{x_0})} \left\lVert v_t(\phi_t(\mathbf{x}\vert\mathbf{x_0})) - u_t(\phi(\mathbf{x} \vert \mathbf{x_0})\vert\mathbf{x_1})\right\rVert^2_g.\] <p>Now we need a way to construct the conditional flow. The conditional flow will map all points to \(\mathbf{x_1}\) at time \(t=1\) regardless of the choice of \(p\). So the flow satisfies:</p> \[\phi_1(\mathbf{x}\vert\mathbf{x_1}) = \mathbf{x_1}, \quad \forall \mathbf{x} \in \mathcal{M}.\] <p>Also, in the same manner in which we parameterized the loss function, we can sample \(\mathbf{x_0} \sim p\) and then compute \(\mathbf{x_t} = \phi_t(\mathbf{x_0} \vert \mathbf{x_1})\). Now, in order to construct the conditional flow, we consider two different cases. The first case is when we are on simple manifolds i.e. we have a closed form for the geodesics. Let \(d_g(\mathbf{x}, \mathbf{y})\) represent the geodesic distance between two points on the manifold. Let \(\kappa(t)\) be a monotonically decreasing function s.t. \(\kappa(0) = 1\) and \(\kappa(1) = 0\). We want to find a conditional flow \(\phi_t(\mathbf{x} \vert \mathbf{x_1})\) that will satisfy the following equation according to the scheduler \(\kappa\):</p> \[d_g(\phi_t(\mathbf{x_0} \vert \mathbf{x_1}), \mathbf{x_1}) = \kappa(t)d_g(\mathbf{x_0}, \mathbf{x_1}).\] <p>This will gaurantee that \(\phi_1(\mathbf{x} \vert \mathbf{x_1}) = \mathbf{x_1}\). A simple choice for this scheduler is \(\kappa(t) = 1 - t\). In fact, the conditional flow, \(\phi_t(\mathbf{x_0} \vert \mathbf{x_1})\) is a geodesic connecting \(x_0\) and \(x_1\). Additionally, the geodesic can be expressed as,</p> \[\phi_t(\mathbf{x_0} \vert \mathbf{x_1}) = \exp_{\mathbf{x_1}}(\kappa(t)\log_{\mathbf{x_1}}(\mathbf{x_0})),\] <p>which is simple to compute and results in a highly-scalable training objective. This conditional flow can be thought of as the analouge of interpolating between \(\mathbf{x_0}\) and \(\mathbf{x_1}\) in Euclidean space:</p> \[(1 - \kappa(t))\mathbf{x_1} + \kappa(t)\mathbf{x_0}.\] <p>When we are not on simple manifolds and don’t have access to the geodesic in closed form, we have to work with a pre-metric. A pre-metric is a function \(d: \mathcal{M} \times \mathcal{M} \to \mathbb{R}\) which satisfies the following properties:</p> <ul> <li>Non-negative: \(d(\mathbf{x}, \mathbf{y}) \geq 0\) for all \(x, y \in \mathcal{M}\)</li> <li>Positive: \(d(\mathbf{x}, \mathbf{y}) = 0\) iff \(x = y\)</li> <li>Non-degenerate: \(\nabla_x d(\mathbf{x}, \mathbf{y}) \neq 0\) iff \(x \neq y\)</li> </ul> <p>Note that a geodesic satisfies the definition for a premetric. Then we want a flow \(\phi_t(\mathbf{x_0} \vert \mathbf{x_1})\) to satisfy,</p> \[d(\phi_t(\mathbf{x_0} \vert \mathbf{x_1}), \mathbf{x_1}) = \kappa(t)d(\mathbf{x_0}, \mathbf{x_1}).\] <p>Once again, this will gaurantee that \(\phi_1(\mathbf{x_0} \vert \mathbf{x_1}) = \mathbf{x_1}\). Furthermore, the conditional vector field that generates this flow can be shown to be:</p> \[\mu_t(\mathbf{x} \vert \mathbf{x_1}) = \frac{d \log \kappa(t)}{dt} d(\mathbf{x}, \mathbf{x_1})\frac{\nabla_x d(\mathbf{x}, \mathbf{x_1})}{\lVert \nabla_x d(\mathbf{x}, \mathbf{x_1}) \rVert _g^2}.\] <p>Although this formula seems complicated, the basic component is the gradient of the distance, \(\nabla_x d(\mathbf{x}, \mathbf{x_1})\). This ensures we are going in the direction of \(\mathbf{x_1}\). The other terms control for the speed and make sure that the flow hits \(\mathbf{x_1}\) at time \(t=1\).</p> <p>If we don’t have access to the geodesic then there is no simple closed form interpolation like formula to compute \(\mathbf{x_t}\). Therefore, we must simulate/use an ODE solver to obtain \(\mathbf{x_t}\) which may computationally expensive.</p> <p>An example of a pre-metric is the spectral distance:</p> \[d_w(\mathbf{x},\mathbf{y})^2 = \sum_{i=1}^{\infty} w(\lambda_i) (\varphi_i(\mathbf{x}) - \varphi_i(\mathbf{y})),\] <p>where \(\varphi_i: \mathcal{M} \to \mathbb{R}\) are the eigenfunctions of the Laplace-Beltrami operator \(\Delta_g\) over \(\mathcal{M}\) with eigenvalues \(\lambda_i\), \(\Delta_g \varphi_i = \lambda_i \varphi_i\) and \(w: \mathbb{R} \to \mathbb{R}_{&gt;0}\) is some monotonically decreasing weighting function. Using the spectral distance can be more beneficial than geodesics because they are more robust to topological noise such as holes and shortcuts and are more geometry aware. An example of a spectral distance is the biharmonic distance which is helpful in avoiding boundaries of manifolds as show in the following figure.</p>]]></content><author><name>Robin Yadav</name></author><category term="generative"/><category term="models"/><summary type="html"><![CDATA[An introduction to flow matching.]]></summary></entry><entry><title type="html">Flow Matching (Part 1)</title><link href="https://dsl-lab.github.io/blog/2024/norm/" rel="alternate" type="text/html" title="Flow Matching (Part 1)"/><published>2024-06-18T00:00:00+00:00</published><updated>2024-06-18T00:00:00+00:00</updated><id>https://dsl-lab.github.io/blog/2024/norm</id><content type="html" xml:base="https://dsl-lab.github.io/blog/2024/norm/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>This is part one in a series of blog posts that will provide an introduction to flow-based models and flow matching.</p> <p>Flow-based models are an example of a probabilistic generative model. The goal of probabilistic modeling is to model the distribution of a random variable \(X\). This is typically done in a supervised fashion using examples \(\{x^{(i)}\}_{i=1}^N\) collected from the data distribution. We learn to approximate the probability density function of the data distribution with a model \(p(x;\theta)\) where \(\theta\) represents the parameters of a neural network. Why might this be useful? The most well-known use case is sampling. Once we have an approximation of the data distribution, we can sample from it to create new unseen data. In the past decade, we have witnessed Variational Auto-Encoders (VAE), Generative Adversarial Networks (GAN), and diffusion models at the forefront of research in generative modelling <d-cite key="kingma_auto-encoding_2022"></d-cite> <d-cite key="goodfellow_generative_2020"></d-cite> <d-cite key="song_score-based_2021"></d-cite> <d-cite key="ho_denoising_2020"></d-cite>. These models have been applied successfully across various domains especially for image generation.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/flow_methods.JPG-480.webp 480w,/blog/2024/flows/flow_methods.JPG-800.webp 800w,/blog/2024/flows/flow_methods.JPG-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/flow_methods.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Flow matching generalizes diffusion models. For context, continuous normalizing flows are a subset of normalizing flows. Flow matching is a scalable way to train continuous normalizing flows so it can be considered a subset of continuous normalizing flows <d-cite key="lipman_flow_nodate"></d-cite>. </div> <p>Although flow-based models have recieved relatively less attention compared to other generative models in those years, there has been a recent surge in popularity due to the advent of flow matching. Flow matching encompasses diffusion models as a special case and offers a more simple and flexible training framework. We will build up to flow matching by covering some of the other relevant techniques developed for flow-based modeling in the past decade. Part one will start with normalizing flows and cover residual flow methods. Part two will touch on Neural ODEs and dicuss continuous normalizing flows. Finally, in part three, we dicuss flow matching and its generalizations such as Riemannian flow matching.</p> <p>Other than being a competitive alternative to diffusion models, what are some other motivations to study flow-based methods and flow matching? Well, flow-based methods are capable of likelihood evaluation because they model the probability density function directly. Also, as we will see, the flow matching framework relies on Ordinary Differential Equations (ODE) so they are more effecient at sample generation compared to diffusion models.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/nvp_ex.JPG-480.webp 480w,/blog/2024/flows/nvp_ex.JPG-800.webp 800w,/blog/2024/flows/nvp_ex.JPG-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/nvp_ex.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/fm_ex.JPG-480.webp 480w,/blog/2024/flows/fm_ex.JPG-800.webp 800w,/blog/2024/flows/fm_ex.JPG-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/fm_ex.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> On the left are examples generated by Real-NVP, a normalizing flow model trained on ImageNet-64 <d-cite key="dinh_density_2017"> </d-cite>. On the right are examples from a conditional flow matching model <d-cite key="lipman_flow_2023"> </d-cite>. We can see the significant improvements made in generative modeling in just over five years with normalizing flow methods. </div> <h2 id="change-of-variables">Change of variables</h2> <p>In future blog posts, we will see that flow matching is a way to train continuous normalizing flows. So we start by covering the basics of normalizing flows. The framework for normalizing flows is based on a rather simple fact from probability theory <d-cite key="noauthor_222_nodate"> </d-cite>. Suppose \(\mathbf{x_0} \in \mathbb{R}^d\) is distributed according to \(p\) i.e. \(\mathbf{x_0} \sim p\). Let \(f: \mathbb{R}^d \to \mathbb{R}^d\) be an invertible and differentiable function. Now, let’s do a change of variables, \(\mathbf{x_1} = f(\mathbf{x_0})\). Then we are able to determine \(q\), the distribution of the transformed variable, \(\mathbf{x_1}\), in terms of \(p\). Namely,</p> \[\begin{align} q(\mathbf{x_1}) &amp;= p(\mathbf{x_0})\left|\det \frac{\partial f^{-1}}{\partial \mathbf{x_1}}(\mathbf{x_1})\right| \notag \\ &amp;= p\left(f^{-1}(\mathbf{x_1})\right)\left|\det \frac{\partial f^{-1}}{\partial \mathbf{x_1}}(\mathbf{x_1})\right|. \end{align}\] <p>The notation \(\frac{\partial f^{-1}}{\partial \mathbf{x_1}}\) denotes the Jacobian of \(f^{-1}\). Also, because the transformation is invertible, we can write \(p\) in terms of \(q\) too:</p> \[\begin{align*} p(\mathbf{x_0}) &amp;= q(\mathbf{x_1})\left|\det \frac{\partial f}{\partial \mathbf{x_0}}(\mathbf{x_0}) \right| \\ &amp;= q(f(\mathbf{x_0}))\left|\det \frac{\partial f}{\partial \mathbf{x_0}}(\mathbf{x_0}) \right|. \end{align*}\] <p><b> Example 1 </b>. Scaling and shifting a Gaussian. Suppose \(\mathbf{x_0} \in \mathbb{R}\) and \(\mathbf{x_0} \sim \mathcal{N}(0,1)\). Let \(\mathbf{x_1} = f(\mathbf{x_0}) = \sigma \mathbf{x_0} + \mathbf{\mu}\). Then \(\mathbf{x_0} = f^{-1}(\mathbf{x_1}) = \frac{\mathbf{x_1} - \mathbf{\mu}}{\sigma}\) so \(\frac{df^{-1}}{d\mathbf{x_1}} = \frac{1}{\sigma}\). In this case, the Jacobian is a positive scalar function so the determinant is itself. Recall the pdf of a canonical Gaussian:</p> \[p(\mathbf{x_0}) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}\mathbf{x_0}^2}.\] <p>Applying the formula we obtain a Gaussian with mean \(\mu\) and variance \(\sigma^2\),</p> \[\begin{align*} q(\mathbf{x_1}) &amp;= p\left(f^{-1}(\mathbf{x_1})\right)\left|\det \frac{\partial f^{-1}}{\partial \mathbf{x_1}}(\mathbf{x_1})\right| \\ &amp;= \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x - \mathbf{\mu}}{\sigma})^2}\frac{1}{\sigma} \\ &amp;= \frac{1}{\sqrt{2\pi\sigma}}e^\frac{-(x-\mathbf{\mu})^2}{2\sigma^2}. \end{align*}\] <p>Intuitively, multiplying \(\mathbf{x_0}\) by \(\sigma\) stretches the domain which changes the variance of the Gaussian. Adding \(\mu\) applies a shift to this stretched Gaussian.</p> <p><b> Example 2 </b>. Non-linear transformation of a canonical Gaussian. Suppose \(\begin{bmatrix} x \\ y\end{bmatrix} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\). The pdf of a canonical Gaussian in 2D is:</p> \[p(x,y) = \frac{1}{\sqrt{2\pi}}e^\frac{-(x^2 + y^2)}{2}.\] <p>Let’s apply a cubic transformation to each coordinate, \(u = x^3\) and \(v = y^3\). The inverse is \(x = u^\frac{1}{3}\) and \(y = v^\frac{1}{3}\). The Jacobian of this transformation is the following:</p> \[\begin{bmatrix} \frac{\partial x}{\partial u} &amp; \frac{\partial v}{\partial v} \\ \frac{\partial y}{\partial u} &amp; \frac{\partial v}{\partial v} \\ \end{bmatrix} = \begin{bmatrix} \frac{1}{3}u^{-\frac{2}{3}} &amp; 0 \\ 0 &amp; \frac{1}{3}v^{-\frac{2}{3}}\\ \end{bmatrix}.\] <p>The absolute value of the determinant of this matrix is \(\frac{1}{9}\lvert uv\rvert ^{-\frac{2}{3}}\). Therefore,</p> \[\begin{align*} q(u, v) &amp;= \frac{1}{9}\lvert uv\rvert ^{-\frac{2}{3}} p(x,y) \\ &amp;= \frac{1}{9}\lvert uv\rvert ^{-\frac{2}{3}}p(u^\frac{1}{3}, v^\frac{1}{3}) \\ &amp;= \frac{\lvert uv\rvert ^{-\frac{2}{3}}}{9\sqrt{2\pi}}e^\frac{-(u^\frac{2}{3} + v^\frac{2}{3})}{2} \\ \end{align*}\] <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/ex2_1-480.webp 480w,/blog/2024/flows/ex2_1-800.webp 800w,/blog/2024/flows/ex2_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/ex2_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/ex2_2-480.webp 480w,/blog/2024/flows/ex2_2-800.webp 800w,/blog/2024/flows/ex2_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/ex2_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> On the left is the graph of a canonical Gaussian. By applying a cubic transformation (which is invertible), we obtained a slightly more complex distribution that is displayed on the right. </div> <h2 id="normalizing-flows">Normalizing flows</h2> <p>In the next sections, we will see that flow matching is capable of transforming between arbitrary distributions \(p\) and \(q\). But in the context of normalizing flows for generative modeling, \(p\) is simple distribution which we can sample from easily, typically a canonical Gaussian and \(q\) is our data distribution which we only have samples from i.e. the dataset \(x^{(i)}\). Our goal with this setup is to learn the transformation from \(p\) to the complex data distribution \(q\). We can do this by learning the invertible transformation \(f\). The function \(f\) will involve the use a neural network with parameters \(\theta\), so from now on we will denote the transformation as \(f_\theta\). Once we have learned \(f_\theta\) we will have access to \(\hat{q}\) which hopefully will be a good approximation of \(q\).</p> <p>Given that we learned \(f_\theta\), how do we do density estimation and generate samples from \(q\)? This is quite simple for flow models. If you have a data sample \(\mathbf{x}^{(i)}\), you can compute \(f^{-1}(\mathbf{x}^{(i)})\) and the deterimant of the Jacobian. Then plug those into eq. (1) to obtain \(\hat{q}(\mathbf{x}^{(i)})\). If you want to sample from \(q\), first obtain a sample \(\mathbf{x_0} \sim p\) which we know how to do because \(p\) is a simple distribution. Then, we can compute \({\mathbf{x_1} = f^{-1}_\theta(\mathbf{x_0})}\) and so \(\mathbf{x_1}\) will be a sample from \(\hat{q}\). Essentially, normalizing flows provide a way to learn how to transform samples from a simple distribution to a complex data distribution. This might seem a bit neboulous right now. How do we learn the transformation \(f_\theta\) using only samples from the complex data distribution? First, we have to discuss how to determine the design of \(f_\theta\) and ensure that it is invertible.</p> <p>Ensuring invertibility is challenging so normalizing flow methods start with imposing a specific structure on \(f_\theta\). We want to learn the transformation from \(p\) to \(q\) as a sequence of simpler transformations. Define functions \(f_1 \cdots f_k\) to be invertible and differentiable. Note these functions are still parameterized by \(\theta\) but we omit making this explicit for sake of notation. Invertible and differentiable functions are closed under composition. We can use this fact to define \(f_\theta\) in the following manner:</p> \[f_\theta = f_k \circ f_{k-1} \cdots f_2 \circ f_1.\] <p>The intiution behind this formulation is somewhat analagous to the justification of stacking many layers in a deep learning model instead of using one wide layer. Learning the transformation from \(p\) to \(q\) in one step might be too difficult. Instead, we can learn a sequence of functions where each function is responsible for transforming its input distribution into a slightly more complex distribution. Eventually, over the entire sequence we are able to model the complexity of the data distribution. Furthermore, now we only need to ensure that each simpler transformation is invertible which should be easier than designing a complex invertible transformation in one step.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/norm_flow-480.webp 480w,/blog/2024/flows/norm_flow-800.webp 800w,/blog/2024/flows/norm_flow-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/norm_flow.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Each transforms an input distrubtion into a slightly more complex distribution. The overall transformation maps the simple distribution to the complex data distribution. </div> <p>Let’s reformulate the process of normalizing flows. Since we are performing multiple steps, \(\mathbf{x_1}\) is no longer a sample from \(q\) but a sample from a distribution slightly more complex than \(p_0 = p\). After applying \(K\) transformations we will have that \(\mathbf{x_K} \sim \hat{q}\):</p> \[\begin{align*} &amp;\phantom{\Rightarrow} \ \ \mathbf{x_0} \sim p_0, \quad \mathbf{x_1} = f_1(\mathbf{x_0}) \\ &amp;\Rightarrow \mathbf{x_1} \sim p_1, \quad \mathbf{x_2} = f_2(\mathbf{x_1}) \\ \phantom{\Rightarrow x_1} &amp;\cdots \\ &amp;\Rightarrow \mathbf{x}_{K-1} \sim p_{K-1}, \quad \mathbf{x}_K = f_K(\mathbf{x}_{K-1}) \\ &amp;\Rightarrow \mathbf{x}_K \sim p_K = \hat{q} \approx q. \end{align*}\] <p>The sequence of transformations from \(p\) to the distribution \(q\) is called a flow. The term normalizing in normalizing flow refers to the fact that after a transformation is applied, the resulting pdf is valid i.e. it integrates to one over its support and is greater than zero.</p> <p>So how do we actually train normalizing flows? The objective function is simply the maximum log-likelihood of the data:</p> \[\begin{align*} \theta^* &amp;= \max_{\theta} \sum_{i=1}^{N} \log(\hat{q}(\mathbf{x}^{(i)})) \\ &amp;= \max_{\theta} \sum_{i=1}^{N} \log\left(p\left(f^{-1}_\theta(\mathbf{x}^{(i)})\right)\left|\det \frac{\partial f^{-1}_\theta}{\partial \mathbf{x}_K}(\mathbf{x}^{(i)})\right|\right) \\ &amp;= \max_{\theta} \sum_{i=1}^{N} \log p\left(f^{-1}_\theta(\mathbf{x}^{(i)})\right) + \log\left|\det \frac{\partial f^{-1}_\theta}{\partial \mathbf{x}_K}(\mathbf{x}^{(i)})\right| \end{align*}.\] <p>Remember that \(f_\theta\) is actually the composition of a sequence of functions. We can simplify the determinant of the Jacobian of \(f\) by decomposing it as a product of the individual determinants. Specifically,</p> \[\left| \det \frac{f^{-1}_\theta}{\partial \mathbf{x}_K} \right| = \left| \det \prod_{k=1}^K \frac{f^{-1}_k}{\partial \mathbf{x}_k} \right| = \prod_{k=1}^K \left| \det \frac{f^{-1}_k}{\partial \mathbf{x}_k} \right|.\] <p>Substituting this back into the objective function we obtain:</p> \[\max_{\theta} \sum_{i=1}^{N} \left[ \log p\left(f^{-1}_\theta(\mathbf{x}^{(i)})\right) + \sum_{k=1}^{K} \log\left|\det \frac{f^{-1}_k}{\partial \mathbf{x}_k} (\mathbf{x}^{(i)}) \right|\right]\] <p>We can intepret the sum of log determinants in the objective as each “layer” of the flow receiving additional gradient information about the objective.</p> <p>While we discussed that \(f_\theta\) is a sequence of transformations, we didn’t cover how to define those transformations. Research in normalizing flow methods typically consists of constructing transformations that are easily invertible and have simple and computable log determinants. The most well-known normalizing flow methods are NICE, RealNVP and Glow <d-cite key="dinh_nice_2015"> </d-cite> <d-cite key="dinh_density_2017"> </d-cite> <d-cite key="kingma_glow_2018"> </d-cite>. Many of these methods impose specific archictectural constraints on each neural network layer to ensure that it is invertible and that the Jacobian has some relatively simple structure.</p> <p>For example, in the NICE paper, each transformation is a coupling layer that has a lower triangular Jacobian. The determinant of a triangular matrix is just the product of entries on the diagonal. The coupling layer transformation is quite simple. First we partition the input to layer \(K\) into two blocks \(\mathbf{x}_{K - 1} = [\mathbf{x}_{K - 1}^A, \mathbf{x}_{K - 1}^B]\). Then we compute the following:</p> \[\begin{align*} \mathbf{x}_{K}^A &amp;= \mathbf{x}_{K - 1}^A \\ \mathbf{x}_{K}^B &amp;= \mathbf{x}_{K - 1}^B + m_{\theta_K}(\mathbf{x}_{K - 1}^A), \end{align*}\] <p>where \(m_\theta\) is some arbitrarly complex neural network at layer \(K\). Then we set \(\mathbf{x}_{K} = [\mathbf{x}_{K}^A, \mathbf{x}_{K}^B]\). In words, this transformation keeps the first block of the partition the same. The second block is updated/coupled with the first part based on some complicated function parameterized by a neural network. The inverse of this transformation can be obtain simply:</p> \[\begin{align*} \mathbf{x}_{K - 1}^A &amp;= \mathbf{x}_{K}^A \\ \mathbf{x}_{K - 1}^B &amp;= \mathbf{x}_{K}^B - m_{\theta_K}(\mathbf{x}_{K - 1}^A). \end{align*}\] <p>The Jacobian of this transformation can be written as a lower triangular block matrix. We can see this by taking the derivative with respect to each part in the partitions. The following figure shows a visual depication of the transformation:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/nice_transf.JPG-480.webp 480w,/blog/2024/flows/nice_transf.JPG-800.webp 800w,/blog/2024/flows/nice_transf.JPG-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/nice_transf.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Visualization of the coupling transformation architecture <d-cite key="marcus_normalizing_nodate"> </d-cite>. In general, we can use any invertible coupling transform but the additive coupling described in the previous paragraphs is the most simple and common. </div> <p>The next method we will cover is residual flows which will help us understand and motivate continuous normalizing flows.</p> <h3 id="residual-flows">Residual Flows</h3> <p>Many of the methods described above impose specific architectural constraints on the neural network to ensure that the transformation \(f_\theta\) is invertible. Furthermore, additional restrictions have to be placed in order to ensure the transformation has a sparse or structured Jacobian to make the log determinant easier to compute. Creating invertible neural network architectures with structured Jacobians is a difficult task that often leads to exotic designs, and in general, is a limiting approach to normalizing flows.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2024/flows/jacobian.JPG-480.webp 480w,/blog/2024/flows/jacobian.JPG-800.webp 800w,/blog/2024/flows/jacobian.JPG-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2024/flows/jacobian.JPG" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Examples of the Jacobians of various normalizing flow methods <d-cite key="chen_residual_2020"> </d-cite>. The Jacobian of the invertible transformation defined in residual flows has no special structure. </div> <p>Residual flows make use of invertible-ResNets (i-ResNet) and compute an unbiased estimate of the log determinant <d-cite key="chen_residual_2020"> </d-cite> <d-cite key="behrmann_invertible_2019"> </d-cite>. Unlike previous approaches there are no constraints on the Jacobian. These properties allow us to use more expressive architectures. In particular, there is a rather simple property that can be imposed on ResNets to make them invertible.</p> <p>Recall that ResNets are a pretty simple architecture that consist of many residual blocks of the form:</p> \[\mathbf{x}_{t+1} = \mathbf{x_t} + g_{\theta_{t}}(\mathbf{x_t}).\] <p>Simply transform the input \(\mathbf{x_t}\) via the neural network \(g_{\theta_{t}}\) at layer \(t\) and add it to itself. If we can find a way to make each layer invertible then the entire ResNet will be invertible. To understand how we can accomplish this, we first have to learn about the Banach fixed point theorem.</p> <p>Suppose you have a contractive transformation \(T: \mathbb{R}^d \to \mathbb{R}^d\). Technically, \(T\) can map between any two general metric spaces but we will consider \(\mathbb{R}^d\) for simplicity. We say that the transformation \(T\) is contractive if there exists a constant \(K &lt; 1\) such that for all \(\mathbf{x}, \mathbf{y} \in \mathbb{R}^d\),</p> \[\left\lVert T(\mathbf{x}) - T(\mathbf{y}) \right\rVert \leq K\left\lVert \mathbf{x} - \mathbf{y} \right\rVert.\] <p>The Banach fixed point theorem states that there is a unique point \(\mathbf{x}\) such that \(T(\mathbf{x}) = \mathbf{x}\) i.e. \(\mathbf{x}\) is a fixed point that does not move under the transformation. In fact, we can compute \(\mathbf{x}\) using the following iterative procedure which provably converges. Select \(\mathbf{x}^{(0)} \in \mathbb{R}^d\) at random and then,</p> \[\mathbf{x}^{(n+1)} = T(\mathbf{x}^{(n)}).\] <p>Intuitively, since \(T\) is contractive, the distances between images of the iterate \(\mathbf{x}^{(n)}\) and the fixed point \(\mathbf{x}\) under \(T\) will shrink. Since the distance is shrinking it must mean that the iterates are converging to the fixed point.</p> <p>An equivalent way of stating that map \(T\) is contractive is declaring that \(T\) is \(L\)-Lipschitz continuous with constant \(L &lt; 1\). To make a residual layer invertible, we are going to enforce that the neural network \(g_{\theta_t}\) is contractive i.e. it has \(L_t &lt; 1\). Although this won’t provide us with an analytical form for the inverse, we can determine the inverse through an iterative routine. The proof of this is rather short. Suppose \(\mathbf{x}_{t+1} \in \mathbb{R}^d\) is arbitrary. We need to show that there exists a point \(\mathbf{x}_t\) such that \(\mathbf{x}_{t+1} = \mathbf{x}_t + g_{\theta_t}(\mathbf{x}_t)\). Let’s perform the following iterative routine with initial point \(\mathbf{y}^{(0)} = \mathbf{x}_{t+1}\):</p> \[\mathbf{y}^{(n+1)} = \mathbf{x}_{t+1} - g_{\theta_t}(\mathbf{y}^{(n)}).\] <p>We are going to define transformation \(T_{\mathbf{x}_{t+1}}(\mathbf{w}) = \mathbf{x}_{t+1} - g_{\theta_t}(\mathbf{w})\). Notice that \(\mathbf{x}_{t+1}\) is a constant with respect to the transformation in \(\mathbf{w}\). Multiplying \(g_{\theta_t}\) by \(-1\) and adding a constant perserves the Lipschitz continuity and does not change the Lipschitz constant. Therefore, \(T_{\mathbf{x}_{t+1}}\) is also a contractive map. Therefore, there exists a point we will denote by \(\mathbf{x}_t\) that is a fixed point of the transformation and the above iterative routine is equivalent to the following:</p> \[\mathbf{y}^{(n+1)} = T_{\mathbf{x}_{t+1}}(\mathbf{y}^{(n)}).\] <p>Therefore, the iterative subroutine will converge to fixed point \(\mathbf{x}_t\). Since \(\mathbf{x}_{t+1}\) was arbitrary and \(\mathbf{x_t}\) satisifies,</p> \[\mathbf{x}_t = \mathbf{x}_{t+1} - g_{\theta_t}(\mathbf{x}_t),\] <p>the residual layer is invertible.</p> <p>Now, how can we actually design a neural network \(g_{\theta_t}\) that will have a Lipschitz constant less than one? Fortunately, this does not require any complex architecture requirements. We can do this by using contractive activition functions such as \(\tanh\), ReLU and ELU and standard linear layers such as a feed-forward layer or convolutional layer. However, we must normalize the weight matrix of each layer, \(\mathbf{W}_i\) such that the spectral norm \(\left\lVert \mathbf{W}_i\right\rVert _2 \leq 1\). To do this, we compute an approximation of spectral norm of the unnormalized matrix and simply divide the unnormalized matrix by this approximation.</p> <p>Once we have the invertible network, the next tricky part of residual flows is evaluating the log-determinant: \(\log\left\vert\det \frac{\partial f^{-1}_\theta}{\partial \mathbf{x}}\right\vert\) of the transformation. Interestingly, the log-determinant of each layer of the ResNet can be written as an infinite series of trace matrix powers:</p> \[\sum_{k=1}^{\infty} \frac{(-1)^{k+1}}{k} \text{tr}\left[\left(\frac{\partial g_{\theta_t}}{\partial \mathbf{x}}\right)^k\right].\] <p>We can compute an approximation of this infinite series by truncating it to the first \(N\) terms where \(N\) is a hyperparameter. The trace of the matrix in each term can be estimated using the Hutchinson trace estimator. The Hutchinson trace estimator computes an unbiased estimate of the trace using matrix vector products. Specifically, to compute the trace of matrix \(\mathbf{A}\), we need a random vector \(\mathbf{v}_i\) such that \(\mathbb{E}[\mathbf{v}^{}_i\mathbf{v}^\top _i] = \mathbf{I}\). Then,</p> \[\text{tr}[\mathbf{A}] = \frac{1}{V} \sum_{i=1}^{V} \mathbf{v}_i^\top \mathbf{A} \mathbf{v}_i.\] <p>In practice, we only use one sample to estimate the trace. Although the trace estimation is unbiased, since we always truncate the original infinite series at \(N\) terms, the overall estimate will be biased.</p> <p>To make the estimator unbiased, we need to introduce some randomness into the truncation and take an expectation. Fortunately, we can use the “Russian roulette” estimator. The formula for the estimator is quite involved so we present a high-level intuition. The basic idea is that we always evaluate the first term and to determine whether we should evaluate the remaining terms we flip a coin that has probability \(p\) of coming up heads. If the remaining terms are evaluated then they are reweighted by \(\frac{1}{p}\) which results in an unbiased estimate. Futhermore, the estimate has probability \(1 - p\) of being evaluated in finite time (the case where we only evaluate the first term). Interesingly, we can obtain an estimator that is evaluated in finite time with probability one. We simply have to apply this process infinitely many times to the terms that have yet to be computed. Eventually, we are gauranteed to flip a tail and stop computing. Also, just like before we use the Hutchinson trace estimator to estimate the trace of the matrix in each term. Thus, we can compute this infinite series as:</p> \[\mathbb{E}_{n, \mathbf{v}}\left[\sum_{k=1}^{n} \frac{(-1)^{k+1}}{\mathbb{P}(N \geq k)} \mathbf{v}^\top\left[\left(\frac{\partial g_{\theta_t}}{\partial \mathbf{x}}\right)^k\right]\mathbf{v}\right],\] <p>where \(n \sim p(N)\) for some distribution \(p\) and \(\mathbf{v} \sim \mathcal{N}(0,1)\).</p> <h2 id="summary">Summary</h2> <p>To summarize, we have introduced normalizing flows, a class of generative models that learn an invertible transformation between a noise distribution \(p\) and a data distribution \(q\). We briefly covered some normalizing flow methods such as NICE that impose specific architectural constraints to ensure an invertible neural network and computable Jacobian. We discussed residual flows in detail which avoid exotic architecture design by using invertible ResNets. Relatively simple design choices can ensure that ResNets are invertible. Then we discussed how to compute an unbiased estimator of the Jacobian in the case of residual flows. Overall, normalizing flows are a powerful framework for generative modeling. Their main drawbacks include the limitation regarding architecture design and the high computational cost of the determinant of the Jacobian. In the next blog post, we will attempt to address these issues with continuous normalizing flows.</p>]]></content><author><name>Robin Yadav</name></author><category term="generative-models"/><category term="normalizing-flows"/><category term="residual-flows"/><category term="probability"/><category term="flow-matching"/><summary type="html"><![CDATA[This is the beginning in a series of blog posts about flow matching and its generalizations. We start by covering normalizing flows, the foundation for flow matching methods.]]></summary></entry><entry><title type="html">Markov Chains</title><link href="https://dsl-lab.github.io/blog/2023/markov-chains/" rel="alternate" type="text/html" title="Markov Chains"/><published>2023-07-12T00:00:00+00:00</published><updated>2023-07-12T00:00:00+00:00</updated><id>https://dsl-lab.github.io/blog/2023/markov-chains</id><content type="html" xml:base="https://dsl-lab.github.io/blog/2023/markov-chains/"><![CDATA[<h2 id="markov-chains-definitions-and-representations">Markov Chains: Definitions and Representations</h2> <p>A stochastic process $X = { x(t): t\in T}$ is a collection of random variables. There are two elements:</p> <ul> <li>Time $t$: <ul> <li>discrete time ($T$ is a countably infinite set; under this case, we call <strong>Markov chain</strong>)</li> <li>continuous time (under this case, we call <strong>Markov process</strong>)</li> </ul> </li> <li>Space $\Omega$: <ul> <li>discrete space ($X_{t}$ comes from a countably infinite set)</li> <li>continuous space.</li> </ul> </li> </ul> <p>Markov chain is a <strong>discrete-time</strong> process for which the future behaviour, given the past and the present, only depends on the present and not on the past.</p> <p>Markov process is the <strong>continuous-time</strong> version of a Markov chain.</p> <blockquote> <p>Definition 1. [Markov chain] A discrete time stochastic process $ X_0, X_1, X_2, $. . . is a Markov chain if the following Markov property holds:</p> </blockquote> \[\small P(X_{t} = a_t \vert X_{t-1} = a_{t-1}, X_{t-2} = a_{t-2}, ..., X_0 = a_0) = P(X_{t} = a_t \vert X_{t-1} = a_{t-1}) = P_{a_{t-1}, a_{t}}\] <p><em>Remark 1</em>: This is time-homogeneous markov chain, for $\forall t$, for $\forall a_{t-1}, a_{t} \in \Omega$, the transition probability $P_{a_{t-1}, a_{t} }$ is the same.</p> <p><em>Remark 2</em>: In DDPM <d-cite key="ho2020denoising"></d-cite>, it is not a time-homogeneous chain, as the transition probability at t is obtained by a network(t).</p> <p>The state $X_{t}$ depends on the previous state $X_{t-1}$ but is independent of the particular history $X_{t-2}, X_{t-3},…$. This is called the <strong>Markov property</strong> or <strong>memoryless property</strong>.</p> <p>The Markov property does not imply that $X_{t}$ is independent of the random variables $X_{0}$, $X_{1}$,…, $X_{t-2}$; it just implies that <strong>any dependency of $X_{t}$ on the past is captured in the value of $X_{t-1}$</strong>.</p> <p>The Markov chain is <strong>uniquely</strong> defined by the one-step transition probability matrix $P$:</p> \[P = \begin{pmatrix} P_{0,0} &amp; P_{0, 1} &amp; \cdots &amp; P_{0, j} &amp; \cdots\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots&amp; \vdots\\ P_{i,0} &amp; P_{i, 1} &amp; \cdots &amp; P_{i, j} &amp; \cdots\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots&amp; \vdots\\ \end{pmatrix},\] <p>where $P_{i,j}$ is the probability of transition from state $i$ to state $j$. $P_{i,j} = P(X_{t} = j \vert X_{t-1} = i), i,j \in \Omega$. $\forall i, \sum_{j \geq 0} P_{i,j} = 1$.</p> <h2 id="classification-of-states">Classification of States</h2> <p>For simplicity, we assume that the state space $\Omega$ is finite. Below we introduce some concepts related to the classification of states.</p> <h3 id="communicating-class">Communicating class</h3> <blockquote> <p>Definition 2. [Communicating class] A state $j$ is reachable from state $i$ if there exists a positive integer $n$ such that $P_{i,j}^{(n)} &gt; 0$. We write $i \rightarrow j$. If $j$ is reachable from $i$, and $i$ is reachable from $j$, then the states $i$ and $j$ are said to <strong>communicate</strong>, denoted by $i \leftrightarrow j$. A communicating class $C$ is a <strong>maximal</strong> set of states that communicate with each other. <strong>No state in $C$ communicates with any state not in $C$.</strong></p> </blockquote> <h3 id="irreducible-markov-chain">Irreducible Markov chain</h3> <blockquote> <p>Definition 3. [Irreducibility] A Markov chain is <strong>irreducible</strong> if all states belong to <strong>one</strong> communicating class.</p> </blockquote> <p>This means that <strong>any state can be reached from any other state</strong>, <em>i.e.,</em> $\forall i, j \in \Omega$, $P_{i,j} &gt; 0$.</p> <blockquote> <p>Lemma 1. A finite Markov chain is irreducible if and only if its graph representation is a strongly connected graph.</p> </blockquote> <h3 id="transient-vs-recurrent-states">Transient vs recurrent states</h3> <p>Let $r_{i,j}^{t}$ denote the probability that the chain, starting at state $i$, <strong>the first time</strong> transition to state $j$ occurs at time $t$. That is, $ r_{i,j}^{t} = P(X_{t} = j, X_{s} \neq j, \forall 1 \leq s \leq t-1 \vert X_{0} = i). $</p> <blockquote> <p>Definition 4. [Transient and Recurrent States] A state is <strong>recurrent</strong> if $\sum_{t \geq 1} r_{i,i}^{t} = 1$ and it is <strong>transient</strong> if $\sum_{t \geq 1} r_{i,i}^{t} &lt; 1$. A Markov chain is recurrent if every state in the chain is recurrent.</p> </blockquote> <ul> <li> <p>If state i is recurrent then, once the chain visits that state, it will (with probability 1) eventually return to that state. Hence the chain will visit state $i$ over and over again, <strong>infinitely</strong> often.</p> </li> <li> <p>A transient state has the property that a Markov chain starting at this state returns to this state only <strong>finitely often</strong>, with probability 1.</p> </li> <li> <p>If one state in a communicating class is transient (respectively, recurrent) then all states in that class are transient (respectively, recurrent).</p> </li> </ul> <blockquote> <p>Definition 5. An irreducible Markov chain is called recurrent if at least one (equivalently, every) state in this chain is recurrent. An irreducible Markov chain is called transient if at least one (equivalently, every) state in this chain is transient.</p> </blockquote> <p>Let $\mu_{i} = \sum_{t \geq 1} t \cdot r_{i,i}^{t}$ denote the expected time to return to state $i$ when starting at state $i$.</p> <blockquote> <p>Definition 6. A state $i$ is <strong>positive recurrent</strong> if $\mu_{i} &lt; \infty$ and <strong>null recurrent</strong> if $\mu_{i} = \infty$.</p> </blockquote> <p>Here we give an example of a Markov chain that has null recurrent states. Consider the following markov chain whose states are the positive integers.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2023/markov-chains/image-480.webp 480w,/blog/2023/markov-chains/image-800.webp 800w,/blog/2023/markov-chains/image-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2023/markov-chains/image.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Starting at state 1, the probability of not having returned to state 1 within the first $t$ steps is \(\prod_{j=1}^{t} \frac{j}{j+1} = \frac{1}{t+1}.\) The probability of never returning to state 1 from state 1 is 0, and state 1 is recurrent. Thus, the probability of the first time transition to state $1$ occurs at time $t$ is \(r_{1,1}^{t} = \frac{1}{t} \cdot \frac{1}{t+1} = \frac{1}{t(t+1)}.\) The expected number of steps until the first return to state 1 when starting at state 1 is \(\mu_{1} = \sum_{t = 1}^{\infty} t \cdot r_{1,1}^{t} = \sum_{t = 1}^{\infty} \frac{1}{t+1} = \infty.\) State 1 is recurrent but null recurrent.</p> <blockquote> <p>Lemma 2. In a finite Markov chain:</p> <ol> <li>at least one state is recurrent; and</li> <li>all recurrent states are positive recurrent.</li> </ol> </blockquote> <p>Thus, all states of a finite, irreducible Markov chain are positive recurrent.</p> <h3 id="periodic-vs-aperiodic-states">Periodic vs aperiodic states</h3> <blockquote> <p>Definition 7. A state $j$ in a discrete time Markov chain is <strong>periodic</strong> if there exists an integer $k&gt;1$ such that $P(X_{t+s}= j \vert X_t = j) = 0$ unless $s$ is divisible by $k$. A discrete time Markov chain is periodic if any state in the chain is periodic. A state or chain that is not periodic is <strong>aperiodic</strong>.</p> </blockquote> <p>A state $i$ is periodic means that for $s = k, 2k, 3k,…$, $P(X_{t+s}= j \vert X_t = j) &gt; 0$ (<strong>N.B.: k &gt; 1</strong>).</p> <h3 id="ergodicity">Ergodicity</h3> <blockquote> <p>Definition 8. An <strong>aperiodic</strong>, <strong>positive recurrent</strong> state is an <strong>ergodic</strong> state. A Markov chain is ergodic if all its states are ergodic.</p> </blockquote> <blockquote> <p>Corollary 1. Any finite, irreducible, and aperiodic Markov chain is an ergodic chain.</p> </blockquote> <h3 id="stationary-distribution">Stationary distribution</h3> <p>Consider the two-state “broken printer” Markov chain:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2023/markov-chains/2023-07-22-11-00-52-480.webp 480w,/blog/2023/markov-chains/2023-07-22-11-00-52-800.webp 800w,/blog/2023/markov-chains/2023-07-22-11-00-52-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/2023/markov-chains/2023-07-22-11-00-52.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Transition diagram for the two-state broken printer chain. </div> <p>There are two state (0 and 1) in this Markov chain, and assume that the initial distribution is:</p> \[P(X_0 = 0) = \frac{\beta}{\alpha+\beta}, P(X_0 = 1) = \frac{\alpha}{\alpha+\beta}.\] <p>Then, according to the transition probability matrix $P$, after one step, the distribution is</p> \[\small \begin{align*} P(X_1 = 0) &amp;= P(X_0 = 0)P(X_1 = 0 \vert X_0 = 0) + P(X_0 = 1)P(X_1 = 0 \vert X_0 = 1) \\ &amp;= \frac{\beta}{\alpha+\beta} \cdot (1-\alpha) + \frac{\alpha}{\alpha+\beta} \cdot \beta = \frac{\beta}{\alpha+\beta}, \\ P(X_1 = 1) &amp;= P(X_0 = 0)P(X_1 = 1 \vert X_0 = 0) + P(X_0 = 1)P(X_1 = 1 \vert X_0 = 1) \\ &amp;= \frac{\beta}{\alpha+\beta} \cdot \alpha + \frac{\alpha}{\alpha+\beta} \cdot (1-\beta) = \frac{\alpha}{\alpha+\beta}. \end{align*}\] <p>Apparently, the distribution of $X_1$ is the same as the initial distribution. Similarly, we can prove that the distribution of $X_t$ is the same as the initial distribution for any $t$. Here, $\pi = (\frac{\beta}{\alpha+\beta}, \frac{\alpha}{\alpha+\beta})$ is called <strong>stationary distribution</strong>.</p> <blockquote> <p>Definition 9. A probability distribution $\pi = (\pi_i)$, $\sum_{i \in \Omega} \pi_i = 1$(<strong>row vector</strong>) on the state space $\Omega$ is called a <strong>stationary distribution</strong> (or an equilibrium distribution) for the Markov chain with transition probability matrix $P$ if $\pi = \pi P$, equivalently, $\pi_j = \sum_{i \in \Omega}\pi_i P_{i,j}$ for all $j \in \Omega$.</p> </blockquote> <ul> <li> <p>One interpretation of the stationary distribution: if we started off a <strong>thousand</strong> Markov chains, choosing each starting position to be state $i$ with probability $\pi_i$, then(roughly) <strong>$1000 \pi_j$</strong> of them would be in state $j$ at any time in the future – but not necessarily the same ones each time.</p> </li> <li> <p>If a chain ever reaches a stationary distribution then it maintains that distribution for all future time, and thus a stationary distribution represents a steady state or an equilibrium in the chain’s behavior.</p> </li> </ul> <h3 id="finding-a-stationary-distribution">Finding a stationary distribution</h3> <p>Consider the following no-claims discount Markov chain with state space $\Omega = {1,2,3}$ and transition matrix:</p> \[P = \begin{pmatrix} \frac{1}{4} &amp; \frac{3}{4} &amp; 0\\ \frac{1}{4} &amp; 0 &amp; \frac{3}{4}\\ 0 &amp; \frac{1}{4} &amp; \frac{3}{4} \end{pmatrix}.\] <ul> <li> <p>Step 1: Assume $\pi = {\pi_1, \pi_2, \pi_3} $ is a stationary distribution. According to the definition 9 of stationary distribution, we need to solve the following equations:</p> \[\begin{align*} \pi_1 &amp;= \frac{1}{4}\pi_1 + \frac{1}{4}\pi_2, \\ \pi_2 &amp;= \frac{3}{4}\pi_1 + \frac{1}{4}\pi_3, \\ \pi_3 &amp;= \frac{3}{4}\pi_2 + \frac{3}{4}\pi_3. \end{align*}\] <p>Adding the normalising condition $\pi_1 + \pi_2 + \pi_3 = 1$, we get four equations in three unknown parameters.</p> </li> <li> <p>Step 2: Choose one of the parameters, say $\pi_1$, and solve for the other two parameters in terms of $\pi_1$. We get</p> \[\pi_1 = \frac{1}{4}\pi_1 + \frac{1}{4}\pi_2 \Rightarrow \pi_2 = 3\pi_1, \pi_3 = 3\pi_2 = 9\pi_1.\] </li> <li> <p>Step 3: Combining with the normalising condition, we get</p> \[\pi_1 + 3\pi_1 + 9\pi_1 = 1 \Rightarrow \pi_1 = \frac{1}{13}, \pi_2 = \frac{3}{13}, \pi_3 = \frac{9}{13}.\] <p>Finally, we get the stationary distribution $\pi = (\frac{1}{13}, \frac{3}{13}, \frac{9}{13})$.</p> </li> </ul> <h3 id="existence-and-uniqueness">Existence and uniqueness</h3> <p>Given a Markov chaine, how can we know whether it has a stationary distribution? If it has, is it unique? At this part, we will answer these questions.</p> <p>Some notations:</p> <ul> <li> <p>Hitting time to hit the state $j$: $H_{j} = \min \{ t \in \{0, 1, 2,…\}: X_t = j\}$. Note that here we include time $t = 0$.</p> </li> <li> <p>Hitting probability to hit the state $j$ staring from state $i$: $h_{i,j} = P(X_t = j, \text{for some} \ t \geq 0 \vert X_0 = i) = P(H_{j} &lt; \infty \vert X_0 = i) = \sum_{t \geq 0} r_{i,j}^{t}.$</p> </li> </ul> <p>Note that this is different from $r_{i,j}^{t}$, which denotes the probability that the chain, starting at state $i$, the <strong>first</strong> time transition to state $j$ <strong>occurs at time $t$</strong>.</p> <p>We also have</p> \[h_{i,j} = \begin{cases} \sum_{k \in \Omega}P_{i,k}h_{k,j}, &amp; \text{if} \quad j \ne i, \\ 1, &amp; \text{if} \quad j = i. \end{cases}\] <ul> <li> <p><strong>Expected hitting time</strong>: $\eta_{i,j} = \mathbb{E}(H_{j} \vert X_0 = i) = \sum_{t \geq 0} t \cdot r_{i,j}^{t}$. The expected time until we hit state $j$ starting from state $i$. We also have</p> \[\eta_{i,j} = \begin{cases} 1 + \sum_{k \in \Omega}P_{i,k}\eta_{k,j}, &amp; \text{if} \quad j \ne i, \\ 0, &amp; \text{if} \quad j = i. \end{cases}\] <p>(For the first case, we add 1 because we need to consider the first step from state $i$ to state $k$.)</p> </li> <li><strong>Return time</strong>: $M_i = \min \{ t \in \{1, 2,…\}: X_t = i\}$. It is different from $H_{i}$, as we exclude time $t = 0$. It is the first time that the chain returns to state $i$ after $t = 0$.</li> <li><strong>Return probability</strong>: $m_{i} = P(X_t = i \ \text{for some} \ n \geq 1 \vert X_0 = i) = P(M_i &lt; \infty \vert X_0 = i) = \sum_{t&gt;1}r_{i,i}^{t}.$</li> <li><strong>Expected return time</strong>: $\mu_{i} = E(M_i \vert X_0 = i) = \sum_{t \geq 1} t \cdot r_{i,i}^{t}$. The expected time until we return to state $i$ starting from state $i$. Therefore, we have the following equations: $ m_{i} = \sum_{j \in \Omega} P_{i,j}h_{j,i}, \mu_{i} = 1 + \sum_{j \in \Omega} P_{i,j}\eta_{j,i}. $</li> </ul> <h2 id="theorems-on-irreducible-markov-chains">Theorems on Irreducible Markov Chains</h2> <h3 id="existence-and-uniqueness-of-stationary-distribution">Existence and uniqueness of stationary distribution</h3> <blockquote> <p>Theorem 1. Consider an irreducible Markov chain (<strong>finite or infinite</strong>), (1) if it is <strong>positive recurrent</strong>, $\exists$ an unique stationary distribution $\pi$, such that $\pi_i = \frac{1}{\mu_{i}}$. (2) if it is <strong>null recurrent</strong> or <strong>transient</strong>, no stationary distribution exists.</p> </blockquote> <p><em>Remark</em>: If the chain is <strong>finite</strong> irreducible, it must be positive recurrent, thus it has an unique stationary distribution.</p> <p><em>Remark</em>: If the Markov chain is not irreducible, we can decompose the state space into several communicating classes. Then, we can consider each communicating class separately.</p> <ul> <li>If none of the classes are positive recurrent, then no stationary distribution exists.</li> <li>If exactly one of the classes is positive recurrent (and therefore closed), then there exists a unique stationary distribution, supported only on that closed class.</li> <li>If more the one of the classes are positive recurrent, then many stationary distributions will exist.</li> </ul> <p>Now, we give the proof of Theorem 1. We first prove that if a Markov chain is irreducible and positive recurrent, then there <strong>exists</strong> a stationary distribution. Next, we will prove the stationary distribution is <strong>unique</strong>. Since the second part with the null recurrent or transitive Markov chains is less important and more complicated, we will omit it. If you are interested in it, you can refer to the book <a href="https://www.statslab.cam.ac.uk/~james/Markov/">Markov Chains</a> by James Norris <d-cite key="norris1998markov"></d-cite>.</p> <p><em>Proof</em>. (1) Suppose that $(X_0, X_1 …)$ a recurrent Markov chain, which can be positive recurrent or null recurrent. Then we can desigh a stationary distribution as follows. (If we can desigh a stationary distribution, then it must be existed.)</p> <p>Let $\nu_i$ be the expected number of visits to $i$ before we return back to $k$,</p> \[\begin{align*} \nu_i &amp;= \mathbb{E}(\# \text{visits to $i$ before returning to } k \vert X_0 = k) \\ &amp;= \mathbb{E}\sum_{t=1}^{M_k} P(X_t = i \vert X_0 = k) \\ &amp;= \mathbb{E}\sum_{t = 0}^{M_k - 1} P(X_t = i \vert X_0 = k) \end{align*}\] <p>The last equation holds because of $ P(X_0 = i \vert X_0 = k) = 0$ and $ P(X_{M_k} = i \vert X_0 = k) = 0$.</p> <p>If we want design a stationary distribution, it must statisfy $\pi P = \pi$ and $\sum_{i \in \Omega}\pi_i = 1$.</p> <p>(a) We first prove that $\nu P = \nu$.</p> \[\begin{align*} \sum_{i \in \Omega} \nu_i P_{i,j} &amp;= \mathbb{E}\sum_{i \in \Omega} \sum_{t = 0}^{M_k - 1} P(X_t = i, X_{t+1} = j \vert X_0 = k) \\ &amp;= \mathbb{E}\sum_{t = 0}^{M_k - 1} \sum_{i \in \Omega} P(X_t = i, X_{t+1} = j \vert X_0 = k) \\ &amp;= \mathbb{E} \sum_{t = 0}^{M_k - 1} P(X_{t+1} = j \vert X_0 = k) \\ &amp;= \mathbb{E} \sum_{t = 1}^{M_k } P(X_{t} = j \vert X_0 = k) \\ &amp;= \mathbb{E} \sum_{t = 0}^{M_k - 1} \nu_i \\ &amp;= \nu_j. \end{align*}\] <p>(b) Next, what we need to do is to normalize $\nu$ to get a stationary distribution. We have</p> \[\begin{align*} \sum_{i \in \Omega} \nu_i &amp;= \sum_{i \in \Omega} \mathbb{E} \sum_{t = 0}^{M_k - 1} P(X_t = i \vert X_0 = k) \\ &amp;=\mathbb{E} \sum_{t = 0}^{M_k - 1} \sum_{i \in \Omega} P(X_t = i \vert X_0 = k) \\ &amp;= \mathbb{E}(M_k \vert X_0 = i) \\ &amp;= \mu_k. \end{align*}\] <p>Thus, we can define $\pi_i = \nu_i/\mu_k$, $\pi = {\pi_i, i \in \Omega}$ is one of the stationary distribution.</p> <p>(2) Next, we prove that if a Markov chain is irreducible and positive recurrent, then the stationary distribution is <strong>unique</strong> and is given by $\pi_j = \frac{1}{\mu_j}$.</p> <p>Given a stationary distribution $\pi$, if we prove that for all $i$, $\pi_j == \frac{1}{\mu_j}$, then we prove that the stationary distribution is unique.</p> <p>Remember that the expected hitting time:</p> <p>\begin{equation} \eta_{i,j} = 1 + \sum_{k \in \Omega}P_{i,k}\eta_{k,j}, j \ne i \label{eq:1} \end{equation}</p> <p>We multiply both sides of Eq. \eqref{eq:1} by $\pi_i$ and sum over $i (i \ne j)$ to get</p> <p>\begin{equation} \sum_{i \ne j} \pi_i \eta_{i,j} = \sum_{i \ne j} \pi_i + \sum_{i \ne j} \sum_{k \in \Omega} \pi_i P_{i,k}\eta_{k,j} \label{eq:2} \end{equation}</p> <p>Since $\eta_{j,j} = 0$, we can rewrite the above equation as</p> <p>\begin{equation} \sum_{i \in \Omega} \pi_i \eta_{i,j} = \sum_{i \ne j} \pi_i + \sum_{i \ne j} \sum_{k \in \Omega} \pi_i P_{i,k}\eta_{k,j}. \label{eq:3} \end{equation}</p> <p>(The above equality lacks $j$, and we also want to design $\pi_j = 1/\mu_j$.)</p> <p>Remember that the expected return time:</p> \[\mu_{j} = 1 + \sum_{i \in \Omega} P_{j,i}\eta_{i,j}.\] <p>We multiply both sides of Eq. \eqref{eq:2} by $\pi_j$ to get</p> <p>\begin{equation} \pi_j \mu_{j} =\pi_j + \sum_{k \in \Omega} \pi_j P_{j,k}\eta_{k,j} \label{eq:4} \end{equation}</p> <p>Adding Eq. \eqref{eq:2} and Eq. \eqref{eq:4}, we get</p> \[\begin{align*} \sum_{i \in \Omega} \pi_i \eta_{i,j} + \pi_j \mu_{j} &amp;= \sum_{i \in \Omega} \pi_i + \sum_{i \in \Omega} \sum_{k \in \Omega} \pi_i P_{i,k}\eta_{k,j} \\ &amp;= 1 + \sum_{k \in \Omega} \sum_{i \in \Omega} \pi_i P_{i,k}\eta_{k,j} \\ &amp;= 1 + \sum_{k \in \Omega} \pi_k \eta_{k,j} \qquad (\text{since} \sum_{i \in \Omega} \pi_i P_{i,k} = \pi_k) \\ \end{align*}\] <p><strong>Since the Markov chain is irreducible and positive recurrent, that means all states belong to a communication class and the expected return time of each state is finite. Thus, the space $\Omega$ is a finite dimensional space.</strong></p> <p>We can substract $\sum_{k \in \Omega} \pi_k \eta_{k,j}$ and $\sum_{i \in \Omega} \pi_i \eta_{i,j} $ (equal) from both sides of the above equation to get $ \pi_j \mu_{j}=1, $ which means $\pi_j = 1/\mu_j$. Similarly, we can prove that $\pi_i = 1/\mu_i$ for all $i \in \Omega$.</p> <h3 id="limit-theorem">Limit theorem</h3> <blockquote> <p>Theorem 2. [Limit theorem] Consider an irreducible, aperiodic Markov chain (maybe infinite), we have $\lim\limits_{t \to \infty} P_{i,j}^{t} = \frac{1}{\mu_{j}}$. Spectially, (1) Suppose the Markov chain is positive recurrent. Then $\lim\limits_{t \to \infty} P_{i,j}^{t} = \pi_j = \frac{1}{\mu_{j}}$. (2) Suppose the Markov chain is null recurrent or transient. Then there is no limite probability.</p> </blockquote> <p>Three conditions for convergence to an equilibrium probability distribution: irreducibility, aperiodicity, and positive recurrence. The limit probability is</p> \[P = \begin{pmatrix} \pi_1 &amp; \pi_2 &amp; \cdots &amp; \pi_N\\ \pi_1 &amp; \pi_2 &amp; \cdots &amp; \pi_N\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\ \pi_1 &amp; \pi_2 &amp; \cdots &amp; \pi_N\\ \end{pmatrix},\] <p>where each row is identical.</p> <h3 id="ergodic-theorem">Ergodic theorem</h3> <p>Define $V_{i,j}^{t} = \vert{ n &lt; t \vert X_n = j}\vert$. $V_{i,j}^{t}$ is the number of visits to state $j$ before time $t$ starting from state $i$. Then we can interpret $V_{i,j}^{t}/t$ as the proportion of time up to time $t$ spent in state $j$.</p> <blockquote> <p>Theorem 3. [Ergodic theorem] Consider an irreducible Markov chain, we have $\lim\limits_{t \to \infty} V_{i,j}^{t}/t = \frac{1}{\mu_{j}}$ <strong>almost surely</strong>. Spectially, (1) Suppose the Markov chain is positive recurrent. Then $\lim\limits_{t \to \infty} V_{i,j}^{t}/t = \pi_j = \frac{1}{\mu_{j}}$ <strong>almost surely</strong>. (2) Suppose the Markov chain is null recurrent or transient. Then $ V_{i,j}^{t}/t \to 0$ <strong>almost surely</strong> for all $j$.</p> </blockquote> <p>The term <strong>almost surely</strong> means that the convergence probability of the event is 1.</p> <h3 id="detailed-balance-condition">Detailed balance condition</h3> <blockquote> <p>Theorem 4. [Detailed balance condition]. Consider a finite, irreducible, and ergodic Markov chain with transition matrix $P$. If there are nonnegative numbers $\bar{\pi} = (\pi_0, \pi_1, …, \pi_n)$ such that $\sum_{i=0}^{n} \pi_i = 1$ and if, for any pair of states $i, j$, $ \pi_i P_{i,j} = \pi_{j} P_{j,i}, $ then $\bar{\pi}$ is the stationary distribution corresponding to $P$.</p> </blockquote> <p><em>Proof</em>. We have $ \sum_{i} \pi_i P_{i,j} = \sum_{i}\pi_{j} P_{j,i} = \pi_{j} $ Thus, $\bar{\pi} = \bar{\pi}P$. Since this is a finite, irreducible, and ergodic Markov chain, $\bar{\pi}$ must be the unique stationary distribution of the Markov chain.</p> <p><em>Remark</em>: Theorem 4 is a sufficient but not necessary condition.</p> <h2 id="further-reading">Further Reading</h2> <p>We have introduced the basic concepts of Markov chains, including the definition, classification of states, and theorems on irreducible Markov chains. If you are interested in more details, you can refer to the following materials:</p> <ul> <li>Mitzenmacher, M., &amp; Upfal, E. (2005). Probability and Computing. Cambridge University Press.</li> <li><a href="https://mpaldridge.github.io/math2750/S09-recurrence-transience.html">Recurrence and transience</a></li> <li><a href="https://mpaldridge.github.io/math2750/S07-classes.html">Class structure</a></li> <li><a href="https://mpaldridge.github.io/math2750/S10-stationary-distributions.html">Stationary distributions</a></li> <li>Stirzaker, David. <a href="https://www.ctanujit.org/uploads/2/5/3/9/25393293/_elementary_probability.pdf">Elementary Probability</a></li> </ul>]]></content><author><name>Xue Yu</name></author><category term="probability,"/><category term="random-process,"/><category term="Markov-chain"/><summary type="html"><![CDATA[An introduction to Markov Chains.]]></summary></entry></feed>