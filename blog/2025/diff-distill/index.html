<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>A Unified Framework for Diffusion Distillation | Laboratory for Deep Structured Learning</title> <meta name="author" content=" "> <meta name="description" content="The explosive growth in one-step and few-step diffusion models has taken the field deep into the weeds of complex notations. In this blog, we cut through the confusion by proposing a coherent set of notations that reveal the connections among these methods."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://dsl-lab.github.io/blog/2025/diff-distill/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "A Unified Framework for Diffusion Distillation",
      "description": "The explosive growth in one-step and few-step diffusion models has taken the field deep into the weeds of complex notations. In this blog, we cut through the confusion by proposing a coherent set of notations that reveal the connections among these methods.",
      "published": "August 21, 2025",
      "authors": [
        {
          "author": "Yuxiang Fu",
          "authorURL": "https://felix-yuxiang.github.io/",
          "affiliations": [
            {
              "name": "UBC",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Laboratory for Deep Structured Learning</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blogs<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/members/">members</a> </li> <li class="nav-item "> <a class="nav-link" href="/photo/">photos</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>A Unified Framework for Diffusion Distillation</h1> <p>The explosive growth in one-step and few-step diffusion models has taken the field deep into the weeds of complex notations. In this blog, we cut through the confusion by proposing a coherent set of notations that reveal the connections among these methods.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#introduction">Introduction</a></div> <div><a href="#notation-at-a-glance">Notation at a Glance</a></div> <div><a href="#ode-distillation-methods">ODE Distillation methods</a></div> <div><a href="#"></a></div> <ul> <li><a href="#meanflow">MeanFlow</a></li> <li><a href="#consistency-models">Consistency Models</a></li> <li><a href="#flow-anchor-consistency-model">Flow Anchor Consistency Model</a></li> <li><a href="#align-your-flow">Align Your Flow</a></li> </ul> <div><a href="#connections">Connections</a></div> <div><a href="#"></a></div> <ul> <li><a href="#shortcut-models">Shortcut Models</a></li> <li><a href="#reflow">ReFlow</a></li> <li><a href="#inductive-moment-matching">Inductive Moment Matching</a></li> </ul> <div><a href="#closing-thoughts">Closing Thoughts</a></div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>Diffusion and flow-based models<d-cite key="ho2020denoising, lipman_flow_2023, albergo2023stochastic, liu2022flow"></d-cite> have taken over the generative AI space, enabling unprecedented capabilities in videos, audios, and text generation. Nonetheless, there is a caveat⚠️ — they are painfully <strong>slow</strong> during inference. Generating a single high-quality sample requires running through hundreds of denoising steps, which translate to high costs and long wait times.</p> <p>At its core, diffusion models (equivalently, flow matching models) operate by iteratively refining noisy data into high-quality outputs through a series of denoising steps. Similar to divide-and-conquer algorithms <d-footnote>Common ones like Mergesort, locating the median and Fast Fourier Transform.</d-footnote>, diffusion models first <em>divide</em> the difficult denoising task into subtasks and <em>conquer</em> one of these at a time during training. To obtain a sample, we make a sequence of recursive predictions which means we need to <em>conquer</em> the entire task end-to-end.</p> <p>This challenge has spurred research into acceleration strategies across multiple granular levels, including hardware optimization, mixed precision training<d-cite key="micikevicius2017mixed"></d-cite>, <a href="https://github.com/bitsandbytes-foundation/bitsandbytes" rel="external nofollow noopener" target="_blank">quantization</a>, and parameter-efficient fine-tuning<d-cite key="hu2021lora"></d-cite>. In this blog, we focus on an orthogonal approach, <strong>ODE distillation</strong>, which minimize Number of Function Evaluations (NFEs) so that we can generate high-quality samples with as few denoising steps as possible.</p> <p>Distillation, in general, is a technique that transfers knowledge from a complex, high-performance model (the <em>teacher</em>) to a more efficient, customized model (the <em>student</em>). Recent distillation methods have achieved remarkable reductions in sampling steps, from hundreds to a few and even <strong>one</strong> step, while preserving the sample quality. This advancement paves the way for real-time applications and deployment in resource-constrained environments.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/blog/2025/diff-distill/diff-distill.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls="" loop=""></video> </figure> </div> </div> <h2 id="notation-at-a-glance">Notation at a Glance</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/diff-distill/teaser_probpath_velocity_field-480.webp 480w,/blog/2025/diff-distill/teaser_probpath_velocity_field-800.webp 800w,/blog/2025/diff-distill/teaser_probpath_velocity_field-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/blog/2025/diff-distill/teaser_probpath_velocity_field.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> From left to right:<d-cite key="lipman2024flowmatchingguidecode"></d-cite>conditional and marginal probability paths, conditional and marginal velocity fields. The velocity field induces a flow that dictates its instantaneous movement across all points in space. </div> <p>The modern approaches of generative modelling consist of picking some samples from a base distribution \(\mathbf{x}_1\sim p_{\text{noise}}\), typically an isotropic Gaussian, and learning a map such that \(\mathbf{x}_0\sim p_{\text{data}}\). The connection between these two distributions can be expressed by establishing an initial value problem controlled by the <strong>velocity field</strong> $v(\mathbf{x}_t, t)$,</p> \[\require{physics} \begin{equation} \dv{\psi_t(\mathbf{x}_t)}{t}=v(\psi_t(\mathbf{x}_t), t),\quad\psi_0(\mathbf{x}_0)=\mathbf{x}_0,\quad \mathbf{x}_0\sim p_{\text{data}} \label{eq:1} \end{equation}\] <p>where the <strong>flow</strong> $\psi_t:\mathbb{R}^d\times[0,1]\to \mathbb{R}^d$ is a diffeomorphic map with \(\psi_t(\mathbf{x}_t)\) defined as the solution to the above ODE (\ref{eq:1}). If the flow satisfies the push-forward equation<d-footnote>This is also known as the change of variable equation: $[\phi_t]_\# p_0(x) = p_0(\phi_t^{-1}(x)) \det \left[ \frac{\partial \phi_t^{-1}}{\partial x}(x) \right].$</d-footnote> \(p_t=[\psi_t]_\#p_0\), we say a <strong>probability path</strong> \((p_t)_{t\in[0,1]}\) is generated from the velocity vector field. The goal of flow matching<d-cite key="lipman_flow_2023"></d-cite> is to find a velocity field \(v_\theta(\mathbf{x}_t, t)\) so that it transforms \(\mathbf{x}_1\sim p_{\text{noise}}\) to \(\mathbf{x}_0\sim p_{\text{data}}\) when integrated. In order to receive supervision at each time step, one must predefine a condition probability path \(p_t(\cdot \vert \mathbf{x}_0)\)<d-footnote>In practice, the most common one is the Gaussian conditional probability path. This arises from a Gaussian conditional vector field, whose analytical form can be derived from the continuity equation. $$\frac{\partial p_t}{\partial t} + \nabla \cdot (p_t v) = 0$$ See the table for details.</d-footnote> associated with its velocity field. For each datapoint \(\mathbf{x}_0\in \mathbb{R}^d\), let \(v(\mathbf{x}_t, t\vert\mathbf{x}_0)=\mathbb{E}_{p_t(v_t \vert \mathbf{x}_0)}[v_t]\) denote a conditional velocity vector field so that the corresponding ODE (\ref{eq:1}) yields the conditional flow.</p> <p>Most of the conditional probability paths are designed as the <strong>differentiable</strong> interpolation between noise and data for simplicity, and we can express sampling from a marginal path \(\mathbf{x}_t = \alpha(t)\mathbf{x}_0 + \beta(t)\mathbf{x}_1\) where \(\alpha(t), \beta(t)\) are predefined schedules. <d-footnote>The stochastic interpolant paper defines this probability path that summarizes all diffusion models, with several assumptions. Here, we use a simpler interpolant for clean illustration.</d-footnote></p> <p>We provide some popular instances <d-footnote>We ignore the diffusion models with SDE formulation like DDPM<d-cite key="ho2020denoising"></d-cite> or ScoreSDE<d-cite key="song2020score"></d-cite> on purpose since we concentrate on ODE distillation in this blog.</d-footnote> of these schedules in the table below.</p> <table> <thead> <tr> <th>Method</th> <th>Probability Path \(p_t\)</th> <th>Vector Field \(u(\mathbf{x}_t, t\vert\mathbf{x}_0)\)</th> </tr> </thead> <tbody> <tr> <td>Gaussian</td> <td>\(\mathcal{N}(\alpha(t)\mathbf{x}_0,\beta^2(t)I_d)\)</td> <td>\(\left(\dot{\alpha}_t - \frac{\dot{\beta}_t}{\beta_t}\alpha_t\right) \mathbf{x}_0 + \frac{\dot{\beta}_t}{\beta_t}\mathbf{x}_1\)</td> </tr> <tr> <td>FM <d-cite key="lipman_flow_2023"></d-cite> </td> <td>\(\mathcal{N}(t\mathbf{x}_1, (1-t+\sigma t)^2I_d)\)</td> <td>\(\frac{\mathbf{x}_1 - (1-\sigma)\mathbf{x}_t}{1-\sigma+\sigma t}\)</td> </tr> <tr> <td>iCFM <d-cite key="liu2022flow"></d-cite> </td> <td>\(\mathcal{N}( t\mathbf{x}_1 + (1-t)\mathbf{x}_0, \sigma^2I_d)\)</td> <td>\(\mathbf{x}_1 - \mathbf{x}_0\)</td> </tr> <tr> <td>OT-CFM <d-cite key="tong2023improving"></d-cite> </td> <td>Same prob. path above with \(q(z) = \pi(\mathbf{x}_0, \mathbf{x}_1)\)</td> <td>\(\mathbf{x}_1 - \mathbf{x}_0\)</td> </tr> <tr> <td>VP-SI <d-cite key="albergo2023stochastic"></d-cite> </td> <td>\(\mathcal{N}( \cos(\pi t/2)\mathbf{x}_0 + \sin(\pi t/2)\mathbf{x}_1, \sigma^2I_d)\)</td> <td>\(\frac{\pi}{2}(\cos(\pi t/2)\mathbf{x}_1 - \sin(\pi t/2)\mathbf{x}_0)\)</td> </tr> </tbody> </table> <p>The simplest form of conditional probability path is \(\mathbf{x}_t = (1-t)\mathbf{x}_0 + t\mathbf{x}_1\) with the corresponding default conditional velocity field OT target \(v(\mathbf{x}_t, t \vert \mathbf{x}_0)=\mathbb{E}[\dot{\mathbf{x}}_t\vert \mathbf{x}_0]=\mathbf{x}_1- \mathbf{x}_0.\)</p> <p>Borrowed from this <a href="https://rectifiedflow.github.io/assets/slides/icml_07_distillation.pdf" rel="external nofollow noopener" target="_blank">slide</a> at ICML2025, the objectives of ODE distillation have been categorized into three cases, i.e., (a) <strong>forward loss</strong>, (b) <strong>backward loss</strong> and (c) <strong>self-consistency loss</strong>.</p> <p><span style="color: blue; font-weight: bold;">Training</span>: Since minimizing the conditional Flow Matching (FM) loss is equivalent to minimize the marginal FM loss<d-cite key="lipman_flow_2023"></d-cite>, the optimization problem becomes</p> \[\arg\min_\theta\mathbb{E}_{\mathbf{x}_0, \mathbf{x}_1, t} \left[ w(t) \left\| v_\theta(\mathbf{x}_t, t) - v(\mathbf{x}_t, t | \mathbf{x}_0) \right\|_2^2 \right]\] <p>where \(w(t)\) is a reweighting function<d-footnote>The weighting function modulates the contribution of the loss at each time step. This is necessary because the nature of the task differs fundamentally between high and low noise levels, requiring a balanced treatment of the loss across these regimes. Some common ones are included in this blog https://diffusionflow.github.io/.</d-footnote>.</p> <p><span style="color: orange; font-weight: bold;">Sampling</span>: Solve the ODE \(\require{physics} \dv{\mathbf{x}_t}{t}=v_\theta(\mathbf{x}_t, t)\) from the initial condition \(\mathbf{x}_1\sim p_{\text{noise}}.\) Typically, an Euler solver or another high-order ODE solver is employed, taking a few hundred discrete steps through iterative refinements.</p> <h2 id="ode-distillation-methods">ODE Distillation methods</h2> <p>Before introducing ODE distillation methods, it is imperative to define a general continuous-time flow map \(f_{t\to s}(\mathbf{x}_t, t, s)\)<d-cite key="boffi2025build"></d-cite> where it maps any noisy input \(\mathbf{x}_t, t\in[0,1]\) to any point \(\mathbf{x}_s, s\in[0,1]\) on the ODE (\ref{eq:1}) that describes the probability flow aformentioned. This is a generalization of flow-based distillation and consistency models within a single unified framework. The flow map is well-defined only if its <strong>boundary conditions</strong> satisfy \(f_{t\to t}(\mathbf{x}_t, t, t) = \mathbf{x}_t\) for all time steps. One popular way to meet the condition is to parameterize the model as \(f_{t\to s}(\mathbf{x}_t, t, s)= c_{\text{skip}}(t, s)\mathbf{x}_t + c_{\text{out}}(t,s)F_{t\to s}(\mathbf{x}_t, t, s)\) where \(c_{\text{skip}}(t, t) = 1\) and \(c_{\text{out}}(t, t) = 0\) for all \(t\).</p> <p>At its core, ODE distillation boils down to how to strategically construct the training objective of the flow map \(f_{t\to s}(\mathbf{x}_t, t, s)\) so that it can be efficiently evaluated during sampling. In addition, we need to orchestrate the schedule of \((t,s)\) pairs for better training dynamics.</p> <p>In the context of distillation, the forward direction \(s&lt;t\) is typically taken as the target. Yet, the other direction can also carry meaningful structure. Notice in DDIM<d-cite key="song2020denoising"></d-cite> sampling, the conditional probability path is traversed twice. In our flow map formulation, this can be replaced with the flow maps \(f_{\tau_i\to 0}(\mathbf{x}_{\tau_i}, \tau_i, 0), f_{0\to \tau_{i-1}}(\mathbf{x}_0, 0, \tau_{i-1})\) where \(0&lt;\tau_{i-1}&lt;\tau_i&lt;1\). Intuitively, the flow map \(f_{t\to s}(\mathbf{x}_t, t, s)\) represents a direct mapping of some <strong>displacement field</strong> where \(F_{t\to s}(\mathbf{x}_t, t, s)\) measures the increment which corresponds to a <strong>velocity field</strong>.</p> <h3 id="meanflow">MeanFlow</h3> <p>MeanFlow<d-cite key="geng2025mean"></d-cite> can be trained from scratch or distilled from a pretrained FM model. The conditional probability path is defined as the linear interpolation between noise and data \(\mathbf{x}_t = (1-t)\mathbf{x}_0 + t\mathbf{x}_1\) with the corresponding default conditional velocity field OT target \(v(\mathbf{x}_t, t \vert \mathbf{x}_0)=\mathbf{x}_1- \mathbf{x}_0.\) The main contribution consists of identifying and defining an <strong>average velocity field</strong> which coincides with our flow map as</p> \[F_{t\to s}(\mathbf{x}_t, t, s)=u(\mathbf{x}_t, t, s) \triangleq \frac{1}{t - s} \int_s^t v(\mathbf{x}_\tau, \tau) d\tau=\dfrac{f_{t\to s}(\mathbf{x}_t, t, s)-f_{t\to t}(\mathbf{x}_t, t, t)}{s-t}\] <p>where \(c_{\text{out}}(t,s)=s-t\). This is great since it attributes actual physical meaning to our flow map. In particular, \(f_{t\to s}(\mathbf{x}_t, t, s)\) represents the “displacement” from \(\mathbf{x}_t\) to \(\mathbf{x}_s\), while \(F_{t\to s}(\mathbf{x}_t, t, s)\) is the average velocity field pointing from \(\mathbf{x}_t\) to \(\mathbf{x}_s\).</p> <p>We rearrange equation above.</p> \[\begin{equation} (t-s)F_{t\to s}(\mathbf{x}_t, t, s)=\int_s^t v(\mathbf{x}_\tau, \tau) d\tau \label{eq:2} \end{equation}\] <p>Differentiating (\ref{eq:2}) both sides w.r.t. $t$ and considering the assumption that $s$ is independent of $t$, we obtain the MeanFlow identity<d-cite key="geng2025mean"></d-cite></p> \[\require{physics} v(\mathbf{x}_t, t)=F_{t\to s}(\mathbf{x}_t, t, s) +(t-s)\dv{F_{t\to s}(\mathbf{x}_t, t, s)}{t}\] <p>where we further compute the total derivative and derive the target \(F_{t\to s}^{\text{tgt}}(\mathbf{x}_t, t, s)\).</p> <p><span style="color: blue; font-weight: bold;">Training</span>: Adapting to our flow map notation, the training objective turns to</p> \[\mathbb{E}_{\mathbf{x}_0, \mathbf{x}_1, t, s} \left[ w(t) \left\| F^\theta_{t\to s}(\mathbf{x}_t, t, s) - F_{t\to s}^{\text{tgt}}(\mathbf{x}_t, t, s | \mathbf{x}_0) \right\|_2^2 \right]\] <p>where \(F_{t\to s}^{\text{tgt}}(\mathbf{x}_t, t, s\vert\mathbf{x}_0)=v - (t-s)(v\partial_{\mathbf{x}_t}F^{\theta^-}_{t\to s}(\mathbf{x}_t, t, s) + \partial_t F^{\theta^-}_{t\to s}(\mathbf{x}_t, t, s))\) and \(\theta^-\) means <code class="language-plaintext highlighter-rouge">stopgrad()</code>. Note <code class="language-plaintext highlighter-rouge">stopgrad</code> aims to avoid high order gradient computation. There are a couple of choices for \(v\), we can substitute it with \(F_{t\to t}(\mathbf{x}_t, t, t)\) or \(v(\mathbf{x}_t, t \vert \mathbf{x}_0)=\mathbf{x}_1- \mathbf{x}_0.\) Again, MeanFlow adopts the latter to reduce computation.</p> <details> <summary>Full derivation of the target</summary> Based on the MeanFlow identity, we can compute the target as follows: $$ \require{physics} \require{cancel} \begin{align*} F_{t\to s}^{\text{tgt}}(\mathbf{x}_t, t, s\vert\mathbf{x}_0) &amp;= \dv{\mathbf{x}_t}{t} - (t-s)\dv{F_{t\to s}(\mathbf{x}_t, t, s)}{t} \\ &amp; = \dv{\mathbf{x}_t}{t} - (t-s)\left(\nabla_{\mathbf{x}_t} F_{t\to s}(\mathbf{x}_t, t, s) \dv{\mathbf{x}_t}{t} + \partial_t F_{t\to s}(\mathbf{x}_t, t, s) + \cancel{\partial_s F_{t\to s}(\mathbf{x}_t, t, s) \dv{s}{t}}\right) \\ &amp; = v - (t-s)\left(v \nabla_{\mathbf{x}_t} F_{t\to s}(\mathbf{x}_t, t, s) + \partial_t F_{t\to s}(\mathbf{x}_t, t, s)\right). \\ \end{align*} $$ Note that in MeanFlow $$\dv{\mathbf{x}_t}{t} = v(\mathbf{x}_t, t\vert \mathbf{x}_0)$$ and $$\dv{s}{t}=0$$ since $s$ is independent of $t$. </details> <p>In practice, the total derivative of \(F_{t\to s}(\mathbf{x}_t, t, s)\) and the evaluation can be done in a single function call: <code class="language-plaintext highlighter-rouge">f, dfdt=jvp(f_theta, (xt, s, t), (v, 0, 1))</code>. Despite <code class="language-plaintext highlighter-rouge">jvp</code> operation only introduces one extra backward pass, it still incurs instability and slows down training. Moreover, the <code class="language-plaintext highlighter-rouge">jvp</code> operation is currently incompatible with the latest attention architecture. SplitMeanFlow<d-cite key="guo2025splitmeanflow"></d-cite> circumvents this issue by enforcing another consistency identity \((t-s)F_{t\to s} = (t-r)F_{t\to r}+(r-s)F_{r\to s}\) where \(s&lt;r&lt;t\). This implies a discretized version of the MeanFlow objective which falls into loss type (c).</p> <details> <summary>Loss type</summary> Type (b) backward loss </details> <p><span style="color: orange; font-weight: bold;">Sampling</span>: Either one-step or multi-step sampling can be performed. It is intuitive to obtain the following expression by the definition of average velocity field</p> \[\mathbf{x}_s = \mathbf{x}_t - (t-s)F^\theta_{t\to s}(\mathbf{x}_t, t, s).\] <p>In particular, we achieve one-step inference by setting $t=1, s=0$ and sampling from \(\mathbf{x}_1\sim p_{\text{noise}}\).</p> <h3 id="consistency-models">Consistency Models</h3> <p>Essentially, consistency models (CMs)<d-cite key="lu2024simplifying"></d-cite> are our flow map when \(s=0\), i.e., \(f_{t\to 0}(\mathbf{x}_t, t, 0).\)</p> <p><strong>Discretized CM</strong></p> <p>CMs are trained to have consistent outputs between adjacent timesteps along the ODE (\ref{eq:1}) trajectory. They can be trained from scratch by consistency training or distilled from given diffusion or flow models via consistency distillation like MeanFlow.</p> <ul> <li> <span style="color: blue; font-weight: bold;">Training</span>: When expressed in our flow map notation, the objective becomes</li> </ul> \[\mathbb{E}_{\mathbf{x}_t, t} \left[ w(t) d\left(f_{t \to 0}^\theta(\mathbf{x}_t, t,0), f_{t \to 0}^{\theta^-}(\mathbf{x}_{t-\Delta t}, t - \Delta t,0)\right) \right],\] <p>where \(\theta^-\) denotes \(\text{stopgrad}(\theta)\), \(w(t)\) is a weighting function, \(\Delta t &gt; 0\) is the distance between adjacent time steps, and $d(\cdot, \cdot)$ is a distance metric.<d-footnote>Common choices include $\ell_2$ loss $d(\mathbf{x}, \mathbf{y}) = ||\mathbf{x} - \mathbf{y}||_2^2$, pseudo-Huber loss $d(\mathbf{x}, \mathbf{y}) = \sqrt{||\mathbf{x} - \mathbf{y}||_2^2 + c^2} - c$ and Learned Perceptual Image Patch Similarity (LPIPS) loss. </d-footnote></p> <ul> <li> <span style="color: orange; font-weight: bold;">Sampling</span>: It is natural to conduct one-step sampling with CM</li> </ul> \[\hat{\mathbf{x}}_0 = f^{\theta}_{1\to 0}(\mathbf{x}_1, 1,0),\] <p>while multi-step sampling is also possible since we can compute the next noisy output \(\mathbf{x}_{t-\Delta t}\sim p_{t-\Delta t}(\cdot\vert \mathbf{x}_0)\) using the prescribed conditional probability path at our discretion. Discrete-time CMs depend heavily on the choice of \(\Delta t\) and often require carefully designed annealing schedules. To obtain the noisy sample \(\mathbf{x}_{t-\Delta t}\) at the previous step, one typically evolves backward \(\mathbf{x}_t\) by numerically solving the ODE (\ref{eq:1}), which can introduce additional discretization errors.</p> <p><strong>Continuous CM</strong></p> <p>When using \(d(\mathbf{x}, \mathbf{y}) = ||\mathbf{x} - \mathbf{y}||_2^2\) and taking the limit $\Delta t \to 0$, Song et al.<d-cite key="song2020score"></d-cite> show that the gradient of the discretized CM’s loss with respect to $\theta$ converges to a new objective with no \(\Delta t\) involved.</p> <ul> <li> <span style="color: blue; font-weight: bold;">Training</span>: In our notation, the objective is</li> </ul> \[\require{physics} \mathbb{E}_{\mathbf{x}_t, t} \left[ w(t) (f^\theta_{t\to 0})^{\top}(\mathbf{x}_t, t,0) \dv{f^{\theta^-}_{t\to 0}(\mathbf{x}_t, t,0)}{t} \right]\] <p>where \(\require{physics} \dv{f^{\theta^-}_{t\to 0}(\mathbf{x}_t, t,0)}{t} = \nabla_{\mathbf{x}_t} f^{\theta^-}_{t\to 0}(\mathbf{x}_t, t,0) \dv{\mathbf{x}_t}{t} + \partial_t f^{\theta^-}_{t\to 0}(\mathbf{x}_t, t,0)\) is the tangent of \(f^{\theta^-}_{t\to 0}\) at \((\mathbf{x}_t, t)\) along the trajectory of the ODE (\ref{eq:1}). Consistency Trajectory Models (CTMs)<d-cite key="kim2023consistency"></d-cite> extend this objective so that the forward loss (type (a)) becomes globally optimized. In this context, their intuition is that \(f^\theta_{t \to s}(\mathbf{x}_t, t, s)\approx f^\theta_{r \to s}(\texttt{Solver}_{t\to r}(\mathbf{x}_t, t, r), r, s).\) The composition order on the right-hand side depends on the assumption of the solver of the teacher model.</p> <ul> <li><span style="color: orange; font-weight: bold;">Sampling</span></li> </ul> <p>Same as the Discretized Version. CTMs<d-cite key="kim2023consistency"></d-cite> introduce a new sampling method called \(\gamma\)-sampling which controls the noise level of diffusing the intermediate noisy sample according to the conditional probability path during multi-step sampling.</p> <details> <summary>Loss type</summary> Type (b) backward loss, while CTMs<d-cite key="kim2023consistency"></d-cite> optimize type (a) forward loss, both locally and globally. </details> <h3 id="flow-anchor-consistency-model">Flow Anchor Consistency Model</h3> <p>Similar to MeanFlow preliminaries, Flow Anchor Consistency Model (FACM)<d-cite key="peng2025flow"></d-cite> also adopts the linear conditional probability path \(\mathbf{x}_t = (1-t)\mathbf{x}_0 + t\mathbf{x}_1\) with the corresponding default conditional velocity field OT target \(v(\mathbf{x}_t, t \vert \mathbf{x}_0)=\mathbf{x}_1- \mathbf{x}_0.\) In our flow maps notation, FACM parameterizes the model as \(f^\theta_{t\to s}(\mathbf{x}_t, t, 0)= \mathbf{x}_t - tF^\theta_{t\to s}(\mathbf{x}_t, t, 0)\) where \(c_{\text{skip}}(t,s)=1\) and \(c_{\text{out}}(t,s)=-t\).</p> <p>FACM imposes a <strong>consistency property</strong> which requires the total derivative of the consistency function to be zero \(\require{physics} \dv{t}f^\theta_{t \to 0}(\mathbf{x}, t, 0) = 0.\)</p> <p>By substituting the parameterization of FACM, we have</p> \[\require{physics} F^\theta_{t\to 0}(\mathbf{x}_t, t, 0)=v(\mathbf{x}_t, t)-t\dv{F^\theta_{t\to 0}(\mathbf{x}_t, t, 0)}{t}.\] <p>Notice this is equivalent to <a href="#meanflow">MeanFlow</a> where \(s=0\). This indicates CM objective directly forces the network \(F^\theta_{t\to 0}(\mathbf{x}_t, t, 0)\) to learn the properties of an average velocity field heading towards the data distribution, thus enabling the 1-step generation shortcut.</p> <p><span style="color: blue; font-weight: bold;">Training</span>: FACM training algorithm equipped with our flow map notation. Notice that \(d_1, d_2\) are $\ell_2$ with cosine loss<d-footnote>$L_{\cos}(\mathbf{x}, \mathbf{y}) = 1 - \dfrac{\mathbf{x} \cdot \mathbf{y}}{\|\mathbf{x}\|_{2} \, \|\mathbf{y}\|_{2}}$</d-footnote> and norm $\ell_2$ loss<d-footnote>$L_{\text{norm}}(\mathbf{x}, \mathbf{y}) =\dfrac{\|\mathbf{x}-\mathbf{y}\|^2}{\sqrt{\|\mathbf{x}-\mathbf{y}\|^2+c}}$ where $c$ is a small constant. This is a special case of adaptive L2 loss proposed in MeanFlow<d-cite key="geng2025mean"></d-cite>.</d-footnote> respectively, plus reweighting. Interestingly, they separate the training of FM and CM on disentangled time intervals. When training with CM target, we let \(s=0, t\in[0,1]\). On the other hand, we set \(t'=2-t, t'\in[1,2]\) when training with FM anchors.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/diff-distill/facm_training-480.webp 480w,/blog/2025/diff-distill/facm_training-800.webp 800w,/blog/2025/diff-distill/facm_training-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/blog/2025/diff-distill/facm_training.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><span style="color: orange; font-weight: bold;">Sampling</span>: Same as CM.</p> <details> <summary>Loss type</summary> Type (b) backward loss </details> <h3 id="align-your-flow">Align Your Flow</h3> <p>Our notation incorporates a small modification of the flow map introduced by Align Your Flow<d-cite key="sabour2025align"></d-cite>, where we indicate the direction of the distillation. Hence, we say that Align Your Flow (AYF) the continuous-time flow map \(f^{\text{AYF}}(\mathbf{x}_t, t, s)=f_{t\to s}(\mathbf{x}_t, t, s).\) Specifically, AYF selects a tighter set of boundary conditions \(c_{\text{skip}}(t,s)=1\) and \(c_{\text{out}}(t,s)=s-t\).</p> <p><span style="color: blue; font-weight: bold;">Training</span>: The first variant of the objective, called AYF-<strong>Eulerian Map Distillation</strong>, is compatible with both distillation and training from scratch.</p> \[\nabla_\theta \mathbb{E}_{\mathbf{x}_t, t, s}\left[w(t, s)\text{sign}(t - s) \cdot (f^\theta_{t \to s})^\top(\mathbf{x}_t, t, s) \cdot \frac{\text{d}f^{\theta^-}_{t\to s}(\mathbf{x}_t, t, s)}{\text{d}t}\right]\] <p>It is intriguing that this objective reduces to the <a href="#consistency-models">continuous CM</a> objective when \(s=0\), while transforming to original FM objective when \(s\to t\)<d-footnote>The gradient of AYF-EMD matches the gradient of FM objective up to some constant when taking the limit $s\to t$.</d-footnote>. In addition, CTMs<d-cite key="kim2023consistency"></d-cite> uses a discrete consistency loss with a fixed discretized time schedule comparing to AYF-EMD objective. Regarding the second variant, named AYF-<strong>Lagrangian Map Distillation</strong>, it is only applicable to distillation from a pretrained flow model \(F^\delta_{t \to t}(\mathbf{x}_t,t,t)\).</p> \[\nabla_\theta \mathbb{E}_{\mathbf{x}_t, t, s}\left[w(t, s)\text{sign}(s - t) \cdot (f^\theta_{t \to s})^\top \cdot \left(\frac{\text{d}f^{\theta^-}_{t\to s}}{\text{d}s} - F^\delta_{s \to s}((f_{\theta^-}(\mathbf{x}_t, t, s), s,s)\right)\right].\] <p><span style="color: orange; font-weight: bold;">Sampling</span>: Same as CM. A combination of \(\gamma\)-sampling and classifier-free guidance.</p> <p>The formulation of these objectives is majorly built on the Flow Map Matching<d-cite key="boffi2025build"></d-cite>. Similar to the trick in training <a href="#meanflow">Meanflow</a> and <a href="#consistency-models">CMs</a>, they add a <code class="language-plaintext highlighter-rouge">stopgrad</code> operator to the loss to stabilize training and make the objective practical. In their appendix, they provide a detailed proof of why these objectives are equivalent to the objectives in Flow Map Matching<d-cite key="boffi2025build"></d-cite>.</p> <details> <summary>Loss type</summary> Type (b) backward loss for AYF-EMD, type (a) forward loss for AYF-LMD. </details> <h2 id="connections">Connections</h2> <p>Now it is time to connect the dots with some previous existing methods. Let’s frame their objectives in our flow map notation and identify their loss types if possible.</p> <h3 id="shortcut-models">Shortcut Models</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/diff-distill/shortcut_model-480.webp 480w,/blog/2025/diff-distill/shortcut_model-800.webp 800w,/blog/2025/diff-distill/shortcut_model-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/blog/2025/diff-distill/shortcut_model.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The diagram of Shortcut Models<d-cite key="frans2024one"></d-cite> </div> <p>In essence, Shortcut Models<d-cite key="frans2024one"></d-cite> augment the standard flow matching objective with a self-consistency regularization term. This additional loss component ensures that the learned vector field satisfies a midpoint consistency property: the result of a single large integration step should match the composition of two smaller steps traversing the same portion of the ODE (\ref{eq:1}) trajectory.</p> <p><span style="color: blue; font-weight: bold;">Training</span>: In the training objective, we neglect the input arguments and focus on the core transition between time steps. Again, we elaborate it with our flow map notation.</p> \[\mathbb{E}_{\mathbf{x}_t, t, s}\left[\left\|F^\theta_{t\to t} - \dfrac{\text{d}\mathbf{x}_t}{\text{d}t}\right\|_2^2 + \left\|f^\theta_{t\to s} - f^{\theta^-}_{\frac{t+s}{2}\to s}\circ f^{\theta^-}_{t \to \frac{t+s}{2}}\right\|_2^2\right]\] <p>where we adopt the same flow map conditions based on <a href="#align-your-flow">AYF</a>.</p> <p><span style="color: orange; font-weight: bold;">Sampling</span>: Same with MeanFlow yet with specific shortcut lengths.</p> <details> <summary>Loss type</summary> Type (c) tri-consistency loss </details> <h3 id="reflow">ReFlow</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/diff-distill/rectifiedflow-480.webp 480w,/blog/2025/diff-distill/rectifiedflow-800.webp 800w,/blog/2025/diff-distill/rectifiedflow-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/blog/2025/diff-distill/rectifiedflow.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The diagram of rectified flow and ReFlow process<d-cite key="liu2022flow"></d-cite> </div> <p>Unlike most ODE distillation methods that learn to jump from \(t\to s\) according to our defined flow map \(f_{t\to s}(\mathbf{x}_t, t, s)\), ReFlow<d-cite key="liu2022flow"></d-cite> takes a different approach by establishing new noise-data couplings so that the new model will generate straighter trajectories.<d-footnote>In the rectified flow paper<d-cite key="liu2022flow"></d-cite>, the straightness of any continuously differentiable process $$Z=\{Z_t\}$$ can be measured by $$S(Z)=\int_0^1\mathbb{E}\|(Z_1-Z_0)-\dot{Z}_t\|^2 dt$$ where $S(Z)=0$ implies the trajectories are perfectly straight.</d-footnote> In this case, this allows the ODE (\ref{eq:1}) to be solved with fewer steps and larger step sizes. To some extent, this resembles the preconditioning from OT-CFM<d-cite key="tong2023improving"></d-cite> where they intentionally sample noise and data pairs jointly from an optimal transport map \(\pi(\mathbf{x}_0, \mathbf{x}_1)\) instead of independent marginals.</p> <p><span style="color: blue; font-weight: bold;">Training</span>: Pair synthesized data from the pretrained model with the noise. Use this new coupling to train a student model with the standard FM objective.</p> <p><span style="color: orange; font-weight: bold;">Sampling</span>: Same as FMs.</p> <h3 id="inductive-moment-matching">Inductive Moment Matching</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/2025/diff-distill/IMM-480.webp 480w,/blog/2025/diff-distill/IMM-800.webp 800w,/blog/2025/diff-distill/IMM-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/blog/2025/diff-distill/IMM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The diagram of IMM<d-cite key="zhou2025inductive"></d-cite> </div> <p>This recent method<d-cite key="zhou2025inductive"></d-cite> trains our flow map from scratch via matching the distributions of \(f^{\theta}_{t\to s}(\mathbf{x}_t, t, s)\) and \(f^{\theta}_{r\to s}(\mathbf{x}_r, r, s)\) where \(s&lt;r&lt;t\). They adopt an Maximum Mean Discrepancy (MMD) loss to match the distributions.</p> <p><span style="color: blue; font-weight: bold;">Training</span>: In our flow map notation, the training objective becomes</p> \[\mathbb{E}_{\mathbf{x}_t, t, s} \left[ w(t,s) \text{MMD}^2\left(f_{t \to s}(\mathbf{x}_t, t,s), f_{r \to s}(\mathbf{x}_{r}, r,s)\right) \right]\] <p>where \(w(t,s)\) is a weighting function.</p> <p><span style="color: orange; font-weight: bold;">Sampling</span>: Same spirit as <a href="#align-your-flow">AYF</a>.</p> <h2 id="closing-thoughts">Closing Thoughts</h2> <p>The concept of a flow map offers a capable and unifying notation for summarizing the diverse landscape of diffusion distillation methods. Beyond these ODE distillation methods, an intriguing family of approaches pursues a more direct goal: training a one-step generator from the ground up by directly matching the data distribution from the teacher model.</p> <p>The core question is: how can we best leverage a pre-trained teacher model to train a student that approximates the data distribution \(p_{\text{data}}\) in a single shot? With access to the teacher’s flow, several compelling strategies emerge. It becomes possible to directly match the velocity fields, minimize the \(f\)-divergence between the student and teacher output distributions<d-cite key="yin2024improved, xu2025one"></d-cite>, or align their respective score functions<d-cite key="wang2025uni, zhou2024score"></d-cite>.</p> <p>This leads to distinct techniques in practice. For example, adversarial distillation<d-cite key="yin2024improved, sabour2025align"></d-cite> employs a min-max objective to align the two distributions, while other methods like <a href="#inductive-moment-matching">IMM</a> rely on statistical divergences like the Maximum Mean Discrepancy (MMD).</p> <p>In our own work on human motion prediction<d-cite key="fu2025moflowonestep"></d-cite>, we explored this direction by using Implicit Maximum Likelihood Estimation (IMLE). IMLE is a potent, if less common, technique that aligns distributions based purely on their samples, offering a direct and elegant way to distill the teacher’s knowledge without requiring an explicit density function or a discriminator.</p> <p>Diffusion distillation is a dynamic field brimming with potential. The journey from a hundred steps to a single step is not just a technical challenge but a gateway to real-time, efficient generative AI applications.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2025-08-18-diff-distill.bib"></d-bibliography> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-JGPDT2N8BY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-JGPDT2N8BY");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>