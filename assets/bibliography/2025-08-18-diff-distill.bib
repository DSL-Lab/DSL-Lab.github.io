@misc{lipman_flow_2023,
	title = {Flow Matching for Generative Modeling},
	url = {http://arxiv.org/abs/2210.02747},
	doi = {10.48550/arXiv.2210.02747},
	abstract = {We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows ({CNFs}), allowing us to train {CNFs} at unprecedented scale. Specifically, we present the notion of Flow Matching ({FM}), a simulation-free approach for training {CNFs} based on regressing vector fields of fixed conditional probability paths. Flow Matching is compatible with a general family of Gaussian probability paths for transforming between noise and data samples -- which subsumes existing diffusion paths as specific instances. Interestingly, we find that employing {FM} with diffusion paths results in a more robust and stable alternative for training diffusion models. Furthermore, Flow Matching opens the door to training {CNFs} with other, non-diffusion probability paths. An instance of particular interest is using Optimal Transport ({OT}) displacement interpolation to define the conditional probability paths. These paths are more efficient than diffusion paths, provide faster training and sampling, and result in better generalization. Training {CNFs} using Flow Matching on {ImageNet} leads to consistently better performance than alternative diffusion-based methods in terms of both likelihood and sample quality, and allows fast and reliable sample generation using off-the-shelf numerical {ODE} solvers.},
	number = {{arXiv}:2210.02747},
	publisher = {{arXiv}},
	author = {Lipman, Yaron and Chen, Ricky T. Q. and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
	urldate = {2024-07-05},
	date = {2023-02-08},
	eprinttype = {arxiv},
	eprint = {2210.02747 [cs, stat]}
}

@article{albergo2023stochastic,
  title={Stochastic interpolants: A unifying framework for flows and diffusions},
  author={Albergo, Michael S and Boffi, Nicholas M and Vanden-Eijnden, Eric},
  journal={arXiv preprint arXiv:2303.08797},
  year={2023}
}

@article{tong2023improving,
  title={Improving and generalizing flow-based generative models with minibatch optimal transport},
  author={Tong, Alexander and Fatras, Kilian and Malkin, Nikolay and Huguet, Guillaume and Zhang, Yanlei and Rector-Brooks, Jarrid and Wolf, Guy and Bengio, Yoshua},
  journal={arXiv preprint arXiv:2302.00482},
  year={2023}
}

@article{liu2022flow,
  title={Flow straight and fast: Learning to generate and transfer data with rectified flow},
  author={Liu, Xingchao and Gong, Chengyue and Liu, Qiang},
  journal={arXiv preprint arXiv:2209.03003},
  year={2022}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models. arXiv 2021},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  volume={10},
  year={2021}
}

@article{micikevicius2017mixed,
  title={Mixed precision training},
  author={Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and others},
  journal={arXiv preprint arXiv:1710.03740},
  year={2017}
}

@inproceedings{fu2025moflowonestep,
  author    = {Fu, Yuxiang and Yan, Qi and Wang, Lele and Li, Ke and Liao, Renjie},
  title     = {MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation based Distillation},
  journal   = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year      = {2025},
}

@misc{lipman2024flowmatchingguidecode,
      title={Flow Matching Guide and Code}, 
      author={Yaron Lipman and Marton Havasi and Peter Holderrieth and Neta Shaul and Matt Le and Brian Karrer and Ricky T. Q. Chen and David Lopez-Paz and Heli Ben-Hamu and Itai Gat},
      year={2024},
      eprint={2412.06264},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2412.06264}, 
}

@article{boffi2025build,
  title={How to build a consistency model: Learning flow maps via self-distillation},
  author={Boffi, Nicholas M and Albergo, Michael S and Vanden-Eijnden, Eric},
  journal={arXiv preprint arXiv:2505.18825},
  year={2025}
}

@article{geng2025mean,
  title={Mean flows for one-step generative modeling},
  author={Geng, Zhengyang and Deng, Mingyang and Bai, Xingjian and Kolter, J Zico and He, Kaiming},
  journal={arXiv preprint arXiv:2505.13447},
  year={2025}
}

@article{peng2025flow,
  title={Flow-Anchored Consistency Models},
  author={Peng, Yansong and Zhu, Kai and Liu, Yu and Wu, Pingyu and Li, Hebei and Sun, Xiaoyan and Wu, Feng},
  journal={arXiv preprint arXiv:2507.03738},
  year={2025}
}

@article{guo2025splitmeanflow,
  title={SplitMeanFlow: Interval Splitting Consistency in Few-Step Generative Modeling},
  author={Guo, Yi and Wang, Wei and Yuan, Zhihang and Cao, Rong and Chen, Kuan and Chen, Zhengyang and Huo, Yuanyuan and Zhang, Yang and Wang, Yuping and Liu, Shouda and others},
  journal={arXiv preprint arXiv:2507.16884},
  year={2025}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}

@article{lu2024simplifying,
  title={Simplifying, stabilizing and scaling continuous-time consistency models},
  author={Lu, Cheng and Song, Yang},
  journal={arXiv preprint arXiv:2410.11081},
  year={2024}
}

@article{kim2023consistency,
  title={Consistency trajectory models: Learning probability flow ode trajectory of diffusion},
  author={Kim, Dongjun and Lai, Chieh-Hsin and Liao, Wei-Hsiang and Murata, Naoki and Takida, Yuhta and Uesaka, Toshimitsu and He, Yutong and Mitsufuji, Yuki and Ermon, Stefano},
  journal={arXiv preprint arXiv:2310.02279},
  year={2023}
}

@article{sabour2025align,
  title={Align Your Flow: Scaling Continuous-Time Flow Map Distillation},
  author={Sabour, Amirmojtaba and Fidler, Sanja and Kreis, Karsten},
  journal={arXiv preprint arXiv:2506.14603},
  year={2025}
}

@article{frans2024one,
  title={One step diffusion via shortcut models},
  author={Frans, Kevin and Hafner, Danijar and Levine, Sergey and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2410.12557},
  year={2024}
}

@article{zhou2025inductive,
  title={Inductive moment matching},
  author={Zhou, Linqi and Ermon, Stefano and Song, Jiaming},
  journal={arXiv preprint arXiv:2503.07565},
  year={2025}
} 

@article{yin2024improved,
  title={Improved distribution matching distillation for fast image synthesis},
  author={Yin, Tianwei and Gharbi, Micha{\"e}l and Park, Taesung and Zhang, Richard and Shechtman, Eli and Durand, Fredo and Freeman, Bill},
  journal={Advances in neural information processing systems},
  volume={37},
  pages={47455--47487},
  year={2024}
}

@article{wang2025uni,
  title={Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction},
  author={Wang, Yifei and Bai, Weimin and Zhang, Colin and Zhang, Debing and Luo, Weijian and Sun, He},
  journal={arXiv preprint arXiv:2505.20755},
  year={2025}
}